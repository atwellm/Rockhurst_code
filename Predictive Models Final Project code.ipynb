{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atwell - Assignment 2 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Package import, initial setup, and data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mlatw\\\\Desktop\\\\BIA6303\\\\Final_Project'"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Change working directory if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cd C:\\\\Users\\\\mlatw\\\\Desktop\\\\BIA6303\\\\Assignment_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "The data is contained in two different files (train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>Esctacy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>Semer</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Gender  Education  Country  Ethnicity  N_Score  E_Score  \\\n",
       "0     0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1    -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2     0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3    -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4     0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...       ...      ...        ...      ...        ...      ...      ...   \n",
       "1880 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "      O_Score  A_Score  C_Score ...   Esctacy  Heroin Ketamine Legal_highs  \\\n",
       "0    -0.58331 -0.91699 -0.00665 ...       CL0     CL0      CL0         CL0   \n",
       "1     1.43533  0.76096 -0.14277 ...       CL4     CL0      CL2         CL0   \n",
       "2    -0.84732 -1.62090 -1.01450 ...       CL0     CL0      CL0         CL0   \n",
       "3    -0.01928  0.59042  0.58489 ...       CL0     CL0      CL2         CL0   \n",
       "4    -0.45174 -0.30172  1.30612 ...       CL1     CL0      CL0         CL1   \n",
       "...       ...      ...      ... ...       ...     ...      ...         ...   \n",
       "1880  1.88511  0.76096 -1.13788 ...       CL0     CL0      CL0         CL3   \n",
       "1881  0.58331  0.76096 -1.51840 ...       CL2     CL0      CL0         CL3   \n",
       "1882 -1.27553 -1.77200 -1.38502 ...       CL4     CL0      CL2         CL0   \n",
       "1883  0.29338 -1.62090 -2.57309 ...       CL3     CL0      CL0         CL3   \n",
       "1884  1.65653  1.11406  0.41594 ...       CL3     CL0      CL0         CL3   \n",
       "\n",
       "      LSD Meth Mushrooms Nicotine Semer  VSA  \n",
       "0     CL0  CL0       CL0      CL2   CL0  CL0  \n",
       "1     CL2  CL3       CL0      CL4   CL0  CL0  \n",
       "2     CL0  CL0       CL1      CL0   CL0  CL0  \n",
       "3     CL0  CL0       CL0      CL2   CL0  CL0  \n",
       "4     CL0  CL0       CL2      CL2   CL0  CL0  \n",
       "...   ...  ...       ...      ...   ...  ...  \n",
       "1880  CL3  CL0       CL0      CL0   CL0  CL5  \n",
       "1881  CL5  CL4       CL4      CL5   CL0  CL0  \n",
       "1882  CL2  CL0       CL2      CL6   CL0  CL0  \n",
       "1883  CL3  CL0       CL3      CL4   CL0  CL0  \n",
       "1884  CL3  CL0       CL3      CL6   CL0  CL2  \n",
       "\n",
       "[1885 rows x 31 columns]"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import train data\n",
    "pd.options.display.max_rows = 10\n",
    "df_drug = pd.read_csv(\"drug_consumption_data.csv\", header=None,  \n",
    "                      names = ['ID','Age','Gender','Education','Country','Ethnicity','N_Score','E_Score','O_Score',\n",
    "                               'A_Score','C_Score','Impulsivenesss','SS','Alcohol','Amphetamine','Amyl',\n",
    "                              'Benzos','Caffeine','Cannibis','Chocolate','Cocaine','Crack','Esctacy','Heroin',\n",
    "                              'Ketamine','Legal_highs','LSD','Meth','Mushrooms','Nicotine','Semer','VSA'])\n",
    "del df_drug['ID'] #drops unnecessary ID column\n",
    "df_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the data types to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Type Age               float64\n",
      "Gender            float64\n",
      "Education         float64\n",
      "Country           float64\n",
      "Ethnicity         float64\n",
      "N_Score           float64\n",
      "E_Score           float64\n",
      "O_Score           float64\n",
      "A_Score           float64\n",
      "C_Score           float64\n",
      "Impulsivenesss    float64\n",
      "SS                float64\n",
      "Alcohol            object\n",
      "Amphetamine        object\n",
      "Amyl               object\n",
      "Benzos             object\n",
      "Caffeine           object\n",
      "Cannibis           object\n",
      "Chocolate          object\n",
      "Cocaine            object\n",
      "Crack              object\n",
      "Esctacy            object\n",
      "Heroin             object\n",
      "Ketamine           object\n",
      "Legal_highs        object\n",
      "LSD                object\n",
      "Meth               object\n",
      "Mushrooms          object\n",
      "Nicotine           object\n",
      "Semer              object\n",
      "VSA                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 31\n",
    "print(\"Training Data Type\", df_drug.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first 12 columns are all numeric, and the remainder are objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Gender            0\n",
       "Education         0\n",
       "Country           0\n",
       "Ethnicity         0\n",
       "N_Score           0\n",
       "E_Score           0\n",
       "O_Score           0\n",
       "A_Score           0\n",
       "C_Score           0\n",
       "Impulsivenesss    0\n",
       "SS                0\n",
       "Alcohol           0\n",
       "Amphetamine       0\n",
       "Amyl              0\n",
       "Benzos            0\n",
       "Caffeine          0\n",
       "Cannibis          0\n",
       "Chocolate         0\n",
       "Cocaine           0\n",
       "Crack             0\n",
       "Esctacy           0\n",
       "Heroin            0\n",
       "Ketamine          0\n",
       "Legal_highs       0\n",
       "LSD               0\n",
       "Meth              0\n",
       "Mushrooms         0\n",
       "Nicotine          0\n",
       "Semer             0\n",
       "VSA               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls!  The second to last column, 'Semer', is a fictional drug designed to tease out over-claimers. Let's see how many respondants said they used it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CL0    1877\n",
       "CL2       3\n",
       "CL1       2\n",
       "CL3       2\n",
       "CL4       1\n",
       "Name: Semer, dtype: int64"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug.Semer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a very small number of respondents (8) said they used Semer, we can safely drop these rows from the dataset, and then drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1877, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>Crack</th>\n",
       "      <th>Esctacy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.59171</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-1.22751</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>-0.30033</td>\n",
       "      <td>-1.55521</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.09449</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>-1.09207</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>0.93949</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-1.73790</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.32828</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.62967</td>\n",
       "      <td>2.57309</td>\n",
       "      <td>-0.97631</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>1.13407</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.82213</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>-1.42424</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.12331</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.05308</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-1.11902</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>1.81175</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.09449</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.28519</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.32828</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.14143</td>\n",
       "      <td>-1.92595</td>\n",
       "      <td>-0.52745</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.82213</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>2.28554</td>\n",
       "      <td>0.16767</td>\n",
       "      <td>0.44585</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-0.78155</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.82213</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.79151</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.94156</td>\n",
       "      <td>3.46436</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.82213</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.92104</td>\n",
       "      <td>1.45421</td>\n",
       "      <td>0.44585</td>\n",
       "      <td>-0.60633</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.28519</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.05308</td>\n",
       "      <td>0.96248</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>1.81866</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-1.22751</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.02119</td>\n",
       "      <td>-0.43999</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>-1.07533</td>\n",
       "      <td>0.12331</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.79151</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>2.44904</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-1.43719</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.23177</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>-0.60633</td>\n",
       "      <td>-0.40581</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>2.59171</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>2.44904</td>\n",
       "      <td>0.94156</td>\n",
       "      <td>-0.65253</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.76250</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.78155</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-1.43719</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.49158</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.76250</td>\n",
       "      <td>0.88309</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>2.33337</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.28519</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.79151</td>\n",
       "      <td>0.32197</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>-0.27607</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Gender  Education  Country  Ethnicity  N_Score  E_Score  \\\n",
       "0     0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1    -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2     0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3    -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4     0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "5     2.59171  0.48246   -1.22751  0.24923   -0.31685 -0.67825 -0.30033   \n",
       "6     1.09449 -0.48246    1.16365 -0.57009   -0.31685 -0.46725 -1.09207   \n",
       "7     0.49788 -0.48246   -1.73790  0.96082   -0.31685 -1.32828  1.93886   \n",
       "8     0.49788  0.48246   -0.05921  0.24923   -0.31685  0.62967  2.57309   \n",
       "9     1.82213 -0.48246    1.16365  0.96082   -0.31685 -0.24649  0.00332   \n",
       "10   -0.07854  0.48246    0.45468  0.96082   -0.31685 -1.05308  0.80523   \n",
       "11    1.09449 -0.48246   -0.61113 -0.28519   -0.31685 -1.32828  0.00332   \n",
       "12    1.82213  0.48246    0.45468  0.96082   -0.31685  2.28554  0.16767   \n",
       "13    1.82213  0.48246   -0.05921  0.24923   -0.31685 -0.79151  0.80523   \n",
       "14    1.82213  0.48246   -0.05921  0.96082   -0.31685 -0.92104  1.45421   \n",
       "...       ...      ...        ...      ...        ...      ...      ...   \n",
       "1862 -0.07854  0.48246    0.45468 -0.28519   -0.31685 -1.05308  0.96248   \n",
       "1863 -0.95197 -0.48246   -1.22751 -0.57009   -0.31685  1.02119 -0.43999   \n",
       "1864 -0.95197 -0.48246   -0.61113  0.24923   -0.31685 -0.79151  0.00332   \n",
       "1865 -0.95197 -0.48246   -1.43719 -0.57009   -0.31685  0.73545 -1.23177   \n",
       "1866  2.59171 -0.48246   -0.61113 -0.57009   -0.31685  2.12700 -0.15487   \n",
       "1867 -0.95197 -0.48246   -0.61113 -0.57009    0.12600 -0.05188 -1.76250   \n",
       "1868 -0.07854 -0.48246   -0.61113  0.24923    0.11440 -0.14882 -0.57545   \n",
       "1869 -0.95197 -0.48246   -1.43719 -0.57009   -0.31685  1.49158 -1.92173   \n",
       "1870 -0.95197 -0.48246    0.45468  0.24923   -0.31685 -0.05188 -1.76250   \n",
       "1871 -0.95197 -0.48246   -0.61113 -0.28519   -0.31685 -0.79151  0.32197   \n",
       "1872 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1873 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1874 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1875 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1876 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "      O_Score  A_Score  C_Score ...   Crack  Esctacy Heroin Ketamine  \\\n",
       "0    -0.58331 -0.91699 -0.00665 ...     CL0      CL0    CL0      CL0   \n",
       "1     1.43533  0.76096 -0.14277 ...     CL0      CL4    CL0      CL2   \n",
       "2    -0.84732 -1.62090 -1.01450 ...     CL0      CL0    CL0      CL0   \n",
       "3    -0.01928  0.59042  0.58489 ...     CL0      CL0    CL0      CL2   \n",
       "4    -0.45174 -0.30172  1.30612 ...     CL0      CL1    CL0      CL0   \n",
       "5    -1.55521  2.03972  1.63088 ...     CL0      CL0    CL0      CL0   \n",
       "6    -0.45174 -0.30172  0.93949 ...     CL0      CL0    CL0      CL0   \n",
       "7    -0.84732 -0.30172  1.63088 ...     CL0      CL0    CL0      CL0   \n",
       "8    -0.97631  0.76096  1.13407 ...     CL0      CL0    CL0      CL0   \n",
       "9    -1.42424  0.59042  0.12331 ...     CL0      CL0    CL0      CL0   \n",
       "10   -1.11902 -0.76096  1.81175 ...     CL0      CL0    CL0      CL0   \n",
       "11    0.14143 -1.92595 -0.52745 ...     CL0      CL3    CL0      CL0   \n",
       "12    0.44585 -1.62090 -0.78155 ...     CL0      CL0    CL0      CL0   \n",
       "13   -0.01928  0.94156  3.46436 ...     CL0      CL0    CL0      CL0   \n",
       "14    0.44585 -0.60633  1.63088 ...     CL0      CL0    CL0      CL0   \n",
       "...       ...      ...      ... ...     ...      ...    ...      ...   \n",
       "1862  1.88511  1.81866  1.30612 ...     CL0      CL3    CL0      CL0   \n",
       "1863  1.43533 -1.07533  0.12331 ...     CL3      CL3    CL6      CL3   \n",
       "1864  2.44904  0.76096 -1.51840 ...     CL0      CL2    CL0      CL2   \n",
       "1865  0.58331 -0.60633 -0.40581 ...     CL2      CL3    CL2      CL0   \n",
       "1866  2.44904  0.94156 -0.65253 ...     CL0      CL0    CL0      CL0   \n",
       "1867  0.58331 -0.76096 -0.14277 ...     CL0      CL5    CL0      CL0   \n",
       "1868  1.43533 -0.91699 -0.78155 ...     CL0      CL3    CL0      CL3   \n",
       "1869 -0.58331 -1.77200  0.58489 ...     CL0      CL2    CL5      CL0   \n",
       "1870  0.88309 -0.76096  2.33337 ...     CL0      CL0    CL0      CL0   \n",
       "1871  0.29338 -0.30172 -0.27607 ...     CL0      CL5    CL2      CL0   \n",
       "1872  1.88511  0.76096 -1.13788 ...     CL0      CL0    CL0      CL0   \n",
       "1873  0.58331  0.76096 -1.51840 ...     CL0      CL2    CL0      CL0   \n",
       "1874 -1.27553 -1.77200 -1.38502 ...     CL0      CL4    CL0      CL2   \n",
       "1875  0.29338 -1.62090 -2.57309 ...     CL0      CL3    CL0      CL0   \n",
       "1876  1.65653  1.11406  0.41594 ...     CL0      CL3    CL0      CL0   \n",
       "\n",
       "     Legal_highs  LSD Meth Mushrooms Nicotine  VSA  \n",
       "0            CL0  CL0  CL0       CL0      CL2  CL0  \n",
       "1            CL0  CL2  CL3       CL0      CL4  CL0  \n",
       "2            CL0  CL0  CL0       CL1      CL0  CL0  \n",
       "3            CL0  CL0  CL0       CL0      CL2  CL0  \n",
       "4            CL1  CL0  CL0       CL2      CL2  CL0  \n",
       "5            CL0  CL0  CL0       CL0      CL6  CL0  \n",
       "6            CL0  CL0  CL0       CL0      CL6  CL0  \n",
       "7            CL0  CL0  CL0       CL0      CL0  CL0  \n",
       "8            CL0  CL0  CL0       CL0      CL6  CL0  \n",
       "9            CL0  CL0  CL0       CL0      CL6  CL0  \n",
       "10           CL0  CL0  CL0       CL0      CL2  CL1  \n",
       "11           CL0  CL1  CL0       CL2      CL6  CL0  \n",
       "12           CL0  CL1  CL1       CL1      CL6  CL0  \n",
       "13           CL0  CL0  CL0       CL0      CL1  CL0  \n",
       "14           CL0  CL0  CL0       CL0      CL6  CL0  \n",
       "...          ...  ...  ...       ...      ...  ...  \n",
       "1862         CL0  CL3  CL0       CL1      CL5  CL0  \n",
       "1863         CL5  CL3  CL3       CL0      CL6  CL6  \n",
       "1864         CL2  CL0  CL0       CL0      CL0  CL0  \n",
       "1865         CL5  CL2  CL2       CL3      CL6  CL2  \n",
       "1866         CL0  CL1  CL0       CL1      CL0  CL0  \n",
       "1867         CL2  CL4  CL0       CL4      CL6  CL2  \n",
       "1868         CL5  CL3  CL0       CL4      CL2  CL2  \n",
       "1869         CL2  CL0  CL6       CL0      CL6  CL2  \n",
       "1870         CL2  CL0  CL0       CL2      CL2  CL0  \n",
       "1871         CL4  CL5  CL4       CL0      CL6  CL1  \n",
       "1872         CL3  CL3  CL0       CL0      CL0  CL5  \n",
       "1873         CL3  CL5  CL4       CL4      CL5  CL0  \n",
       "1874         CL0  CL2  CL0       CL2      CL6  CL0  \n",
       "1875         CL3  CL3  CL0       CL3      CL4  CL0  \n",
       "1876         CL3  CL3  CL0       CL3      CL6  CL2  \n",
       "\n",
       "[1877 rows x 30 columns]"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug = df_drug[df_drug['Semer'] == 'CL0']\n",
    "\n",
    "\n",
    "del df_drug['Semer']\n",
    "df_drug = df_drug.reset_index(drop=True)\n",
    "print(df_drug.shape) #confirm correct operation\n",
    "#iris.ix[iris['sepal length (cm)'] >= 5]\n",
    "df_drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the non-numeric columns to see what's in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1877, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Amphetamine</th>\n",
       "      <th>Amyl</th>\n",
       "      <th>Benzos</th>\n",
       "      <th>Caffeine</th>\n",
       "      <th>Cannibis</th>\n",
       "      <th>Chocolate</th>\n",
       "      <th>Cocaine</th>\n",
       "      <th>Crack</th>\n",
       "      <th>Esctacy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>CL4</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol Amphetamine Amyl Benzos Caffeine Cannibis Chocolate Cocaine  \\\n",
       "0        CL5         CL2  CL0    CL2      CL6      CL0       CL5     CL0   \n",
       "1        CL5         CL2  CL2    CL0      CL6      CL4       CL6     CL3   \n",
       "2        CL6         CL0  CL0    CL0      CL6      CL3       CL4     CL0   \n",
       "3        CL4         CL0  CL0    CL3      CL5      CL2       CL4     CL2   \n",
       "4        CL4         CL1  CL1    CL0      CL6      CL3       CL6     CL0   \n",
       "5        CL2         CL0  CL0    CL0      CL6      CL0       CL4     CL0   \n",
       "6        CL6         CL0  CL0    CL0      CL6      CL1       CL5     CL0   \n",
       "7        CL5         CL0  CL0    CL0      CL6      CL0       CL4     CL0   \n",
       "8        CL4         CL0  CL0    CL0      CL6      CL0       CL6     CL0   \n",
       "9        CL6         CL1  CL0    CL1      CL6      CL1       CL6     CL0   \n",
       "10       CL5         CL0  CL1    CL0      CL6      CL2       CL5     CL2   \n",
       "11       CL5         CL1  CL0    CL0      CL6      CL4       CL5     CL2   \n",
       "12       CL5         CL1  CL0    CL4      CL6      CL3       CL5     CL1   \n",
       "13       CL1         CL0  CL0    CL0      CL5      CL0       CL0     CL0   \n",
       "14       CL6         CL0  CL0    CL0      CL6      CL0       CL6     CL0   \n",
       "...      ...         ...  ...    ...      ...      ...       ...     ...   \n",
       "1862     CL6         CL3  CL1    CL0      CL6      CL5       CL4     CL0   \n",
       "1863     CL6         CL3  CL0    CL3      CL6      CL6       CL4     CL3   \n",
       "1864     CL5         CL6  CL0    CL0      CL5      CL6       CL5     CL0   \n",
       "1865     CL5         CL3  CL0    CL4      CL6      CL6       CL5     CL3   \n",
       "1866     CL5         CL0  CL1    CL6      CL6      CL3       CL6     CL1   \n",
       "1867     CL5         CL0  CL0    CL0      CL5      CL5       CL4     CL0   \n",
       "1868     CL6         CL0  CL0    CL0      CL5      CL6       CL5     CL4   \n",
       "1869     CL6         CL2  CL0    CL6      CL6      CL5       CL5     CL3   \n",
       "1870     CL4         CL0  CL0    CL0      CL2      CL5       CL5     CL0   \n",
       "1871     CL4         CL3  CL0    CL3      CL5      CL6       CL5     CL0   \n",
       "1872     CL5         CL0  CL0    CL0      CL4      CL5       CL4     CL0   \n",
       "1873     CL5         CL0  CL0    CL0      CL5      CL3       CL4     CL0   \n",
       "1874     CL4         CL6  CL5    CL5      CL6      CL6       CL6     CL4   \n",
       "1875     CL5         CL0  CL0    CL0      CL6      CL6       CL5     CL0   \n",
       "1876     CL4         CL3  CL0    CL3      CL6      CL3       CL6     CL3   \n",
       "\n",
       "     Crack Esctacy Heroin Ketamine Legal_highs  LSD Meth Mushrooms Nicotine  \\\n",
       "0      CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL2   \n",
       "1      CL0     CL4    CL0      CL2         CL0  CL2  CL3       CL0      CL4   \n",
       "2      CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL1      CL0   \n",
       "3      CL0     CL0    CL0      CL2         CL0  CL0  CL0       CL0      CL2   \n",
       "4      CL0     CL1    CL0      CL0         CL1  CL0  CL0       CL2      CL2   \n",
       "5      CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL6   \n",
       "6      CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL6   \n",
       "7      CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL0   \n",
       "8      CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL6   \n",
       "9      CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL6   \n",
       "10     CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL2   \n",
       "11     CL0     CL3    CL0      CL0         CL0  CL1  CL0       CL2      CL6   \n",
       "12     CL0     CL0    CL0      CL0         CL0  CL1  CL1       CL1      CL6   \n",
       "13     CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL1   \n",
       "14     CL0     CL0    CL0      CL0         CL0  CL0  CL0       CL0      CL6   \n",
       "...    ...     ...    ...      ...         ...  ...  ...       ...      ...   \n",
       "1862   CL0     CL3    CL0      CL0         CL0  CL3  CL0       CL1      CL5   \n",
       "1863   CL3     CL3    CL6      CL3         CL5  CL3  CL3       CL0      CL6   \n",
       "1864   CL0     CL2    CL0      CL2         CL2  CL0  CL0       CL0      CL0   \n",
       "1865   CL2     CL3    CL2      CL0         CL5  CL2  CL2       CL3      CL6   \n",
       "1866   CL0     CL0    CL0      CL0         CL0  CL1  CL0       CL1      CL0   \n",
       "1867   CL0     CL5    CL0      CL0         CL2  CL4  CL0       CL4      CL6   \n",
       "1868   CL0     CL3    CL0      CL3         CL5  CL3  CL0       CL4      CL2   \n",
       "1869   CL0     CL2    CL5      CL0         CL2  CL0  CL6       CL0      CL6   \n",
       "1870   CL0     CL0    CL0      CL0         CL2  CL0  CL0       CL2      CL2   \n",
       "1871   CL0     CL5    CL2      CL0         CL4  CL5  CL4       CL0      CL6   \n",
       "1872   CL0     CL0    CL0      CL0         CL3  CL3  CL0       CL0      CL0   \n",
       "1873   CL0     CL2    CL0      CL0         CL3  CL5  CL4       CL4      CL5   \n",
       "1874   CL0     CL4    CL0      CL2         CL0  CL2  CL0       CL2      CL6   \n",
       "1875   CL0     CL3    CL0      CL0         CL3  CL3  CL0       CL3      CL4   \n",
       "1876   CL0     CL3    CL0      CL0         CL3  CL3  CL0       CL3      CL6   \n",
       "\n",
       "      VSA  \n",
       "0     CL0  \n",
       "1     CL0  \n",
       "2     CL0  \n",
       "3     CL0  \n",
       "4     CL0  \n",
       "5     CL0  \n",
       "6     CL0  \n",
       "7     CL0  \n",
       "8     CL0  \n",
       "9     CL0  \n",
       "10    CL1  \n",
       "11    CL0  \n",
       "12    CL0  \n",
       "13    CL0  \n",
       "14    CL0  \n",
       "...   ...  \n",
       "1862  CL0  \n",
       "1863  CL6  \n",
       "1864  CL0  \n",
       "1865  CL2  \n",
       "1866  CL0  \n",
       "1867  CL2  \n",
       "1868  CL2  \n",
       "1869  CL2  \n",
       "1870  CL0  \n",
       "1871  CL1  \n",
       "1872  CL5  \n",
       "1873  CL0  \n",
       "1874  CL0  \n",
       "1875  CL0  \n",
       "1876  CL2  \n",
       "\n",
       "[1877 rows x 18 columns]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df_drug.value_counts())\n",
    "df_drug_object_only = df_drug.iloc[:,12:]\n",
    "print(df_drug_object_only.shape)\n",
    "#df_drug_object_only.apply(pd.Series.value_counts)\n",
    "#print(\"Test Set\", df_test.Work_Class.value_counts())\n",
    "df_drug_object_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities here.  All rows have a class assigned from 0 (never used) through 6 (used in last day) for each of the substances listed.  These will have to be converted into numeric form to be usable.  Additionally, rather than running a predictive model for each drug indiviually, it would be more useful to get an aggregate score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creating a numeric dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to convert all of the dataframe to numeric, but first we're going to take a look at the data that's already numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "      <td>1877.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0375771124</td>\n",
       "      <td>-0.0007711135</td>\n",
       "      <td>-0.0009844699</td>\n",
       "      <td>0.3589839265</td>\n",
       "      <td>-0.3097279702</td>\n",
       "      <td>-0.0005513692</td>\n",
       "      <td>-0.0019512627</td>\n",
       "      <td>-0.0032237666</td>\n",
       "      <td>-0.0006573468</td>\n",
       "      <td>-0.0003940170</td>\n",
       "      <td>0.0052934523</td>\n",
       "      <td>-0.0074076026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.8783870711</td>\n",
       "      <td>0.4825879539</td>\n",
       "      <td>0.9498314039</td>\n",
       "      <td>0.6997068755</td>\n",
       "      <td>0.1662196872</td>\n",
       "      <td>0.9984424016</td>\n",
       "      <td>0.9974175429</td>\n",
       "      <td>0.9956909325</td>\n",
       "      <td>0.9966886106</td>\n",
       "      <td>0.9976570684</td>\n",
       "      <td>0.9541479261</td>\n",
       "      <td>0.9620744268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.9519700000</td>\n",
       "      <td>-0.4824600000</td>\n",
       "      <td>-2.4359100000</td>\n",
       "      <td>-0.5700900000</td>\n",
       "      <td>-1.1070200000</td>\n",
       "      <td>-3.4643600000</td>\n",
       "      <td>-3.2739300000</td>\n",
       "      <td>-3.2739300000</td>\n",
       "      <td>-3.4643600000</td>\n",
       "      <td>-3.4643600000</td>\n",
       "      <td>-2.5552400000</td>\n",
       "      <td>-2.0784800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.9519700000</td>\n",
       "      <td>-0.4824600000</td>\n",
       "      <td>-0.6111300000</td>\n",
       "      <td>-0.5700900000</td>\n",
       "      <td>-0.3168500000</td>\n",
       "      <td>-0.6782500000</td>\n",
       "      <td>-0.6950900000</td>\n",
       "      <td>-0.7172700000</td>\n",
       "      <td>-0.6063300000</td>\n",
       "      <td>-0.6525300000</td>\n",
       "      <td>-0.7112600000</td>\n",
       "      <td>-0.5259300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.0785400000</td>\n",
       "      <td>-0.4824600000</td>\n",
       "      <td>-0.0592100000</td>\n",
       "      <td>0.9608200000</td>\n",
       "      <td>-0.3168500000</td>\n",
       "      <td>0.0425700000</td>\n",
       "      <td>0.0033200000</td>\n",
       "      <td>-0.0192800000</td>\n",
       "      <td>-0.0172900000</td>\n",
       "      <td>-0.0066500000</td>\n",
       "      <td>-0.2171200000</td>\n",
       "      <td>0.0798700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.4978800000</td>\n",
       "      <td>0.4824600000</td>\n",
       "      <td>0.4546800000</td>\n",
       "      <td>0.9608200000</td>\n",
       "      <td>-0.3168500000</td>\n",
       "      <td>0.6296700000</td>\n",
       "      <td>0.6377900000</td>\n",
       "      <td>0.7233000000</td>\n",
       "      <td>0.7609600000</td>\n",
       "      <td>0.5848900000</td>\n",
       "      <td>0.5297500000</td>\n",
       "      <td>0.7654000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.5917100000</td>\n",
       "      <td>0.4824600000</td>\n",
       "      <td>1.9843700000</td>\n",
       "      <td>0.9608200000</td>\n",
       "      <td>1.9072500000</td>\n",
       "      <td>3.2739300000</td>\n",
       "      <td>3.2739300000</td>\n",
       "      <td>2.9016100000</td>\n",
       "      <td>3.4643600000</td>\n",
       "      <td>3.4643600000</td>\n",
       "      <td>2.9016100000</td>\n",
       "      <td>1.9217300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Age           Gender        Education          Country  \\\n",
       "count  1877.0000000000  1877.0000000000  1877.0000000000  1877.0000000000   \n",
       "mean      0.0375771124    -0.0007711135    -0.0009844699     0.3589839265   \n",
       "std       0.8783870711     0.4825879539     0.9498314039     0.6997068755   \n",
       "min      -0.9519700000    -0.4824600000    -2.4359100000    -0.5700900000   \n",
       "25%      -0.9519700000    -0.4824600000    -0.6111300000    -0.5700900000   \n",
       "50%      -0.0785400000    -0.4824600000    -0.0592100000     0.9608200000   \n",
       "75%       0.4978800000     0.4824600000     0.4546800000     0.9608200000   \n",
       "max       2.5917100000     0.4824600000     1.9843700000     0.9608200000   \n",
       "\n",
       "             Ethnicity          N_Score          E_Score          O_Score  \\\n",
       "count  1877.0000000000  1877.0000000000  1877.0000000000  1877.0000000000   \n",
       "mean     -0.3097279702    -0.0005513692    -0.0019512627    -0.0032237666   \n",
       "std       0.1662196872     0.9984424016     0.9974175429     0.9956909325   \n",
       "min      -1.1070200000    -3.4643600000    -3.2739300000    -3.2739300000   \n",
       "25%      -0.3168500000    -0.6782500000    -0.6950900000    -0.7172700000   \n",
       "50%      -0.3168500000     0.0425700000     0.0033200000    -0.0192800000   \n",
       "75%      -0.3168500000     0.6296700000     0.6377900000     0.7233000000   \n",
       "max       1.9072500000     3.2739300000     3.2739300000     2.9016100000   \n",
       "\n",
       "               A_Score          C_Score   Impulsivenesss               SS  \n",
       "count  1877.0000000000  1877.0000000000  1877.0000000000  1877.0000000000  \n",
       "mean     -0.0006573468    -0.0003940170     0.0052934523    -0.0074076026  \n",
       "std       0.9966886106     0.9976570684     0.9541479261     0.9620744268  \n",
       "min      -3.4643600000    -3.4643600000    -2.5552400000    -2.0784800000  \n",
       "25%      -0.6063300000    -0.6525300000    -0.7112600000    -0.5259300000  \n",
       "50%      -0.0172900000    -0.0066500000    -0.2171200000     0.0798700000  \n",
       "75%       0.7609600000     0.5848900000     0.5297500000     0.7654000000  \n",
       "max       3.4643600000     3.4643600000     2.9016100000     1.9217300000  "
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug_numeric = df_drug\n",
    "df_drug_numeric.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the numeric data appears to be z-score normalized.  That said, I disagree with some the decisions made by the designers, and comparing these to the categorical variables may prove difficult.  Let's go through each variable:\n",
    "\n",
    "Age: age data is binned, specifically 18-24, 25-34, 35-44, 45-54, 55-64, and 65+.  \n",
    "\n",
    "Gender: The survey had very similar numbers of men and women.  Men are -.482 and women are +.482.\n",
    "\n",
    "Education: these are in bins on a scale from drop out before age 16 to doctorate degree.  The order is logical.\n",
    "\n",
    "Country: these values don't make sense, as they are on a scale where, for instance, the US is further from New Zealand than it is from Australia.  The ordering has no logical function and would confuse analysis.  A better solution is dummy variables for each country.  \n",
    "\n",
    "Ethnicity: these values also don't make sense.  For instance, mixed black/Asian is closer to white than black or Asian.  The order of the scale makes no logical sense.  A better solution is dummy variables.\n",
    "\n",
    "The remaining scores are scales from tests for neuroticism, extraversion, openness to experience, agreeableness, contientousness, impulsivenss, and sensation.  The scales make sense.\n",
    "\n",
    "Keeping some of these scores is problematic.  For instance, there are very few respondents from New Zealand, so applying a z-score to a 1/0 dummy New Zealand yields much higher valuyes than being from the UK or US wuld do.  Thus, it makes sense to convert these back to their original numbers and use 0/1 scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-24    637\n",
      "25-34    480\n",
      "35-44    355\n",
      "45-54    294\n",
      "55-64     93\n",
      "65+       18\n",
      "Name: Age, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>...</th>\n",
       "      <th>Esctacy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Education  Country  Ethnicity  N_Score  E_Score  O_Score  A_Score  \\\n",
       "0  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545 -0.58331 -0.91699   \n",
       "1 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533  0.76096   \n",
       "2 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732 -1.62090   \n",
       "3  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928  0.59042   \n",
       "4  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174 -0.30172   \n",
       "\n",
       "   C_Score  Impulsivenesss  ...    Esctacy Heroin Ketamine Legal_highs  LSD  \\\n",
       "0 -0.00665        -0.21712  ...        CL0    CL0      CL0         CL0  CL0   \n",
       "1 -0.14277        -0.71126  ...        CL4    CL0      CL2         CL0  CL2   \n",
       "2 -1.01450        -1.37983  ...        CL0    CL0      CL0         CL0  CL0   \n",
       "3  0.58489        -1.37983  ...        CL0    CL0      CL2         CL0  CL0   \n",
       "4  1.30612        -0.21712  ...        CL1    CL0      CL0         CL1  CL0   \n",
       "\n",
       "  Meth Mushrooms Nicotine  VSA    Age  \n",
       "0  CL0       CL0      CL2  CL0  35-44  \n",
       "1  CL3       CL0      CL4  CL0  25-34  \n",
       "2  CL0       CL1      CL0  CL0  35-44  \n",
       "3  CL0       CL0      CL2  CL0  18-24  \n",
       "4  CL0       CL2      CL2  CL0  35-44  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert age bins\n",
    "age_convert = df_drug.loc[:,'Age'].astype(str)   #dfmi.loc[:,('one','second')]\n",
    "age_convert = age_convert.replace({  '-0.95197' : '18-24',\n",
    "'-0.07854' : '25-34',\n",
    "'0.49788' : '35-44', \n",
    "'1.09449' : '45-54', \n",
    "'1.82213' : '55-64', \n",
    "'2.59171' : '65+'  })\n",
    "\n",
    "\n",
    "del df_drug_numeric['Age']\n",
    "df_drug_numeric = pd.concat([df_drug_numeric, age_convert], axis=1, copy=False)\n",
    "\n",
    "#df_drug_numeric.loc[:,'Age'] = age_convert.astype(str)\n",
    "print(df_drug_numeric.Age.value_counts())\n",
    "df_drug_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert gender back to a categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male      940\n",
      "Female    937\n",
      "Name: Gender, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "      <th>...</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  Country  Ethnicity  N_Score  E_Score  O_Score  A_Score  C_Score  \\\n",
       "0   -0.05921  0.96082    0.12600  0.31287 -0.57545 -0.58331 -0.91699 -0.00665   \n",
       "1    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533  0.76096 -0.14277   \n",
       "2   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732 -1.62090 -1.01450   \n",
       "3    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928  0.59042  0.58489   \n",
       "4    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174 -0.30172  1.30612   \n",
       "\n",
       "   Impulsivenesss       SS   ...   Heroin Ketamine Legal_highs  LSD Meth  \\\n",
       "0        -0.21712 -1.18084   ...      CL0      CL0         CL0  CL0  CL0   \n",
       "1        -0.71126 -0.21575   ...      CL0      CL2         CL0  CL2  CL3   \n",
       "2        -1.37983  0.40148   ...      CL0      CL0         CL0  CL0  CL0   \n",
       "3        -1.37983 -1.18084   ...      CL0      CL2         CL0  CL0  CL0   \n",
       "4        -0.21712 -0.21575   ...      CL0      CL0         CL1  CL0  CL0   \n",
       "\n",
       "  Mushrooms Nicotine  VSA    Age  Gender  \n",
       "0       CL0      CL2  CL0  35-44  Female  \n",
       "1       CL0      CL4  CL0  25-34    Male  \n",
       "2       CL1      CL0  CL0  35-44    Male  \n",
       "3       CL0      CL2  CL0  18-24  Female  \n",
       "4       CL2      CL2  CL0  35-44  Female  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert gender bins\n",
    "gender_convert = df_drug.loc[:,'Gender'].astype(str)   #dfmi.loc[:,('one','second')]\n",
    "gender_convert = gender_convert.replace({ '0.48246' : 'Female',\n",
    "'-0.48246' : 'Male'   })\n",
    "\n",
    "del df_drug_numeric['Gender']\n",
    "df_drug_numeric = pd.concat([df_drug_numeric, gender_convert], axis=1, copy=False)\n",
    "print(df_drug_numeric.Gender.value_counts())\n",
    "df_drug_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert education to where they were binned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    503\n",
      "7.0    478\n",
      "8.0    283\n",
      "6.0    270\n",
      "4.0     99\n",
      "2.0     98\n",
      "9.0     89\n",
      "3.0     29\n",
      "1.0     28\n",
      "Name: Education, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>...</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL5</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL5</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Male</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL6</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Male</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL4</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Female</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Ethnicity  N_Score  E_Score  O_Score  A_Score  C_Score  \\\n",
       "0  0.96082    0.12600  0.31287 -0.57545 -0.58331 -0.91699 -0.00665   \n",
       "1  0.96082   -0.31685 -0.67825  1.93886  1.43533  0.76096 -0.14277   \n",
       "2  0.96082   -0.31685 -0.46725  0.80523 -0.84732 -1.62090 -1.01450   \n",
       "3  0.96082   -0.31685 -0.14882 -0.80615 -0.01928  0.59042  0.58489   \n",
       "4  0.96082   -0.31685  0.73545 -1.63340 -0.45174 -0.30172  1.30612   \n",
       "\n",
       "   Impulsivenesss       SS Alcohol    ...    Ketamine Legal_highs  LSD Meth  \\\n",
       "0        -0.21712 -1.18084     CL5    ...         CL0         CL0  CL0  CL0   \n",
       "1        -0.71126 -0.21575     CL5    ...         CL2         CL0  CL2  CL3   \n",
       "2        -1.37983  0.40148     CL6    ...         CL0         CL0  CL0  CL0   \n",
       "3        -1.37983 -1.18084     CL4    ...         CL2         CL0  CL0  CL0   \n",
       "4        -0.21712 -0.21575     CL4    ...         CL0         CL1  CL0  CL0   \n",
       "\n",
       "  Mushrooms Nicotine  VSA    Age  Gender Education  \n",
       "0       CL0      CL2  CL0  35-44  Female       6.0  \n",
       "1       CL0      CL4  CL0  25-34    Male       9.0  \n",
       "2       CL1      CL0  CL0  35-44    Male       6.0  \n",
       "3       CL0      CL2  CL0  18-24  Female       8.0  \n",
       "4       CL2      CL2  CL0  35-44  Female       9.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert education bins\n",
    "Education_convert = df_drug.loc[:,'Education']   #dfmi.loc[:,('one','second')]\n",
    "Education_convert = Education_convert * 100\n",
    "Education_convert = Education_convert.round()\n",
    "Education_convert = Education_convert.replace({  -244 : 1, -174 : 2, -144 : 3, -123 : 4,\n",
    "                                               -61 : 5, -6 : 6, 45 : 7, 116 : 8, 198 : 9 })\n",
    " \n",
    "#pd.set_option('precision', 10)\n",
    "del df_drug_numeric['Education']\n",
    "df_drug_numeric = pd.concat([df_drug_numeric, Education_convert], axis=1, copy=False)\n",
    "#df_drug_numeric.loc[:,'Education'] = Education_convert.astype(str)\n",
    "print(df_drug_numeric.Education.value_counts())\n",
    "#pd.set_option('precision', 10)\n",
    "df_drug_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert the country to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK               1044\n",
      "USA               551\n",
      "Other_Country     118\n",
      "Canada             87\n",
      "Australia          52\n",
      "Ireland            20\n",
      "New Zealand         5\n",
      "Name: Country, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Amphetamine</th>\n",
       "      <th>...</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Male</td>\n",
       "      <td>6.0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL1</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ethnicity  N_Score  E_Score  O_Score  A_Score  C_Score  Impulsivenesss  \\\n",
       "0    0.12600  0.31287 -0.57545 -0.58331 -0.91699 -0.00665        -0.21712   \n",
       "1   -0.31685 -0.67825  1.93886  1.43533  0.76096 -0.14277        -0.71126   \n",
       "2   -0.31685 -0.46725  0.80523 -0.84732 -1.62090 -1.01450        -1.37983   \n",
       "3   -0.31685 -0.14882 -0.80615 -0.01928  0.59042  0.58489        -1.37983   \n",
       "4   -0.31685  0.73545 -1.63340 -0.45174 -0.30172  1.30612        -0.21712   \n",
       "\n",
       "        SS Alcohol Amphetamine   ...   Legal_highs  LSD Meth Mushrooms  \\\n",
       "0 -1.18084     CL5         CL2   ...           CL0  CL0  CL0       CL0   \n",
       "1 -0.21575     CL5         CL2   ...           CL0  CL2  CL3       CL0   \n",
       "2  0.40148     CL6         CL0   ...           CL0  CL0  CL0       CL1   \n",
       "3 -1.18084     CL4         CL0   ...           CL0  CL0  CL0       CL0   \n",
       "4 -0.21575     CL4         CL1   ...           CL1  CL0  CL0       CL2   \n",
       "\n",
       "  Nicotine  VSA    Age  Gender Education Country  \n",
       "0      CL2  CL0  35-44  Female       6.0      UK  \n",
       "1      CL4  CL0  25-34    Male       9.0      UK  \n",
       "2      CL0  CL0  35-44    Male       6.0      UK  \n",
       "3      CL2  CL0  18-24  Female       8.0      UK  \n",
       "4      CL2  CL0  35-44  Female       9.0      UK  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "country_convert = df_drug.loc[:,'Country'].astype(str)   #dfmi.loc[:,('one','second')]\n",
    "#country_convert = country_convert.replace({'Country' : {  '-0.09765' : 'Australia', '0.24923' : 'Canada', '-0.46841' : 'New Zealand',\n",
    "#                                      '-0.28519' : 'Other_Country', '0.21128' : 'Ireland', '0.96082' : 'UK',\n",
    "#                                      '-0.57009' : 'USA'  }})\n",
    "#country_convert = country_convert.replace({'Country' : {  -0.09765 : 'Australia', 0.24923 : 'Canada', -0.46841 : 'New Zealand',\n",
    "#                                      -0.28519 : 'Other_Country', 0.21128 : 'Ireland', 0.96082 : 'UK',\n",
    "#                                      -0.57009 : 'USA'  }})\n",
    "country_convert_names = country_convert.replace({  '-0.09765' : 'Australia', '0.24923' : 'Canada', '-0.46841' : 'New Zealand',\n",
    "                                      '-0.28519' : 'Other_Country', '0.21128' : 'Ireland', '0.96082' : 'UK',\n",
    "                                      '-0.57009' : 'USA'  })\n",
    "#country_convert\n",
    "del df_drug_numeric['Country']\n",
    "\n",
    "df_drug_numeric = pd.concat([df_drug_numeric, country_convert_names], axis=1, copy=False)\n",
    "\n",
    "#df_drug_numeric.loc[:,'Cty'] = country_convert_names.astype(str)\n",
    "print(df_drug_numeric.Country.value_counts())\n",
    "df_drug_numeric.head(5)\n",
    "\n",
    "#df_drug_numeric.loc[:,'Country'] = country_convert.apply(str)\n",
    "#df_drug_numeric.loc[:,'Countries'].value_counts() #verify\n",
    "#country_convert.dtypes\n",
    "#country_convert.value_counts()\n",
    "#df_drug_numeric.loc[:,'Country'] = 0\n",
    "#df_drug_numeric.loc[:,'Country'] = df_drug_numeric.loc[:,'Country'].astype('category')\n",
    "#country_convert = country_convert.replace({'Country' : {  '-0.09765' : 'Australia', '0.24923' : 'Canada', '-0.46841' : 'New Zealand',\n",
    "#                                      '-0.28519' : 'Other_Country', '0.21128' : 'Ireland', '0.96082' : 'UK',\n",
    "#                                      '-0.57009' : 'USA'  }})\n",
    "\n",
    "\n",
    "#train_class_convert = df_train['Income_Class'].astype(str) #changes to string so we can change on the next line of code\n",
    "#train_class_convert = train_class_convert.str.replace('>50K', '1') \n",
    "#train_class_convert = train_class_convert.str.replace('<=50K', '0')\n",
    "#df_train_num['Income_Class'] = train_class_convert.astype(int) #changes to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert ethnicity to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White                1715\n",
      "Other                  62\n",
      "Black                  33\n",
      "Asian                  25\n",
      "Mixed-White/Asian      20\n",
      "Mixed-White/Black      19\n",
      "Mixed-Black/Asian       3\n",
      "Name: Ethnicity, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Amphetamine</th>\n",
       "      <th>Amyl</th>\n",
       "      <th>...</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mixed-White/Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Male</td>\n",
       "      <td>6.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_Score  E_Score  O_Score  A_Score  C_Score  Impulsivenesss       SS  \\\n",
       "0  0.31287 -0.57545 -0.58331 -0.91699 -0.00665        -0.21712 -1.18084   \n",
       "1 -0.67825  1.93886  1.43533  0.76096 -0.14277        -0.71126 -0.21575   \n",
       "2 -0.46725  0.80523 -0.84732 -1.62090 -1.01450        -1.37983  0.40148   \n",
       "3 -0.14882 -0.80615 -0.01928  0.59042  0.58489        -1.37983 -1.18084   \n",
       "4  0.73545 -1.63340 -0.45174 -0.30172  1.30612        -0.21712 -0.21575   \n",
       "\n",
       "  Alcohol Amphetamine Amyl        ...          LSD Meth Mushrooms Nicotine  \\\n",
       "0     CL5         CL2  CL0        ...          CL0  CL0       CL0      CL2   \n",
       "1     CL5         CL2  CL2        ...          CL2  CL3       CL0      CL4   \n",
       "2     CL6         CL0  CL0        ...          CL0  CL0       CL1      CL0   \n",
       "3     CL4         CL0  CL0        ...          CL0  CL0       CL0      CL2   \n",
       "4     CL4         CL1  CL1        ...          CL0  CL0       CL2      CL2   \n",
       "\n",
       "   VSA    Age  Gender Education Country          Ethnicity  \n",
       "0  CL0  35-44  Female       6.0      UK  Mixed-White/Asian  \n",
       "1  CL0  25-34    Male       9.0      UK              White  \n",
       "2  CL0  35-44    Male       6.0      UK              White  \n",
       "3  CL0  18-24  Female       8.0      UK              White  \n",
       "4  CL0  35-44  Female       9.0      UK              White  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_convert = df_drug.loc[:,'Ethnicity'].astype(str)\n",
    "ethnicity_convert_names = ethnicity_convert.replace({  '-0.50212' : 'Asian', \n",
    "                                                          '-1.10702' : 'Black',\n",
    "                                                          '1.90725' : 'Mixed-Black/Asian', \n",
    "                                                          '0.126' : 'Mixed-White/Asian', \n",
    "                                                          '-0.22166' : 'Mixed-White/Black',\n",
    "                                                          '0.1144' : 'Other', \n",
    "                                                          '-0.31685' : 'White'  })\n",
    "del df_drug_numeric['Ethnicity']\n",
    "df_drug_numeric = pd.concat([df_drug_numeric, ethnicity_convert_names], axis=1, copy=False)\n",
    "\n",
    "print(df_drug_numeric.Ethnicity.value_counts()) #verify\n",
    "df_drug_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_scores = df_drug_numeric.iloc[:,0:7]\n",
    "#z_scores\n",
    "#original_scores = z_scores * z_scores.std(ddof=0) + z_scores.mean()\n",
    "#original_scores\n",
    "#z_scores = (z_scores - z_scores.mean())/z_scores.std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create dummy variables for age, gender, country, and ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N_Score',\n",
       " 'E_Score',\n",
       " 'O_Score',\n",
       " 'A_Score',\n",
       " 'C_Score',\n",
       " 'Impulsivenesss',\n",
       " 'SS',\n",
       " 'Alcohol',\n",
       " 'Amphetamine',\n",
       " 'Amyl',\n",
       " 'Benzos',\n",
       " 'Caffeine',\n",
       " 'Cannibis',\n",
       " 'Chocolate',\n",
       " 'Cocaine',\n",
       " 'Crack',\n",
       " 'Esctacy',\n",
       " 'Heroin',\n",
       " 'Ketamine',\n",
       " 'Legal_highs',\n",
       " 'LSD',\n",
       " 'Meth',\n",
       " 'Mushrooms',\n",
       " 'Nicotine',\n",
       " 'VSA',\n",
       " 'Education',\n",
       " 'Age_18-24',\n",
       " 'Age_25-34',\n",
       " 'Age_35-44',\n",
       " 'Age_45-54',\n",
       " 'Age_55-64',\n",
       " 'Age_65+',\n",
       " 'Gender_Female',\n",
       " 'Gender_Male',\n",
       " 'Country_Australia',\n",
       " 'Country_Canada',\n",
       " 'Country_Ireland',\n",
       " 'Country_New Zealand',\n",
       " 'Country_Other_Country',\n",
       " 'Country_UK',\n",
       " 'Country_USA',\n",
       " 'Ethnicity_Asian',\n",
       " 'Ethnicity_Black',\n",
       " 'Ethnicity_Mixed-Black/Asian',\n",
       " 'Ethnicity_Mixed-White/Asian',\n",
       " 'Ethnicity_Mixed-White/Black',\n",
       " 'Ethnicity_Other',\n",
       " 'Ethnicity_White']"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform data transformation. Creates dummies of any categorical feature\n",
    "for col in df_drug_numeric.columns[25:]:\n",
    "\tattName = col\n",
    "\tdType = df_drug_numeric[col].dtype\n",
    "\tmissing = pd.isnull(df_drug_numeric[col]).any()\n",
    "\tuniqueCount = len(df_drug_numeric[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf_drug_numeric = pd.concat([df_drug_numeric, pd.get_dummies(df_drug_numeric[col], prefix=col)], axis=1)\n",
    "\t\tdel df_drug_numeric[attName]\n",
    "list(df_drug_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert the drug use categories to actual numbers 0 through 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N_Score', 'E_Score', 'O_Score', 'A_Score', 'C_Score', 'Impulsivenesss', 'SS', 'Education', 'Age_18-24', 'Age_25-34', 'Age_35-44', 'Age_45-54', 'Age_55-64', 'Age_65+', 'Gender_Female', 'Gender_Male', 'Country_Australia', 'Country_Canada', 'Country_Ireland', 'Country_New Zealand', 'Country_Other_Country', 'Country_UK', 'Country_USA', 'Ethnicity_Asian', 'Ethnicity_Black', 'Ethnicity_Mixed-Black/Asian', 'Ethnicity_Mixed-White/Asian', 'Ethnicity_Mixed-White/Black', 'Ethnicity_Other', 'Ethnicity_White', 'Alcohol', 'Amphetamine', 'Amyl', 'Benzos', 'Caffeine', 'Cannibis', 'Chocolate', 'Cocaine', 'Crack', 'Esctacy', 'Heroin', 'Ketamine', 'Legal_highs', 'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'VSA']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "      <th>Education</th>\n",
       "      <th>Age_18-24</th>\n",
       "      <th>Age_25-34</th>\n",
       "      <th>...</th>\n",
       "      <th>Crack</th>\n",
       "      <th>Esctacy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legal_highs</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.67825</td>\n",
       "      <td>-0.30033</td>\n",
       "      <td>-1.55521</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.54858</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>-1.09207</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>0.93949</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.32828</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>0.19268</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.62967</td>\n",
       "      <td>2.57309</td>\n",
       "      <td>-0.97631</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>1.13407</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.54858</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.24649</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>-1.42424</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.12331</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-0.84637</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.05308</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-1.11902</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>1.81175</td>\n",
       "      <td>0.19268</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.32828</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.14143</td>\n",
       "      <td>-1.92595</td>\n",
       "      <td>-0.52745</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.28554</td>\n",
       "      <td>0.16767</td>\n",
       "      <td>0.44585</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-0.78155</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.79151</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.94156</td>\n",
       "      <td>3.46436</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.84637</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.92104</td>\n",
       "      <td>1.45421</td>\n",
       "      <td>0.44585</td>\n",
       "      <td>-0.60633</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>-1.05308</td>\n",
       "      <td>0.96248</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>1.81866</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1.02119</td>\n",
       "      <td>-0.43999</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>-1.07533</td>\n",
       "      <td>0.12331</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>-0.79151</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>2.44904</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.23177</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>-0.60633</td>\n",
       "      <td>-0.40581</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>2.12700</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>2.44904</td>\n",
       "      <td>0.94156</td>\n",
       "      <td>-0.65253</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.76250</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.78155</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1.49158</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.76250</td>\n",
       "      <td>0.88309</td>\n",
       "      <td>-0.76096</td>\n",
       "      <td>2.33337</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>-0.79151</td>\n",
       "      <td>0.32197</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>-0.27607</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      N_Score  E_Score  O_Score  A_Score  C_Score  Impulsivenesss       SS  \\\n",
       "0     0.31287 -0.57545 -0.58331 -0.91699 -0.00665        -0.21712 -1.18084   \n",
       "1    -0.67825  1.93886  1.43533  0.76096 -0.14277        -0.71126 -0.21575   \n",
       "2    -0.46725  0.80523 -0.84732 -1.62090 -1.01450        -1.37983  0.40148   \n",
       "3    -0.14882 -0.80615 -0.01928  0.59042  0.58489        -1.37983 -1.18084   \n",
       "4     0.73545 -1.63340 -0.45174 -0.30172  1.30612        -0.21712 -0.21575   \n",
       "5    -0.67825 -0.30033 -1.55521  2.03972  1.63088        -1.37983 -1.54858   \n",
       "6    -0.46725 -1.09207 -0.45174 -0.30172  0.93949        -0.21712  0.07987   \n",
       "7    -1.32828  1.93886 -0.84732 -0.30172  1.63088         0.19268 -0.52593   \n",
       "8     0.62967  2.57309 -0.97631  0.76096  1.13407        -1.37983 -1.54858   \n",
       "9    -0.24649  0.00332 -1.42424  0.59042  0.12331        -1.37983 -0.84637   \n",
       "10   -1.05308  0.80523 -1.11902 -0.76096  1.81175         0.19268  0.07987   \n",
       "11   -1.32828  0.00332  0.14143 -1.92595 -0.52745         0.52975  1.22470   \n",
       "12    2.28554  0.16767  0.44585 -1.62090 -0.78155         1.29221  0.07987   \n",
       "13   -0.79151  0.80523 -0.01928  0.94156  3.46436        -0.71126 -0.84637   \n",
       "14   -0.92104  1.45421  0.44585 -0.60633  1.63088         1.29221  0.76540   \n",
       "...       ...      ...      ...      ...      ...             ...      ...   \n",
       "1862 -1.05308  0.96248  1.88511  1.81866  1.30612        -0.71126  0.07987   \n",
       "1863  1.02119 -0.43999  1.43533 -1.07533  0.12331        -0.71126  0.40148   \n",
       "1864 -0.79151  0.00332  2.44904  0.76096 -1.51840         0.88113  1.92173   \n",
       "1865  0.73545 -1.23177  0.58331 -0.60633 -0.40581         0.52975  0.40148   \n",
       "1866  2.12700 -0.15487  2.44904  0.94156 -0.65253        -0.21712  0.07987   \n",
       "1867 -0.05188 -1.76250  0.58331 -0.76096 -0.14277         1.29221  1.22470   \n",
       "1868 -0.14882 -0.57545  1.43533 -0.91699 -0.78155         0.52975  0.40148   \n",
       "1869  1.49158 -1.92173 -0.58331 -1.77200  0.58489        -0.21712  1.22470   \n",
       "1870 -0.05188 -1.76250  0.88309 -0.76096  2.33337        -0.71126 -0.21575   \n",
       "1871 -0.79151  0.32197  0.29338 -0.30172 -0.27607         0.88113  0.76540   \n",
       "1872 -1.19430  1.74091  1.88511  0.76096 -1.13788         0.88113  1.92173   \n",
       "1873 -0.24649  1.74091  0.58331  0.76096 -1.51840         0.88113  0.76540   \n",
       "1874  1.13281 -1.37639 -1.27553 -1.77200 -1.38502         0.52975 -0.52593   \n",
       "1875  0.91093 -1.92173  0.29338 -1.62090 -2.57309         1.29221  1.22470   \n",
       "1876 -0.46725  2.12700  1.65653  1.11406  0.41594         0.88113  1.22470   \n",
       "\n",
       "      Education  Age_18-24  Age_25-34 ...   Crack  Esctacy  Heroin  Ketamine  \\\n",
       "0           6.0          0          0 ...       0        0       0         0   \n",
       "1           9.0          0          1 ...       0        4       0         2   \n",
       "2           6.0          0          0 ...       0        0       0         0   \n",
       "3           8.0          1          0 ...       0        0       0         2   \n",
       "4           9.0          0          0 ...       0        1       0         0   \n",
       "5           4.0          0          0 ...       0        0       0         0   \n",
       "6           8.0          0          0 ...       0        0       0         0   \n",
       "7           2.0          0          0 ...       0        0       0         0   \n",
       "8           6.0          0          0 ...       0        0       0         0   \n",
       "9           8.0          0          0 ...       0        0       0         0   \n",
       "10          7.0          0          1 ...       0        0       0         0   \n",
       "11          5.0          0          0 ...       0        3       0         0   \n",
       "12          7.0          0          0 ...       0        0       0         0   \n",
       "13          6.0          0          0 ...       0        0       0         0   \n",
       "14          6.0          0          0 ...       0        0       0         0   \n",
       "...         ...        ...        ... ...     ...      ...     ...       ...   \n",
       "1862        7.0          0          1 ...       0        3       0         0   \n",
       "1863        4.0          1          0 ...       3        3       6         3   \n",
       "1864        5.0          1          0 ...       0        2       0         2   \n",
       "1865        3.0          1          0 ...       2        3       2         0   \n",
       "1866        5.0          0          0 ...       0        0       0         0   \n",
       "1867        5.0          1          0 ...       0        5       0         0   \n",
       "1868        5.0          0          1 ...       0        3       0         3   \n",
       "1869        3.0          1          0 ...       0        2       5         0   \n",
       "1870        7.0          1          0 ...       0        0       0         0   \n",
       "1871        5.0          1          0 ...       0        5       2         0   \n",
       "1872        5.0          1          0 ...       0        0       0         0   \n",
       "1873        5.0          1          0 ...       0        2       0         0   \n",
       "1874        7.0          0          1 ...       0        4       0         2   \n",
       "1875        5.0          1          0 ...       0        3       0         0   \n",
       "1876        5.0          1          0 ...       0        3       0         0   \n",
       "\n",
       "      Legal_highs  LSD  Meth  Mushrooms  Nicotine  VSA  \n",
       "0               0    0     0          0         2    0  \n",
       "1               0    2     3          0         4    0  \n",
       "2               0    0     0          1         0    0  \n",
       "3               0    0     0          0         2    0  \n",
       "4               1    0     0          2         2    0  \n",
       "5               0    0     0          0         6    0  \n",
       "6               0    0     0          0         6    0  \n",
       "7               0    0     0          0         0    0  \n",
       "8               0    0     0          0         6    0  \n",
       "9               0    0     0          0         6    0  \n",
       "10              0    0     0          0         2    1  \n",
       "11              0    1     0          2         6    0  \n",
       "12              0    1     1          1         6    0  \n",
       "13              0    0     0          0         1    0  \n",
       "14              0    0     0          0         6    0  \n",
       "...           ...  ...   ...        ...       ...  ...  \n",
       "1862            0    3     0          1         5    0  \n",
       "1863            5    3     3          0         6    6  \n",
       "1864            2    0     0          0         0    0  \n",
       "1865            5    2     2          3         6    2  \n",
       "1866            0    1     0          1         0    0  \n",
       "1867            2    4     0          4         6    2  \n",
       "1868            5    3     0          4         2    2  \n",
       "1869            2    0     6          0         6    2  \n",
       "1870            2    0     0          2         2    0  \n",
       "1871            4    5     4          0         6    1  \n",
       "1872            3    3     0          0         0    5  \n",
       "1873            3    5     4          4         5    0  \n",
       "1874            0    2     0          2         6    0  \n",
       "1875            3    3     0          3         4    0  \n",
       "1876            3    3     0          3         6    2  \n",
       "\n",
       "[1877 rows x 48 columns]"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug_use = df_drug_object_only.astype(str)\n",
    "df_drug_use = df_drug_use.replace({  'CL0' : '0', \n",
    "                                    'CL1' : '1',\n",
    "                                    'CL2' : '2', \n",
    "                                    'CL3' : '3', \n",
    "                                    'CL4' : '4',\n",
    "                                    'CL5' : '5', \n",
    "                                    'CL6' : '6'  })\n",
    "#df_drug_use\n",
    "#df_drug_numeric = df_drug_numeric[0:9, 30:]\n",
    "#colsToDrop = [10:29]\n",
    "df_drug_use_int = df_drug_use.astype(int)\n",
    "df_drug_numeric = df_drug_numeric.drop(['Alcohol','Amphetamine','Amyl',\n",
    "                              'Benzos','Caffeine','Cannibis','Chocolate','Cocaine','Crack','Esctacy','Heroin',\n",
    "                              'Ketamine','Legal_highs','LSD','Meth','Mushrooms','Nicotine','VSA'], axis=1)\n",
    "df_drug_numeric = pd.concat([df_drug_numeric, df_drug_use_int], axis=1, copy=False)\n",
    "print(list(df_drug_numeric))\n",
    "df_drug_numeric\n",
    "#df_train_num['Income_Class'] = train_class_convert.astype(int)\n",
    "#list(df_drug_numeric)\n",
    "#df_drug_numeric[:,10:29] = df_drug_use.astype(int)\n",
    "#df_drug_numeric[:,10:29].head(5)\n",
    "\n",
    "#df_drug_object_only.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Type N_Score                        float64\n",
      "E_Score                        float64\n",
      "O_Score                        float64\n",
      "A_Score                        float64\n",
      "C_Score                        float64\n",
      "Impulsivenesss                 float64\n",
      "SS                             float64\n",
      "Education                      float64\n",
      "Age_18-24                        uint8\n",
      "Age_25-34                        uint8\n",
      "Age_35-44                        uint8\n",
      "Age_45-54                        uint8\n",
      "Age_55-64                        uint8\n",
      "Age_65+                          uint8\n",
      "Gender_Female                    uint8\n",
      "Gender_Male                      uint8\n",
      "Country_Australia                uint8\n",
      "Country_Canada                   uint8\n",
      "Country_Ireland                  uint8\n",
      "Country_New Zealand              uint8\n",
      "Country_Other_Country            uint8\n",
      "Country_UK                       uint8\n",
      "Country_USA                      uint8\n",
      "Ethnicity_Asian                  uint8\n",
      "Ethnicity_Black                  uint8\n",
      "Ethnicity_Mixed-Black/Asian      uint8\n",
      "Ethnicity_Mixed-White/Asian      uint8\n",
      "Ethnicity_Mixed-White/Black      uint8\n",
      "Ethnicity_Other                  uint8\n",
      "Ethnicity_White                  uint8\n",
      "Alcohol                          int32\n",
      "Amphetamine                      int32\n",
      "Amyl                             int32\n",
      "Benzos                           int32\n",
      "Caffeine                         int32\n",
      "Cannibis                         int32\n",
      "Chocolate                        int32\n",
      "Cocaine                          int32\n",
      "Crack                            int32\n",
      "Esctacy                          int32\n",
      "Heroin                           int32\n",
      "Ketamine                         int32\n",
      "Legal_highs                      int32\n",
      "LSD                              int32\n",
      "Meth                             int32\n",
      "Mushrooms                        int32\n",
      "Nicotine                         int32\n",
      "VSA                              int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 48\n",
    "print(\"Training Data Type\", df_drug_numeric.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're interested in drugs as a whole, let's create a summary column of all drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1877.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.3521576985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.9731498097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.0000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             All_Drugs\n",
       "count  1877.0000000000\n",
       "mean     33.3521576985\n",
       "std      14.9731498097\n",
       "min       0.0000000000\n",
       "25%      20.0000000000\n",
       "50%      31.0000000000\n",
       "75%      44.0000000000\n",
       "max      80.0000000000"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_drugs = pd.DataFrame(df_drug_use_int.sum(axis=1), columns = ['All_Drugs'])\n",
    "#all_drugs.dtypes\n",
    "all_drugs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll divide the respondents into two drug classes, low and high.  Low will have a total score of 30 and below, High 31 and up, so the two should be roughly equal in size.  We'll encode the two as 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    970\n",
      "0    907\n",
      "Name: All_Drugs_Cat, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_Drugs_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   All_Drugs_Cat\n",
       "0              0\n",
       "1              1\n",
       "2              0\n",
       "3              0\n",
       "4              0"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_drugs_cat = pd.DataFrame(np.where(all_drugs['All_Drugs']>=31, 1, 0), columns = ['All_Drugs_Cat'])\n",
    "print(all_drugs_cat.All_Drugs_Cat.value_counts())\n",
    "all_drugs_cat.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the all_drugs_cat column to the data frame and drop the individual drug columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N_Score                        0\n",
       "E_Score                        0\n",
       "O_Score                        0\n",
       "A_Score                        0\n",
       "C_Score                        0\n",
       "Impulsivenesss                 0\n",
       "SS                             0\n",
       "Education                      0\n",
       "Age_18-24                      0\n",
       "Age_25-34                      0\n",
       "Age_35-44                      0\n",
       "Age_45-54                      0\n",
       "Age_55-64                      0\n",
       "Age_65+                        0\n",
       "Gender_Female                  0\n",
       "Gender_Male                    0\n",
       "Country_Australia              0\n",
       "Country_Canada                 0\n",
       "Country_Ireland                0\n",
       "Country_New Zealand            0\n",
       "Country_Other_Country          0\n",
       "Country_UK                     0\n",
       "Country_USA                    0\n",
       "Ethnicity_Asian                0\n",
       "Ethnicity_Black                0\n",
       "Ethnicity_Mixed-Black/Asian    0\n",
       "Ethnicity_Mixed-White/Asian    0\n",
       "Ethnicity_Mixed-White/Black    0\n",
       "Ethnicity_Other                0\n",
       "Ethnicity_White                0\n",
       "Alcohol                        0\n",
       "Amphetamine                    0\n",
       "Amyl                           0\n",
       "Benzos                         0\n",
       "Caffeine                       0\n",
       "Cannibis                       0\n",
       "Chocolate                      0\n",
       "Cocaine                        0\n",
       "Crack                          0\n",
       "Esctacy                        0\n",
       "Heroin                         0\n",
       "Ketamine                       0\n",
       "Legal_highs                    0\n",
       "LSD                            0\n",
       "Meth                           0\n",
       "Mushrooms                      0\n",
       "Nicotine                       0\n",
       "VSA                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug_numeric.isnull().sum()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1877, 48)"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N_Score', 'E_Score', 'O_Score', 'A_Score', 'C_Score', 'Impulsivenesss', 'SS', 'Education', 'Age_18-24', 'Age_25-34', 'Age_35-44', 'Age_45-54', 'Age_55-64', 'Age_65+', 'Gender_Female', 'Gender_Male', 'Country_Australia', 'Country_Canada', 'Country_Ireland', 'Country_New Zealand', 'Country_Other_Country', 'Country_UK', 'Country_USA', 'Ethnicity_Asian', 'Ethnicity_Black', 'Ethnicity_Mixed-Black/Asian', 'Ethnicity_Mixed-White/Asian', 'Ethnicity_Mixed-White/Black', 'Ethnicity_Other', 'Ethnicity_White', 'All_Drugs_Cat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "      <th>Education</th>\n",
       "      <th>Age_18-24</th>\n",
       "      <th>Age_25-34</th>\n",
       "      <th>...</th>\n",
       "      <th>Country_UK</th>\n",
       "      <th>Country_USA</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Mixed-Black/Asian</th>\n",
       "      <th>Ethnicity_Mixed-White/Asian</th>\n",
       "      <th>Ethnicity_Mixed-White/Black</th>\n",
       "      <th>Ethnicity_Other</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "      <th>All_Drugs_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      N_Score  E_Score  O_Score  A_Score  C_Score  Impulsivenesss       SS  \\\n",
       "0     0.31287 -0.57545 -0.58331 -0.91699 -0.00665        -0.21712 -1.18084   \n",
       "1    -0.67825  1.93886  1.43533  0.76096 -0.14277        -0.71126 -0.21575   \n",
       "2    -0.46725  0.80523 -0.84732 -1.62090 -1.01450        -1.37983  0.40148   \n",
       "3    -0.14882 -0.80615 -0.01928  0.59042  0.58489        -1.37983 -1.18084   \n",
       "4     0.73545 -1.63340 -0.45174 -0.30172  1.30612        -0.21712 -0.21575   \n",
       "...       ...      ...      ...      ...      ...             ...      ...   \n",
       "1872 -1.19430  1.74091  1.88511  0.76096 -1.13788         0.88113  1.92173   \n",
       "1873 -0.24649  1.74091  0.58331  0.76096 -1.51840         0.88113  0.76540   \n",
       "1874  1.13281 -1.37639 -1.27553 -1.77200 -1.38502         0.52975 -0.52593   \n",
       "1875  0.91093 -1.92173  0.29338 -1.62090 -2.57309         1.29221  1.22470   \n",
       "1876 -0.46725  2.12700  1.65653  1.11406  0.41594         0.88113  1.22470   \n",
       "\n",
       "      Education  Age_18-24  Age_25-34      ...        Country_UK  Country_USA  \\\n",
       "0           6.0          0          0      ...                 1            0   \n",
       "1           9.0          0          1      ...                 1            0   \n",
       "2           6.0          0          0      ...                 1            0   \n",
       "3           8.0          1          0      ...                 1            0   \n",
       "4           9.0          0          0      ...                 1            0   \n",
       "...         ...        ...        ...      ...               ...          ...   \n",
       "1872        5.0          1          0      ...                 0            1   \n",
       "1873        5.0          1          0      ...                 0            1   \n",
       "1874        7.0          0          1      ...                 0            1   \n",
       "1875        5.0          1          0      ...                 0            1   \n",
       "1876        5.0          1          0      ...                 0            0   \n",
       "\n",
       "      Ethnicity_Asian  Ethnicity_Black  Ethnicity_Mixed-Black/Asian  \\\n",
       "0                   0                0                            0   \n",
       "1                   0                0                            0   \n",
       "2                   0                0                            0   \n",
       "3                   0                0                            0   \n",
       "4                   0                0                            0   \n",
       "...               ...              ...                          ...   \n",
       "1872                0                0                            0   \n",
       "1873                0                0                            0   \n",
       "1874                0                0                            0   \n",
       "1875                0                0                            0   \n",
       "1876                0                0                            0   \n",
       "\n",
       "      Ethnicity_Mixed-White/Asian  Ethnicity_Mixed-White/Black  \\\n",
       "0                               1                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "1872                            0                            0   \n",
       "1873                            0                            0   \n",
       "1874                            0                            0   \n",
       "1875                            0                            0   \n",
       "1876                            0                            0   \n",
       "\n",
       "      Ethnicity_Other  Ethnicity_White  All_Drugs_Cat  \n",
       "0                   0                0              0  \n",
       "1                   0                1              1  \n",
       "2                   0                1              0  \n",
       "3                   0                1              0  \n",
       "4                   0                1              0  \n",
       "...               ...              ...            ...  \n",
       "1872                0                1              0  \n",
       "1873                0                1              1  \n",
       "1874                0                1              1  \n",
       "1875                0                1              1  \n",
       "1876                0                1              1  \n",
       "\n",
       "[1877 rows x 31 columns]"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "df_drug_numeric = df_drug_numeric.drop(['Alcohol','Amphetamine','Amyl',\n",
    "                              'Benzos','Caffeine','Cannibis','Chocolate','Cocaine','Crack','Esctacy','Heroin',\n",
    "                              'Ketamine','Legal_highs','LSD','Meth','Mushrooms','Nicotine','VSA'], axis=1)\n",
    "df_drug_numeric = pd.concat([df_drug_numeric, all_drugs_cat], axis=1, copy=False)\n",
    "print(list(df_drug_numeric))\n",
    "df_drug_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_class_convert = df_train['Income_Class'].astype(str) #changes to string so we can change on the next line of code\n",
    "#train_class_convert = train_class_convert.str.replace('>50K', '1') \n",
    "#train_class_convert = train_class_convert.str.replace('<=50K', '0')\n",
    "#df_train_num['Income_Class'] = train_class_convert.astype(int) #changes to numeric\n",
    "\n",
    "#test_class_convert = df_test['Income_Class'].astype(str) #changes to string so we can change on the next line of code\n",
    "#test_class_convert = test_class_convert.str.replace('>50K.', '1') \n",
    "#test_class_convert = test_class_convert.str.replace('<=50K.', '0')\n",
    "#df_test_num['Income_Class'] = test_class_convert.astype(int) #changes to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = []\n",
    "\n",
    "#z_scores = df_drug_numeric.iloc[:,10:] #('Cty_Australia', 'Cty_Canada', 'Cty_Ireland', 'Cty_New Zealand', \n",
    "                           #'Cty_Other_Country', 'Cty_UK', 'Cty_USA', 'Eth_Asian', 'Eth_Black', \n",
    "                           #'Eth_Mixed-Black/Asian', 'Eth_Mixed-White/Asian', 'Eth_Mixed-White/Black', \n",
    "                           #'Eth_Other', 'Eth_White', 'All_Drugs_Cat')]\n",
    "#z_scores = (z_scores - z_scores.mean())/z_scores.std(ddof=0)\n",
    "#z_scores\n",
    "\n",
    "#df_drug_numeric[cols]\n",
    "#for col in cols:\n",
    "#    col_zscore = col + '_z'\n",
    "#    df_drug_numeric[col_zscore] = (df_drug_numeric[col] - df_drug_numeric[col].mean())/df_drug_numeric[col].std(ddof=0)\n",
    "#df_drug_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll desginate the target variable and move it to the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All_Drugs_Cat', 'N_Score', 'E_Score', 'O_Score', 'A_Score', 'C_Score', 'Impulsivenesss', 'SS', 'Education', 'Age_18-24', 'Age_25-34', 'Age_35-44', 'Age_45-54', 'Age_55-64', 'Age_65+', 'Gender_Female', 'Gender_Male', 'Country_Australia', 'Country_Canada', 'Country_Ireland', 'Country_New Zealand', 'Country_Other_Country', 'Country_UK', 'Country_USA', 'Ethnicity_Asian', 'Ethnicity_Black', 'Ethnicity_Mixed-Black/Asian', 'Ethnicity_Mixed-White/Asian', 'Ethnicity_Mixed-White/Black', 'Ethnicity_Other', 'Ethnicity_White']\n"
     ]
    }
   ],
   "source": [
    "targetName = 'All_Drugs_Cat' # designate target variable name\n",
    "\n",
    "targetSeries = df_drug_numeric[targetName]\n",
    "#remove target from current location and insert in column 0\n",
    "del df_drug_numeric[targetName]\n",
    "df_drug_numeric.insert(0, targetName, targetSeries)\n",
    "print(list(df_drug_numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll normalize all columns between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_Drugs_Cat</th>\n",
       "      <th>N_Score</th>\n",
       "      <th>E_Score</th>\n",
       "      <th>O_Score</th>\n",
       "      <th>A_Score</th>\n",
       "      <th>C_Score</th>\n",
       "      <th>Impulsivenesss</th>\n",
       "      <th>SS</th>\n",
       "      <th>Education</th>\n",
       "      <th>Age_18-24</th>\n",
       "      <th>...</th>\n",
       "      <th>Country_Other_Country</th>\n",
       "      <th>Country_UK</th>\n",
       "      <th>Country_USA</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Mixed-Black/Asian</th>\n",
       "      <th>Ethnicity_Mixed-White/Asian</th>\n",
       "      <th>Ethnicity_Mixed-White/Black</th>\n",
       "      <th>Ethnicity_Other</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5605621011</td>\n",
       "      <td>0.4121163250</td>\n",
       "      <td>0.4356898344</td>\n",
       "      <td>0.3676537658</td>\n",
       "      <td>0.4990402268</td>\n",
       "      <td>0.4284743029</td>\n",
       "      <td>0.2243982191</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4134743384</td>\n",
       "      <td>0.7961059033</td>\n",
       "      <td>0.7625665124</td>\n",
       "      <td>0.6098269233</td>\n",
       "      <td>0.4793944625</td>\n",
       "      <td>0.3379202287</td>\n",
       "      <td>0.4656580530</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4447879210</td>\n",
       "      <td>0.6229760563</td>\n",
       "      <td>0.3929389171</td>\n",
       "      <td>0.2660606865</td>\n",
       "      <td>0.3535804593</td>\n",
       "      <td>0.2154008265</td>\n",
       "      <td>0.6199574522</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4920447176</td>\n",
       "      <td>0.3768834398</td>\n",
       "      <td>0.5270227381</td>\n",
       "      <td>0.5852134305</td>\n",
       "      <td>0.5844153033</td>\n",
       "      <td>0.2154008265</td>\n",
       "      <td>0.2243982191</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6232753414</td>\n",
       "      <td>0.2505444527</td>\n",
       "      <td>0.4569948539</td>\n",
       "      <td>0.4564537173</td>\n",
       "      <td>0.6885081227</td>\n",
       "      <td>0.4284743029</td>\n",
       "      <td>0.4656580530</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3368896263</td>\n",
       "      <td>0.7658746522</td>\n",
       "      <td>0.8353990096</td>\n",
       "      <td>0.6098269233</td>\n",
       "      <td>0.3357734185</td>\n",
       "      <td>0.6297351036</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4775499422</td>\n",
       "      <td>0.7658746522</td>\n",
       "      <td>0.6245996302</td>\n",
       "      <td>0.6098269233</td>\n",
       "      <td>0.2808541837</td>\n",
       "      <td>0.6297351036</td>\n",
       "      <td>0.7109326760</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6822457923</td>\n",
       "      <td>0.2897954446</td>\n",
       "      <td>0.3235992318</td>\n",
       "      <td>0.2442529067</td>\n",
       "      <td>0.3001044926</td>\n",
       "      <td>0.5653426427</td>\n",
       "      <td>0.3881171239</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6493175568</td>\n",
       "      <td>0.2065102186</td>\n",
       "      <td>0.5776515090</td>\n",
       "      <td>0.2660606865</td>\n",
       "      <td>0.1286341489</td>\n",
       "      <td>0.7050679421</td>\n",
       "      <td>0.8257516480</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4447879210</td>\n",
       "      <td>0.8248389550</td>\n",
       "      <td>0.7983852424</td>\n",
       "      <td>0.6607887171</td>\n",
       "      <td>0.5600312901</td>\n",
       "      <td>0.6297351036</td>\n",
       "      <td>0.8257516480</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      All_Drugs_Cat       N_Score       E_Score       O_Score       A_Score  \\\n",
       "0                 0  0.5605621011  0.4121163250  0.4356898344  0.3676537658   \n",
       "1                 1  0.4134743384  0.7961059033  0.7625665124  0.6098269233   \n",
       "2                 0  0.4447879210  0.6229760563  0.3929389171  0.2660606865   \n",
       "3                 0  0.4920447176  0.3768834398  0.5270227381  0.5852134305   \n",
       "4                 0  0.6232753414  0.2505444527  0.4569948539  0.4564537173   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "1872              0  0.3368896263  0.7658746522  0.8353990096  0.6098269233   \n",
       "1873              1  0.4775499422  0.7658746522  0.6245996302  0.6098269233   \n",
       "1874              1  0.6822457923  0.2897954446  0.3235992318  0.2442529067   \n",
       "1875              1  0.6493175568  0.2065102186  0.5776515090  0.2660606865   \n",
       "1876              1  0.4447879210  0.8248389550  0.7983852424  0.6607887171   \n",
       "\n",
       "           C_Score  Impulsivenesss            SS  Education  Age_18-24  \\\n",
       "0     0.4990402268    0.4284743029  0.2243982191      0.625          0   \n",
       "1     0.4793944625    0.3379202287  0.4656580530      1.000          0   \n",
       "2     0.3535804593    0.2154008265  0.6199574522      0.625          0   \n",
       "3     0.5844153033    0.2154008265  0.2243982191      0.875          1   \n",
       "4     0.6885081227    0.4284743029  0.4656580530      1.000          0   \n",
       "...            ...             ...           ...        ...        ...   \n",
       "1872  0.3357734185    0.6297351036  1.0000000000      0.500          1   \n",
       "1873  0.2808541837    0.6297351036  0.7109326760      0.500          1   \n",
       "1874  0.3001044926    0.5653426427  0.3881171239      0.750          0   \n",
       "1875  0.1286341489    0.7050679421  0.8257516480      0.500          1   \n",
       "1876  0.5600312901    0.6297351036  0.8257516480      0.500          1   \n",
       "\n",
       "           ...         Country_Other_Country  Country_UK  Country_USA  \\\n",
       "0          ...                             0           1            0   \n",
       "1          ...                             0           1            0   \n",
       "2          ...                             0           1            0   \n",
       "3          ...                             0           1            0   \n",
       "4          ...                             0           1            0   \n",
       "...        ...                           ...         ...          ...   \n",
       "1872       ...                             0           0            1   \n",
       "1873       ...                             0           0            1   \n",
       "1874       ...                             0           0            1   \n",
       "1875       ...                             0           0            1   \n",
       "1876       ...                             0           0            0   \n",
       "\n",
       "      Ethnicity_Asian  Ethnicity_Black  Ethnicity_Mixed-Black/Asian  \\\n",
       "0                   0                0                            0   \n",
       "1                   0                0                            0   \n",
       "2                   0                0                            0   \n",
       "3                   0                0                            0   \n",
       "4                   0                0                            0   \n",
       "...               ...              ...                          ...   \n",
       "1872                0                0                            0   \n",
       "1873                0                0                            0   \n",
       "1874                0                0                            0   \n",
       "1875                0                0                            0   \n",
       "1876                0                0                            0   \n",
       "\n",
       "      Ethnicity_Mixed-White/Asian  Ethnicity_Mixed-White/Black  \\\n",
       "0                               1                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "1872                            0                            0   \n",
       "1873                            0                            0   \n",
       "1874                            0                            0   \n",
       "1875                            0                            0   \n",
       "1876                            0                            0   \n",
       "\n",
       "      Ethnicity_Other  Ethnicity_White  \n",
       "0                   0                0  \n",
       "1                   0                1  \n",
       "2                   0                1  \n",
       "3                   0                1  \n",
       "4                   0                1  \n",
       "...               ...              ...  \n",
       "1872                0                1  \n",
       "1873                0                1  \n",
       "1874                0                1  \n",
       "1875                0                1  \n",
       "1876                0                1  \n",
       "\n",
       "[1877 rows x 31 columns]"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set\n",
    "pd.options.display.max_rows = 10\n",
    "#norm = df_drug_numeric.iloc[:,1:8]\n",
    "#3norm_denom = norm.max()- norm.min\n",
    "#norm_eq = (norm-norm.min())/(norm.max()-norm.min())\n",
    "#norm_eq\n",
    "df_drug_numeric.iloc[:,1:9] = (df_drug_numeric.iloc[:,1:9] - df_drug_numeric.iloc[:,1:9].min())/(df_drug_numeric.iloc[:,1:9].max() - df_drug_numeric.iloc[:,1:9].min())\n",
    "df_drug_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Split\n",
    "The data was already in a test/train split, so here we just have to split off the target variable.  The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "target = df_drug_numeric[targetName]\n",
    "features = df_drug_numeric.drop([targetName],axis=1)\n",
    "\n",
    "#target_test = df_test_num[targetName]\n",
    "#features_test = df_test_num.drop([targetName],axis=1)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A view of the size of each test/train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 30)\n",
      "(1257, 30)\n",
      "(620,)\n",
      "(1257,)\n",
      "Percent of Target that is Yes: 53\n"
     ]
    }
   ],
   "source": [
    "print(features_test.shape)\n",
    "print(features_train.shape)\n",
    "print(target_test.shape)\n",
    "print(target_train.shape)\n",
    "print(\"Percent of Target that is Yes:\", round(100*target_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25% of the training data target variable is >$50K.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same info on the target shown graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x18927e70470>"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEHCAYAAACncpHfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18927e345c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df_drug_numeric.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a nearly even split between the two categories.  Now let's try a correlation matrix and see the most significant correlations with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SS                             0.4615102246\n",
       "Country_USA                    0.4266797553\n",
       "O_Score                        0.3570833294\n",
       "Impulsivenesss                 0.3334914634\n",
       "Age_18-24                      0.3147979000\n",
       "Gender_Male                    0.3032609237\n",
       "N_Score                        0.1437142176\n",
       "Country_Other_Country          0.1011115412\n",
       "Country_Australia              0.0852742850\n",
       "Ethnicity_Other                0.0534471872\n",
       "Country_Ireland                0.0484334817\n",
       "Ethnicity_Mixed-Black/Asian    0.0386895439\n",
       "Country_Canada                 0.0356992137\n",
       "Ethnicity_White                0.0255076498\n",
       "Ethnicity_Mixed-White/Asian    0.0172822612\n",
       "Age_25-34                      0.0169708152\n",
       "Country_New Zealand            0.0086064411\n",
       "Ethnicity_Mixed-White/Black   -0.0087213698\n",
       "E_Score                       -0.0129454391\n",
       "Ethnicity_Asian               -0.0643520333\n",
       "Ethnicity_Black               -0.0896704399\n",
       "Age_65+                       -0.1017603943\n",
       "Age_35-44                     -0.1183094537\n",
       "Age_55-64                     -0.1231203016\n",
       "A_Score                       -0.1776094832\n",
       "Age_45-54                     -0.2022058533\n",
       "Education                     -0.2141934355\n",
       "C_Score                       -0.2997212705\n",
       "Gender_Female                 -0.3032609237\n",
       "Country_UK                    -0.4946654595\n",
       "Name: All_Drugs_Cat, dtype: float64"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 35\n",
    "correlations = df_drug_numeric.corr()\n",
    "correlations = correlations[targetName]\n",
    "correlations = correlations[1:,] \n",
    "correlations.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the correlations here weren't too surprising.  Men use drugs more than women.  Younger people use drugs more than older.  Ethnicity had little correlation with drug use.  The biggest surprise to me was the large discrepancy between different countries, all of which (expect 'other', which is unknown) are western primarily English-speaking countries.  Amongst the personality metrics, sensation, openness to experience, impulsiveness, and neuorticism correlated with heavier drug use.  Concientiousness, agreeableness, and extraversion correlated with less drug use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "Now we'll explore different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "First we'll do a K Nearest Neighbor model with default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "#Call up the model to see the parameters you can tune (and their default setting)\n",
    "print(knn) \n",
    "#Fit knn to the training data\n",
    "knn = knn.fit(features_train, target_train)\n",
    "#Predict clf KNN against test data\n",
    "target_predicted_knn = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.819057104914\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.90      0.88     11360\n",
      "     > $50K       0.65      0.57      0.61      3700\n",
      "\n",
      "avg / total       0.81      0.82      0.81     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10222  1138]\n",
      " [ 1587  2113]]\n",
      "Confusion Matrix Percent\n",
      "[[ 67.875166     7.5564409 ]\n",
      " [ 10.53784861  14.03054449]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_knn))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_knn, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_knn))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_knn))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the KNN classifier with default settings had an accuracy of 81.9%.  Now let's do a grid search on the number of neighbors and see the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 20}\n",
      "Best Score: 0.833698030635\n",
      "Best Estimator KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.009965</td>\n",
       "      <td>51.692430</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.893235</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812863</td>\n",
       "      <td>0.894898</td>\n",
       "      <td>0.815183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818167</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>0.815318</td>\n",
       "      <td>0.893742</td>\n",
       "      <td>0.815785</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.431869</td>\n",
       "      <td>0.582183</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.634378</td>\n",
       "      <td>58.908670</td>\n",
       "      <td>0.822359</td>\n",
       "      <td>0.872978</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.816509</td>\n",
       "      <td>0.872850</td>\n",
       "      <td>0.823802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824797</td>\n",
       "      <td>0.873679</td>\n",
       "      <td>0.823442</td>\n",
       "      <td>0.871985</td>\n",
       "      <td>0.823247</td>\n",
       "      <td>0.872778</td>\n",
       "      <td>0.325751</td>\n",
       "      <td>0.702091</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.668756</td>\n",
       "      <td>64.310816</td>\n",
       "      <td>0.827167</td>\n",
       "      <td>0.864357</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.825791</td>\n",
       "      <td>0.864354</td>\n",
       "      <td>0.823305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.862862</td>\n",
       "      <td>0.830570</td>\n",
       "      <td>0.864816</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.864614</td>\n",
       "      <td>0.238282</td>\n",
       "      <td>0.797516</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.946881</td>\n",
       "      <td>68.486197</td>\n",
       "      <td>0.830283</td>\n",
       "      <td>0.858572</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.827781</td>\n",
       "      <td>0.858925</td>\n",
       "      <td>0.826952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830764</td>\n",
       "      <td>0.857765</td>\n",
       "      <td>0.835046</td>\n",
       "      <td>0.858931</td>\n",
       "      <td>0.830874</td>\n",
       "      <td>0.858854</td>\n",
       "      <td>0.654360</td>\n",
       "      <td>1.497782</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.846881</td>\n",
       "      <td>72.971177</td>\n",
       "      <td>0.830946</td>\n",
       "      <td>0.852787</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.851755</td>\n",
       "      <td>0.825626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829272</td>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.838859</td>\n",
       "      <td>0.853792</td>\n",
       "      <td>0.832698</td>\n",
       "      <td>0.852596</td>\n",
       "      <td>0.309264</td>\n",
       "      <td>1.431546</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.471877</td>\n",
       "      <td>76.615004</td>\n",
       "      <td>0.832438</td>\n",
       "      <td>0.850797</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829935</td>\n",
       "      <td>0.850015</td>\n",
       "      <td>0.840849</td>\n",
       "      <td>0.850477</td>\n",
       "      <td>0.834190</td>\n",
       "      <td>0.850358</td>\n",
       "      <td>0.260596</td>\n",
       "      <td>1.083131</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.703131</td>\n",
       "      <td>81.219792</td>\n",
       "      <td>0.833698</td>\n",
       "      <td>0.846719</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.829604</td>\n",
       "      <td>0.848564</td>\n",
       "      <td>0.832422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832753</td>\n",
       "      <td>0.846450</td>\n",
       "      <td>0.838528</td>\n",
       "      <td>0.846291</td>\n",
       "      <td>0.835185</td>\n",
       "      <td>0.845966</td>\n",
       "      <td>0.278985</td>\n",
       "      <td>1.451774</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.696878</td>\n",
       "      <td>88.345418</td>\n",
       "      <td>0.833499</td>\n",
       "      <td>0.841829</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_neighbors': 30}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.827449</td>\n",
       "      <td>0.843922</td>\n",
       "      <td>0.830764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832919</td>\n",
       "      <td>0.841311</td>\n",
       "      <td>0.839854</td>\n",
       "      <td>0.840406</td>\n",
       "      <td>0.836511</td>\n",
       "      <td>0.841656</td>\n",
       "      <td>0.511262</td>\n",
       "      <td>1.355827</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.800004</td>\n",
       "      <td>93.644289</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.839276</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_neighbors': 40}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.840400</td>\n",
       "      <td>0.828775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832587</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.837837</td>\n",
       "      <td>0.835185</td>\n",
       "      <td>0.839625</td>\n",
       "      <td>0.352641</td>\n",
       "      <td>1.942850</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.884380</td>\n",
       "      <td>96.951520</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.836881</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_neighbors': 50}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825791</td>\n",
       "      <td>0.837664</td>\n",
       "      <td>0.827946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829438</td>\n",
       "      <td>0.837167</td>\n",
       "      <td>0.837036</td>\n",
       "      <td>0.835765</td>\n",
       "      <td>0.836511</td>\n",
       "      <td>0.836269</td>\n",
       "      <td>0.465471</td>\n",
       "      <td>4.030956</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       3.009965        51.692430         0.815463          0.893235   \n",
       "1       2.634378        58.908670         0.822359          0.872978   \n",
       "2       2.668756        64.310816         0.827167          0.864357   \n",
       "3       2.946881        68.486197         0.830283          0.858572   \n",
       "4       2.846881        72.971177         0.830946          0.852787   \n",
       "5       2.471877        76.615004         0.832438          0.850797   \n",
       "6       2.703131        81.219792         0.833698          0.846719   \n",
       "7       2.696878        88.345418         0.833499          0.841829   \n",
       "8       2.800004        93.644289         0.832836          0.839276   \n",
       "9       2.884380        96.951520         0.831344          0.836881   \n",
       "\n",
       "  param_n_neighbors               params  rank_test_score  split0_test_score  \\\n",
       "0                 3   {'n_neighbors': 3}               10           0.812863   \n",
       "1                 5   {'n_neighbors': 5}                9           0.816509   \n",
       "2                 7   {'n_neighbors': 7}                8           0.825791   \n",
       "3                 9   {'n_neighbors': 9}                7           0.827781   \n",
       "4                12  {'n_neighbors': 12}                6           0.828278   \n",
       "5                15  {'n_neighbors': 15}                4           0.828941   \n",
       "6                20  {'n_neighbors': 20}                1           0.829604   \n",
       "7                30  {'n_neighbors': 30}                2           0.827449   \n",
       "8                40  {'n_neighbors': 40}                3           0.828278   \n",
       "9                50  {'n_neighbors': 50}                5           0.825791   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.894898           0.815183       ...                  0.818167   \n",
       "1            0.872850           0.823802       ...                  0.824797   \n",
       "2            0.864354           0.823305       ...                  0.828278   \n",
       "3            0.858925           0.826952       ...                  0.830764   \n",
       "4            0.851755           0.825626       ...                  0.829272   \n",
       "5            0.851962           0.828278       ...                  0.829935   \n",
       "6            0.848564           0.832422       ...                  0.832753   \n",
       "7            0.843922           0.830764       ...                  0.832919   \n",
       "8            0.840400           0.828775       ...                  0.832587   \n",
       "9            0.837664           0.827946       ...                  0.829438   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.890961           0.815318            0.893742   \n",
       "1            0.873679           0.823442            0.871985   \n",
       "2            0.862862           0.830570            0.864816   \n",
       "3            0.857765           0.835046            0.858931   \n",
       "4            0.851962           0.838859            0.853792   \n",
       "5            0.850015           0.840849            0.850477   \n",
       "6            0.846450           0.838528            0.846291   \n",
       "7            0.841311           0.839854            0.840406   \n",
       "8            0.839281           0.839357            0.837837   \n",
       "9            0.837167           0.837036            0.835765   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.815785            0.892752      0.431869        0.582183   \n",
       "1           0.823247            0.872778      0.325751        0.702091   \n",
       "2           0.827889            0.864614      0.238282        0.797516   \n",
       "3           0.830874            0.858854      0.654360        1.497782   \n",
       "4           0.832698            0.852596      0.309264        1.431546   \n",
       "5           0.834190            0.850358      0.260596        1.083131   \n",
       "6           0.835185            0.845966      0.278985        1.451774   \n",
       "7           0.836511            0.841656      0.511262        1.355827   \n",
       "8           0.835185            0.839625      0.352641        1.942850   \n",
       "9           0.836511            0.836269      0.465471        4.030956   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.001690         0.001324  \n",
       "1        0.002974         0.000619  \n",
       "2        0.002455         0.000791  \n",
       "3        0.002851         0.000451  \n",
       "4        0.004559         0.000880  \n",
       "5        0.004682         0.000694  \n",
       "6        0.002994         0.000936  \n",
       "7        0.004333         0.001158  \n",
       "8        0.004132         0.000832  \n",
       "9        0.004585         0.000742  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"n_neighbors\": [3,5,7,9,12,15,20,30,40,50]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(knn, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search revealed that n=20 is the best solution.  Let's run the model with that parameter and see the result.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "#Call up the model to see the parameters you can tune (and their default setting)\n",
    "print(knn)\n",
    "#Fit clf to the training data\n",
    "knn = knn.fit(features_train, target_train)\n",
    "#Predict clf KNN against test data\n",
    "target_predicted_knn = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.830942895086\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.92      0.89     11360\n",
      "     > $50K       0.70      0.56      0.62      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10458   902]\n",
      " [ 1644  2056]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.44223108   5.98937583]\n",
      " [ 10.91633466  13.65205843]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_knn))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_knn, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_knn))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_knn))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved from 81.9% to 83.1% using n=20 in the KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use a Manhattan distance in the KNN to see how it compares to the Euclidean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20, p=1)\n",
    "#Fit clf to the training data\n",
    "knn = knn.fit(features_train, target_train)\n",
    "#Predict clf KNN against test data\n",
    "target_predicted_knn = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.830478087649\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.92      0.89     11360\n",
      "     > $50K       0.70      0.54      0.61      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10499   861]\n",
      " [ 1692  2008]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.71447543   5.71713147]\n",
      " [ 11.23505976  13.33333333]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_knn))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_knn, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_knn))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_knn))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy declined slightly when using Manhattan distances.  Thus, Euclidean distance (p=2) was determined to be optimal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83095791  0.83327809  0.83592973  0.83128936  0.83753316  0.82625995\n",
      "  0.83653846  0.84316976  0.8384743   0.8331675 ]\n",
      "Mean cross validation score 0.834659820514\n"
     ]
    }
   ],
   "source": [
    "#verify KNN with Cross Validation\n",
    "knn = KNeighborsClassifier(n_neighbors=20, p=2) #next 3 lines rerun code for best tweaked solution for later use\n",
    "knn.fit(features_train, target_train)\n",
    "target_predicted_knn = knn.predict(features_test)\n",
    "scores_knn = cross_val_score(knn, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores_knn)\n",
    "print(\"Mean cross validation score\", scores_knn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores look consistant, suggesting this model is not overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Now we'll use a decision tree model, starting with default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best')\n",
      "DT Accuracy Score 0.796082337317\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.86      0.86     11360\n",
      "     > $50K       0.58      0.59      0.59      3700\n",
      "\n",
      "avg / total       0.80      0.80      0.80     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[9810 1550]\n",
      " [1521 2179]]\n",
      "Confusion Matrix Percent\n",
      "[[ 65.13944223  10.29216467]\n",
      " [ 10.09960159  14.4687915 ]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "from sklearn import tree \n",
    "clf = tree.DecisionTreeClassifier(random_state=123)\n",
    "print(clf)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_dt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_dt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the decision tree classifier with default settings had an accuracy of 79.6%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tweak the parameters to see if we can get better results.  Let's start with a grid serach on max depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 9}\n",
      "Best Score: 0.853391684902\n",
      "Best Estimator DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best')\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.290104</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.840263</td>\n",
       "      <td>0.840329</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.834245</td>\n",
       "      <td>0.841767</td>\n",
       "      <td>0.835405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843030</td>\n",
       "      <td>0.839654</td>\n",
       "      <td>0.847646</td>\n",
       "      <td>0.838500</td>\n",
       "      <td>0.840988</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>6.249690e-03</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.840926</td>\n",
       "      <td>0.841688</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.833250</td>\n",
       "      <td>0.842264</td>\n",
       "      <td>0.835737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>0.839985</td>\n",
       "      <td>0.846651</td>\n",
       "      <td>0.838707</td>\n",
       "      <td>0.845631</td>\n",
       "      <td>0.845634</td>\n",
       "      <td>0.033656</td>\n",
       "      <td>7.653215e-03</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568757</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.842815</td>\n",
       "      <td>0.845285</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.837063</td>\n",
       "      <td>0.846782</td>\n",
       "      <td>0.837726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842864</td>\n",
       "      <td>0.843881</td>\n",
       "      <td>0.845159</td>\n",
       "      <td>0.841442</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.850193</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>2.953312e-06</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.790628</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.854490</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851649</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.851790</td>\n",
       "      <td>0.849399</td>\n",
       "      <td>0.851932</td>\n",
       "      <td>0.852223</td>\n",
       "      <td>0.077562</td>\n",
       "      <td>6.247902e-03</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.850540</td>\n",
       "      <td>0.855033</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.856273</td>\n",
       "      <td>0.846677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852312</td>\n",
       "      <td>0.853247</td>\n",
       "      <td>0.854277</td>\n",
       "      <td>0.853378</td>\n",
       "      <td>0.853424</td>\n",
       "      <td>0.856202</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>1.169240e-02</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.071879</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.851668</td>\n",
       "      <td>0.859252</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.861412</td>\n",
       "      <td>0.849494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850157</td>\n",
       "      <td>0.856190</td>\n",
       "      <td>0.856432</td>\n",
       "      <td>0.857315</td>\n",
       "      <td>0.855414</td>\n",
       "      <td>0.860387</td>\n",
       "      <td>0.046978</td>\n",
       "      <td>9.881439e-03</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.081253</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>0.853392</td>\n",
       "      <td>0.864772</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847340</td>\n",
       "      <td>0.866095</td>\n",
       "      <td>0.850986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854136</td>\n",
       "      <td>0.864147</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.862578</td>\n",
       "      <td>0.856740</td>\n",
       "      <td>0.865401</td>\n",
       "      <td>0.084085</td>\n",
       "      <td>1.249890e-02</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.001273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.956254</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.852066</td>\n",
       "      <td>0.869107</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>0.870529</td>\n",
       "      <td>0.848997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854799</td>\n",
       "      <td>0.868664</td>\n",
       "      <td>0.857593</td>\n",
       "      <td>0.866639</td>\n",
       "      <td>0.855248</td>\n",
       "      <td>0.870167</td>\n",
       "      <td>0.028641</td>\n",
       "      <td>2.198628e-06</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.001387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.271877</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.838207</td>\n",
       "      <td>0.901979</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 15}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.835903</td>\n",
       "      <td>0.904347</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835571</td>\n",
       "      <td>0.899001</td>\n",
       "      <td>0.847480</td>\n",
       "      <td>0.901699</td>\n",
       "      <td>0.838501</td>\n",
       "      <td>0.901040</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>8.529922e-07</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.303129</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.825608</td>\n",
       "      <td>0.938714</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.820322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826455</td>\n",
       "      <td>0.934933</td>\n",
       "      <td>0.834218</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>0.828718</td>\n",
       "      <td>0.935767</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>7.653682e-03</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.003771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.290104         0.012499         0.840263          0.840329   \n",
       "1       0.475000         0.009373         0.840926          0.841688   \n",
       "2       0.568757         0.015624         0.842815          0.845285   \n",
       "3       0.790628         0.018746         0.848783          0.851800   \n",
       "4       0.912500         0.012500         0.850540          0.855033   \n",
       "5       1.071879         0.015624         0.851668          0.859252   \n",
       "6       1.081253         0.021876         0.853392          0.864772   \n",
       "7       0.956254         0.015625         0.852066          0.869107   \n",
       "8       1.271877         0.015624         0.838207          0.901979   \n",
       "9       1.303129         0.009374         0.825608          0.938714   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "0               3   {'max_depth': 3}                8           0.834245   \n",
       "1               4   {'max_depth': 4}                7           0.833250   \n",
       "2               5   {'max_depth': 5}                6           0.837063   \n",
       "3               6   {'max_depth': 6}                5           0.844853   \n",
       "4               7   {'max_depth': 7}                4           0.846014   \n",
       "5               8   {'max_depth': 8}                3           0.846842   \n",
       "6               9   {'max_depth': 9}                1           0.847340   \n",
       "7              10  {'max_depth': 10}                2           0.843693   \n",
       "8              15  {'max_depth': 15}                9           0.835903   \n",
       "9              20  {'max_depth': 20}               10           0.818333   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.841767           0.835405       ...                  0.843030   \n",
       "1            0.842264           0.835737       ...                  0.843362   \n",
       "2            0.846782           0.837726       ...                  0.842864   \n",
       "3            0.854490           0.843693       ...                  0.851649   \n",
       "4            0.856273           0.846677       ...                  0.852312   \n",
       "5            0.861412           0.849494       ...                  0.850157   \n",
       "6            0.866095           0.850986       ...                  0.854136   \n",
       "7            0.870529           0.848997       ...                  0.854799   \n",
       "8            0.904347           0.833582       ...                  0.835571   \n",
       "9            0.944631           0.820322       ...                  0.826455   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.839654           0.847646            0.838500   \n",
       "1            0.839985           0.846651            0.838707   \n",
       "2            0.843881           0.845159            0.841442   \n",
       "3            0.850139           0.851790            0.849399   \n",
       "4            0.853247           0.854277            0.853378   \n",
       "5            0.856190           0.856432            0.857315   \n",
       "6            0.864147           0.857759            0.862578   \n",
       "7            0.868664           0.857593            0.866639   \n",
       "8            0.899001           0.847480            0.901699   \n",
       "9            0.934933           0.834218            0.936593   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.840988            0.840164      0.030796    6.249690e-03   \n",
       "1           0.845631            0.845634      0.033656    7.653215e-03   \n",
       "2           0.851268            0.850193      0.041457    2.953312e-06   \n",
       "3           0.851932            0.852223      0.077562    6.247902e-03   \n",
       "4           0.853424            0.856202      0.041458    1.169240e-02   \n",
       "5           0.855414            0.860387      0.046978    9.881439e-03   \n",
       "6           0.856740            0.865401      0.084085    1.249890e-02   \n",
       "7           0.855248            0.870167      0.028641    2.198628e-06   \n",
       "8           0.838501            0.901040      0.033658    8.529922e-07   \n",
       "9           0.828718            0.935767      0.095089    7.653682e-03   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.004950         0.001218  \n",
       "1        0.005416         0.002354  \n",
       "2        0.005214         0.002980  \n",
       "3        0.003702         0.001835  \n",
       "4        0.003488         0.001407  \n",
       "5        0.003661         0.002097  \n",
       "6        0.003828         0.001273  \n",
       "7        0.005053         0.001387  \n",
       "8        0.004893         0.001938  \n",
       "9        0.005751         0.003771  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": [3,4,5,6,7,8,9,10,15,20]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search showed that the best max depth is 9.  Let's run the model again with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.841965471448\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.91      0.90     11360\n",
      "     > $50K       0.70      0.63      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10347  1013]\n",
      " [ 1367  2333]]\n",
      "Confusion Matrix Percent\n",
      "[[ 68.70517928   6.72642762]\n",
      " [  9.07702523  15.49136786]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=9,random_state=123)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_dt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_dt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased from 79.6% to 84.2% with this change.  The number of false positives in particular dropped significantly, from 10.3% to 6.7%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the decision tree using information gain vice Gini impurity for the split quality criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.840637450199\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.91      0.90     11360\n",
      "     > $50K       0.69      0.63      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10335  1025]\n",
      " [ 1375  2325]]\n",
      "Confusion Matrix Percent\n",
      "[[ 68.62549801   6.8061089 ]\n",
      " [  9.13014608  15.43824701]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=9,random_state=123)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_dt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_dt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy dropped slightly using information gain (84.1% vice 84.2%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the decision tree, using the Gini impurity as that was more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83990719  0.84852502  0.85382831  0.84686775  0.84714854  0.85377984\n",
      "  0.85046419  0.85775862  0.85936982  0.85207297]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85097222528225969"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "clf = tree.DecisionTreeClassifier(max_depth=9,random_state=123)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the decision tree are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forest\n",
    "Now we'll try the random forest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "RF Accuracy Score 0.837383798141\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.92      0.90     11360\n",
      "     > $50K       0.71      0.57      0.63      3700\n",
      "\n",
      "avg / total       0.83      0.84      0.83     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10505   855]\n",
      " [ 1594  2106]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.75431607   5.67729084]\n",
      " [ 10.58432935  13.98406375]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=123)\n",
    "rf = rf.fit(features_train, target_train)\n",
    "print(rf)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"RF Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_rf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest with default settings had an accuracy of 83.7%.  Let's do a grid seach of the numner of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 100}\n",
      "Best Score: 0.854154233804\n",
      "Best Estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.637499</td>\n",
       "      <td>0.065628</td>\n",
       "      <td>0.846031</td>\n",
       "      <td>0.987592</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.845185</td>\n",
       "      <td>0.988769</td>\n",
       "      <td>0.843196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.987235</td>\n",
       "      <td>0.853780</td>\n",
       "      <td>0.986780</td>\n",
       "      <td>0.843973</td>\n",
       "      <td>0.986863</td>\n",
       "      <td>0.132724</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.790419</td>\n",
       "      <td>0.165627</td>\n",
       "      <td>0.850176</td>\n",
       "      <td>0.995740</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.850655</td>\n",
       "      <td>0.995938</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>0.995980</td>\n",
       "      <td>0.854609</td>\n",
       "      <td>0.995276</td>\n",
       "      <td>0.848615</td>\n",
       "      <td>0.995442</td>\n",
       "      <td>0.318657</td>\n",
       "      <td>0.028979</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.896889</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.851867</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_estimators': 40}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.851152</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.849329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849660</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>0.856101</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.853092</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.498883</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.809397</td>\n",
       "      <td>0.412503</td>\n",
       "      <td>0.852430</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>60</td>\n",
       "      <td>{'n_estimators': 60}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.858753</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.852761</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.309741</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.493070</td>\n",
       "      <td>0.528126</td>\n",
       "      <td>0.853325</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>80</td>\n",
       "      <td>{'n_estimators': 80}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.848997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853638</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.857924</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.853424</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.124685</td>\n",
       "      <td>0.041224</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48.385806</td>\n",
       "      <td>1.609378</td>\n",
       "      <td>0.853226</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>250</td>\n",
       "      <td>{'n_estimators': 250}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.853307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851318</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.858090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853092</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.499808</td>\n",
       "      <td>0.211256</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57.736316</td>\n",
       "      <td>1.828129</td>\n",
       "      <td>0.853259</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>300</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.858256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853590</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67.482784</td>\n",
       "      <td>2.142336</td>\n",
       "      <td>0.853624</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>350</td>\n",
       "      <td>{'n_estimators': 350}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.854136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.857593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854750</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.217008</td>\n",
       "      <td>0.060649</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>77.473933</td>\n",
       "      <td>2.734377</td>\n",
       "      <td>0.853591</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>400</td>\n",
       "      <td>{'n_estimators': 400}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.854136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853473</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.857427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854585</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.399607</td>\n",
       "      <td>0.368566</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>91.475545</td>\n",
       "      <td>3.065631</td>\n",
       "      <td>0.853988</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852975</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.857924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855414</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>5.917007</td>\n",
       "      <td>0.478991</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        1.637499         0.065628         0.846031          0.987592   \n",
       "1        3.790419         0.165627         0.850176          0.995740   \n",
       "2        7.896889         0.262500         0.851867          0.998939   \n",
       "3       11.809397         0.412503         0.852430          0.999776   \n",
       "4       15.493070         0.528126         0.853325          0.999851   \n",
       "..            ...              ...              ...               ...   \n",
       "8       48.385806         1.609378         0.853226          0.999975   \n",
       "9       57.736316         1.828129         0.853259          0.999975   \n",
       "10      67.482784         2.142336         0.853624          0.999975   \n",
       "11      77.473933         2.734377         0.853591          0.999975   \n",
       "12      91.475545         3.065631         0.853988          0.999975   \n",
       "\n",
       "   param_n_estimators                 params  rank_test_score  \\\n",
       "0                  10   {'n_estimators': 10}               13   \n",
       "1                  20   {'n_estimators': 20}               12   \n",
       "2                  40   {'n_estimators': 40}               11   \n",
       "3                  60   {'n_estimators': 60}               10   \n",
       "4                  80   {'n_estimators': 80}                7   \n",
       "..                ...                    ...              ...   \n",
       "8                 250  {'n_estimators': 250}                9   \n",
       "9                 300  {'n_estimators': 300}                8   \n",
       "10                350  {'n_estimators': 350}                4   \n",
       "11                400  {'n_estimators': 400}                5   \n",
       "12                500  {'n_estimators': 500}                2   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0            0.845185            0.988769           0.843196       ...          \n",
       "1            0.850655            0.995938           0.848500       ...          \n",
       "2            0.851152            0.999254           0.849329       ...          \n",
       "3            0.852644            0.999834           0.847174       ...          \n",
       "4            0.852644            0.999793           0.848997       ...          \n",
       "..                ...                 ...                ...       ...          \n",
       "8            0.853307            1.000000           0.850323       ...          \n",
       "9            0.852644            1.000000           0.849660       ...          \n",
       "10           0.854136            1.000000           0.849494       ...          \n",
       "11           0.854136            1.000000           0.848334       ...          \n",
       "12           0.854799            1.000000           0.848831       ...          \n",
       "\n",
       "    split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0            0.844025            0.987235           0.853780   \n",
       "1            0.848500            0.995980           0.854609   \n",
       "2            0.849660            0.998922           0.856101   \n",
       "3            0.850820            0.999751           0.858753   \n",
       "4            0.853638            0.999917           0.857924   \n",
       "..                ...                 ...                ...   \n",
       "8            0.851318            0.999959           0.858090   \n",
       "9            0.852147            0.999959           0.858256   \n",
       "10           0.852147            0.999959           0.857593   \n",
       "11           0.853473            0.999959           0.857427   \n",
       "12           0.852975            0.999959           0.857924   \n",
       "\n",
       "    split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0             0.986780           0.843973            0.986863      0.132724   \n",
       "1             0.995276           0.848615            0.995442      0.318657   \n",
       "2             0.999047           0.853092            0.998384      0.498883   \n",
       "3             0.999834           0.852761            0.999668      0.309741   \n",
       "4             0.999917           0.853424            0.999876      0.124685   \n",
       "..                 ...                ...                 ...           ...   \n",
       "8             1.000000           0.853092            0.999959      0.499808   \n",
       "9             1.000000           0.853590            0.999959      0.373205   \n",
       "10            1.000000           0.854750            0.999959      0.217008   \n",
       "11            1.000000           0.854585            0.999959      0.399607   \n",
       "12            1.000000           0.855414            0.999959      5.917007   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.011688        0.003926         0.000803  \n",
       "1         0.028979        0.002364         0.000318  \n",
       "2         0.015312        0.002500         0.000297  \n",
       "3         0.060600        0.003751         0.000062  \n",
       "4         0.041224        0.002845         0.000067  \n",
       "..             ...             ...              ...  \n",
       "8         0.211256        0.002674         0.000020  \n",
       "9         0.022097        0.002816         0.000020  \n",
       "10        0.060649        0.002703         0.000020  \n",
       "11        0.368566        0.002955         0.000020  \n",
       "12        0.478991        0.003027         0.000020  \n",
       "\n",
       "[13 rows x 21 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [10,20,40,60,80,100,150,200,250,300,350,400,500]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined a n estimators value of 100 as optimal.  Now let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score 0.844090305445\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.92      0.90     11360\n",
      "     > $50K       0.72      0.60      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10480   880]\n",
      " [ 1468  2232]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.58831341   5.84329349]\n",
      " [  9.74767596  14.82071713]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 100, random_state=123)\n",
    "rf = rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"RF Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_rf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model improved with a modest rise in accuracy from 83.7% to 84.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try chaning the class weight to the 'balanced', where columns with a greater count have more weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score 0.84395750332\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.72      0.60      0.65      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10508   852]\n",
      " [ 1498  2202]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.77423639   5.65737052]\n",
      " [  9.94687915  14.62151394]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 100, class_weight='balanced', random_state=123)\n",
    "rf = rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"RF Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_rf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy decreased slightly but still rounds to 84.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross validate the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83891283  0.85946304  0.85051376  0.8471992   0.85709549  0.8494695\n",
      "  0.8561008   0.85941645  0.85903814  0.84875622]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85259654196059564"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "rf = RandomForestClassifier(n_estimators= 100, random_state=123) #best tweaked solution above\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score for each K\",scores_rf)\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation results are consistant, suggesting the model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Support Vector Machine - Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a linear SVM with default settings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "other svc Accuracy Score 0.847543160691\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.60      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10530   830]\n",
      " [ 1466  2234]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.92031873   5.51128818]\n",
      " [  9.73439575  14.83399734]]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "linsvm = SVC(kernel='linear', probability=True, random_state=123) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "linsvm.fit(features_train, target_train)\n",
    "predicted_linsvm=linsvm.predict(features_test)\n",
    "print(linsvm)\n",
    "print(\"other svc Accuracy Score\", accuracy_score(target_test, predicted_linsvm))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_linsvm, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_linsvm))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_linsvm))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default settings produced an accuracy of 84.8%.  Let's try a grid search of the penalty parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 10}\n",
      "Best Score: 0.846827133479\n",
      "Best Estimator SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1213.355169</td>\n",
       "      <td>24.631265</td>\n",
       "      <td>0.845932</td>\n",
       "      <td>0.848037</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.848730</td>\n",
       "      <td>0.842533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.848481</td>\n",
       "      <td>0.848972</td>\n",
       "      <td>0.846498</td>\n",
       "      <td>0.849610</td>\n",
       "      <td>0.847085</td>\n",
       "      <td>7.905853</td>\n",
       "      <td>0.461572</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280.917448</td>\n",
       "      <td>23.718765</td>\n",
       "      <td>0.846595</td>\n",
       "      <td>0.848949</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.843030</td>\n",
       "      <td>0.850305</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847340</td>\n",
       "      <td>0.849559</td>\n",
       "      <td>0.848806</td>\n",
       "      <td>0.846830</td>\n",
       "      <td>0.850274</td>\n",
       "      <td>0.847913</td>\n",
       "      <td>10.501179</td>\n",
       "      <td>0.230276</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1340.921759</td>\n",
       "      <td>23.459390</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.847120</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>8.364369</td>\n",
       "      <td>0.553893</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393.728676</td>\n",
       "      <td>23.118766</td>\n",
       "      <td>0.846794</td>\n",
       "      <td>0.848966</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C': 15}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.847244</td>\n",
       "      <td>0.850605</td>\n",
       "      <td>0.847748</td>\n",
       "      <td>15.020301</td>\n",
       "      <td>0.532957</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307.180304</td>\n",
       "      <td>19.578143</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.848941</td>\n",
       "      <td>20</td>\n",
       "      <td>{'C': 20}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.844190</td>\n",
       "      <td>0.850097</td>\n",
       "      <td>0.843196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846677</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.847120</td>\n",
       "      <td>0.850439</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>239.990557</td>\n",
       "      <td>4.501596</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0    1213.355169        24.631265         0.845932          0.848037       1   \n",
       "1    1280.917448        23.718765         0.846595          0.848949       5   \n",
       "2    1340.921759        23.459390         0.846827          0.849007      10   \n",
       "3    1393.728676        23.118766         0.846794          0.848966      15   \n",
       "4    1307.180304        19.578143         0.846562          0.848941      20   \n",
       "\n",
       "      params  rank_test_score  split0_test_score  split0_train_score  \\\n",
       "0   {'C': 1}                5           0.841372            0.848730   \n",
       "1   {'C': 5}                3           0.843030            0.850305   \n",
       "2  {'C': 10}                1           0.844025            0.850139   \n",
       "3  {'C': 15}                2           0.844356            0.850139   \n",
       "4  {'C': 20}                4           0.844190            0.850097   \n",
       "\n",
       "   split1_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.842533       ...                  0.847174            0.848481   \n",
       "1           0.843527       ...                  0.847340            0.849559   \n",
       "2           0.843693       ...                  0.846842            0.849683   \n",
       "3           0.843527       ...                  0.847174            0.849434   \n",
       "4           0.843196       ...                  0.846677            0.849434   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.848972            0.846498           0.849610   \n",
       "1           0.848806            0.846830           0.850274   \n",
       "2           0.848641            0.847120           0.850937   \n",
       "3           0.848309            0.847244           0.850605   \n",
       "4           0.848309            0.847120           0.850439   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.847085      7.905853        0.461572        0.003366   \n",
       "1            0.847913     10.501179        0.230276        0.002867   \n",
       "2            0.847872      8.364369        0.553893        0.002751   \n",
       "3            0.847748     15.020301        0.532957        0.002591   \n",
       "4            0.847789    239.990557        4.501596        0.002648   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.001076  \n",
       "1         0.001356  \n",
       "2         0.001270  \n",
       "3         0.001243  \n",
       "4         0.001263  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[1,5,10,15,20]}\n",
    "\n",
    "grid_search = GridSearchCV(linsvm, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search revealed a C of 10 as best. Let's run the model with that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other svc Accuracy Score 0.847875166003\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.61      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10519   841]\n",
      " [ 1450  2250]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.84727756   5.58432935]\n",
      " [  9.62815405  14.94023904]]\n"
     ]
    }
   ],
   "source": [
    "linsvm = SVC(C=10, kernel='linear', probability=True, random_state=123) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "linsvm.fit(features_train, target_train)\n",
    "predicted_linsvm=linsvm.predict(features_test)\n",
    "print(\"other svc Accuracy Score\", accuracy_score(target_test, predicted_linsvm))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_linsvm, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_linsvm))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_linsvm))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased slightly but is virtually unchanged.  Now let's try a grid search of the degree of the polynomial function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'degree': 1}\n",
      "Best Score: 0.846827133479\n",
      "Best Estimator SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=1, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1342.590867</td>\n",
       "      <td>23.746890</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>1</td>\n",
       "      <td>{'degree': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>12.942726</td>\n",
       "      <td>0.742633</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1339.347711</td>\n",
       "      <td>23.265639</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>2</td>\n",
       "      <td>{'degree': 2}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>10.185917</td>\n",
       "      <td>0.512253</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1338.544585</td>\n",
       "      <td>23.462514</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>3</td>\n",
       "      <td>{'degree': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>14.793538</td>\n",
       "      <td>0.305004</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.397711</td>\n",
       "      <td>23.290639</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>4</td>\n",
       "      <td>{'degree': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>13.677162</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1212.723884</td>\n",
       "      <td>21.259387</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>5</td>\n",
       "      <td>{'degree': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>250.364330</td>\n",
       "      <td>4.835949</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0    1342.590867        23.746890         0.846827          0.849007   \n",
       "1    1339.347711        23.265639         0.846827          0.849007   \n",
       "2    1338.544585        23.462514         0.846827          0.849007   \n",
       "3    1338.397711        23.290639         0.846827          0.849007   \n",
       "4    1212.723884        21.259387         0.846827          0.849007   \n",
       "\n",
       "  param_degree         params  rank_test_score  split0_test_score  \\\n",
       "0            1  {'degree': 1}                1           0.844025   \n",
       "1            2  {'degree': 2}                1           0.844025   \n",
       "2            3  {'degree': 3}                1           0.844025   \n",
       "3            4  {'degree': 4}                1           0.844025   \n",
       "4            5  {'degree': 5}                1           0.844025   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.850139           0.843693       ...                  0.846842   \n",
       "1            0.850139           0.843693       ...                  0.846842   \n",
       "2            0.850139           0.843693       ...                  0.846842   \n",
       "3            0.850139           0.843693       ...                  0.846842   \n",
       "4            0.850139           0.843693       ...                  0.846842   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.849683           0.848641             0.84712   \n",
       "1            0.849683           0.848641             0.84712   \n",
       "2            0.849683           0.848641             0.84712   \n",
       "3            0.849683           0.848641             0.84712   \n",
       "4            0.849683           0.848641             0.84712   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.850937            0.847872     12.942726        0.742633   \n",
       "1           0.850937            0.847872     10.185917        0.512253   \n",
       "2           0.850937            0.847872     14.793538        0.305004   \n",
       "3           0.850937            0.847872     13.677162        0.501815   \n",
       "4           0.850937            0.847872    250.364330        4.835949   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.002751          0.00127  \n",
       "1        0.002751          0.00127  \n",
       "2        0.002751          0.00127  \n",
       "3        0.002751          0.00127  \n",
       "4        0.002751          0.00127  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'degree':[1,2,3,4,5]}\n",
    "\n",
    "grid_search = GridSearchCV(linsvm, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search revelaed a degree of 1 to be best, though it's effectivly tied with the other degrees per the grid search above.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other svc Accuracy Score 0.847875166003\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.61      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10519   841]\n",
      " [ 1450  2250]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.84727756   5.58432935]\n",
      " [  9.62815405  14.94023904]]\n"
     ]
    }
   ],
   "source": [
    "linsvm = SVC(C=10, kernel='linear', degree=1, probability=True, random_state=123) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "linsvm.fit(features_train, target_train)\n",
    "predicted_linsvm=linsvm.predict(features_test)\n",
    "print(\"other svc Accuracy Score\", accuracy_score(target_test, predicted_linsvm))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_linsvm, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_linsvm))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_linsvm))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is virtually unchanged.  Now let's cross validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.8435532   0.84653629  0.84819357  0.83924428  0.84615385  0.85013263\n",
      "  0.84615385  0.84913793  0.85538972  0.84742952]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84719248315292117"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Linear SVC with Cross Validation\n",
    "scores = cross_val_score(linsvm, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the linear SVC are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###SVM-RBF \n",
    "Now let's try the SVM-RBF with default parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "RBF Accuracy Score 0.827224435591\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.91      0.89     11360\n",
      "     > $50K       0.68      0.57      0.62      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10358  1002]\n",
      " [ 1600  2100]]\n",
      "Confusion Matrix Percent\n",
      "[[ 68.77822045   6.65338645]\n",
      " [ 10.62416999  13.94422311]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_rbf = SVC(kernel='rbf', random_state=123) \n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "print(clf_rbf)\n",
    "print(\"RBF Accuracy Score\", accuracy_score(target_test, predicted_rbf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_rbf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_rbf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_rbf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model calculates 82.7% accuracy.  Now let's run a grid search of the penalty parameter, C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 20}\n",
      "Best Score: 0.843147006167\n",
      "Best Estimator SVC(C=20, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199.820558</td>\n",
       "      <td>29.068766</td>\n",
       "      <td>0.818679</td>\n",
       "      <td>0.819118</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.822311</td>\n",
       "      <td>0.820962</td>\n",
       "      <td>0.813691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.817813</td>\n",
       "      <td>0.829410</td>\n",
       "      <td>0.821384</td>\n",
       "      <td>0.815785</td>\n",
       "      <td>0.817165</td>\n",
       "      <td>1.626299</td>\n",
       "      <td>0.382428</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196.542675</td>\n",
       "      <td>28.128142</td>\n",
       "      <td>0.823122</td>\n",
       "      <td>0.823984</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826952</td>\n",
       "      <td>0.827137</td>\n",
       "      <td>0.817006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.822330</td>\n",
       "      <td>0.834052</td>\n",
       "      <td>0.825528</td>\n",
       "      <td>0.820262</td>\n",
       "      <td>0.822096</td>\n",
       "      <td>1.025101</td>\n",
       "      <td>0.448240</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183.084490</td>\n",
       "      <td>26.428143</td>\n",
       "      <td>0.835522</td>\n",
       "      <td>0.836931</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.835074</td>\n",
       "      <td>0.838410</td>\n",
       "      <td>0.830433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835074</td>\n",
       "      <td>0.836089</td>\n",
       "      <td>0.841844</td>\n",
       "      <td>0.835433</td>\n",
       "      <td>0.835185</td>\n",
       "      <td>0.836352</td>\n",
       "      <td>1.443149</td>\n",
       "      <td>0.484385</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181.390741</td>\n",
       "      <td>25.881264</td>\n",
       "      <td>0.838439</td>\n",
       "      <td>0.840238</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.838720</td>\n",
       "      <td>0.841436</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839383</td>\n",
       "      <td>0.839073</td>\n",
       "      <td>0.843170</td>\n",
       "      <td>0.839121</td>\n",
       "      <td>0.837340</td>\n",
       "      <td>0.840454</td>\n",
       "      <td>2.196188</td>\n",
       "      <td>0.462943</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181.381365</td>\n",
       "      <td>25.903141</td>\n",
       "      <td>0.841058</td>\n",
       "      <td>0.843106</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C': 15}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.841870</td>\n",
       "      <td>0.844005</td>\n",
       "      <td>0.837394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840875</td>\n",
       "      <td>0.841104</td>\n",
       "      <td>0.845656</td>\n",
       "      <td>0.842644</td>\n",
       "      <td>0.839496</td>\n",
       "      <td>0.842858</td>\n",
       "      <td>3.169261</td>\n",
       "      <td>0.263205</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158.227068</td>\n",
       "      <td>21.637511</td>\n",
       "      <td>0.843147</td>\n",
       "      <td>0.845203</td>\n",
       "      <td>20</td>\n",
       "      <td>{'C': 20}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>0.846160</td>\n",
       "      <td>0.838555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842864</td>\n",
       "      <td>0.843549</td>\n",
       "      <td>0.848806</td>\n",
       "      <td>0.844965</td>\n",
       "      <td>0.840822</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>30.621704</td>\n",
       "      <td>4.281204</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0     199.820558        29.068766         0.818679          0.819118     0.5   \n",
       "1     196.542675        28.128142         0.823122          0.823984       1   \n",
       "2     183.084490        26.428143         0.835522          0.836931       5   \n",
       "3     181.390741        25.881264         0.838439          0.840238      10   \n",
       "4     181.381365        25.903141         0.841058          0.843106      15   \n",
       "5     158.227068        21.637511         0.843147          0.845203      20   \n",
       "\n",
       "       params  rank_test_score  split0_test_score  split0_train_score  \\\n",
       "0  {'C': 0.5}                6           0.822311            0.820962   \n",
       "1    {'C': 1}                5           0.826952            0.827137   \n",
       "2    {'C': 5}                4           0.835074            0.838410   \n",
       "3   {'C': 10}                3           0.838720            0.841436   \n",
       "4   {'C': 15}                2           0.841870            0.844005   \n",
       "5   {'C': 20}                1           0.844688            0.846160   \n",
       "\n",
       "   split1_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.813691       ...                  0.812200            0.817813   \n",
       "1           0.817006       ...                  0.817338            0.822330   \n",
       "2           0.830433       ...                  0.835074            0.836089   \n",
       "3           0.833582       ...                  0.839383            0.839073   \n",
       "4           0.837394       ...                  0.840875            0.841104   \n",
       "5           0.838555       ...                  0.842864            0.843549   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.829410            0.821384           0.815785   \n",
       "1           0.834052            0.825528           0.820262   \n",
       "2           0.841844            0.835433           0.835185   \n",
       "3           0.843170            0.839121           0.837340   \n",
       "4           0.845656            0.842644           0.839496   \n",
       "5           0.848806            0.844965           0.840822   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.817165      1.626299        0.382428        0.006381   \n",
       "1            0.822096      1.025101        0.448240        0.006529   \n",
       "2            0.836352      1.443149        0.484385        0.003644   \n",
       "3            0.840454      2.196188        0.462943        0.003103   \n",
       "4            0.842858      3.169261        0.263205        0.002746   \n",
       "5            0.844101     30.621704        4.281204        0.003492   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.001719  \n",
       "1         0.001998  \n",
       "2         0.001228  \n",
       "3         0.000983  \n",
       "4         0.001294  \n",
       "5         0.001346  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[.5,1,5,10,15,20]}\n",
    "grid_search = GridSearchCV(clf_rbf, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search shows that the best C is 20.  Let's run the model with that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Accuracy Score 0.842762284197\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.93      0.90     11360\n",
      "     > $50K       0.73      0.58      0.64      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10551   809]\n",
      " [ 1559  2141]]\n",
      "Confusion Matrix Percent\n",
      "[[ 70.05976096   5.37184595]\n",
      " [ 10.35192563  14.21646746]]\n"
     ]
    }
   ],
   "source": [
    "clf_rbf = SVC(kernel='rbf', C=20.0, random_state=123) \n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"RBF Accuracy Score\", accuracy_score(target_test, predicted_rbf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_rbf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_rbf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_rbf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model showed am improvement from 82.7% to 84.3% accuracy.  Now let's try it with a class weight of balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Accuracy Score 0.791965471448\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.94      0.77      0.85     11360\n",
      "     > $50K       0.55      0.85      0.67      3700\n",
      "\n",
      "avg / total       0.85      0.79      0.80     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[8771 2589]\n",
      " [ 544 3156]]\n",
      "Confusion Matrix Percent\n",
      "[[ 58.24037185  17.19123506]\n",
      " [  3.6122178   20.9561753 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=20, random_state=123, class_weight='balanced') #degree=3, gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"RBF Accuracy Score\", accuracy_score(target_test, predicted_rbf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_rbf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_rbf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_rbf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance dropped from 84.3% to 79.2% accuracy with the balanced setting, so we won't use that setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the SVC-RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83891283  0.84852502  0.84255883  0.833941    0.8494695   0.83919098\n",
      "  0.84980106  0.84781167  0.84676617  0.8371476 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84341246605033382"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify SVC-RBF with Cross Validation\n",
    "clf_rbf = SVC(kernel='rbf', C=20.0, random_state=123, probability=True) \n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "scores = cross_val_score(clf_rbf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the SVC-RBF are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the ANN with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "NN Accuracy Score 0.848671978752\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.61      0.67      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10518   842]\n",
      " [ 1437  2263]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.84063745   5.59096946]\n",
      " [  9.54183267  15.02656042]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(random_state=123) \n",
    "clf_NN.fit(features_train, target_train)\n",
    "predicted_NN = clf_NN.predict(features_test)\n",
    "print(clf_NN)\n",
    "print(\"NN Accuracy Score\", accuracy_score(target_test, predicted_NN))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_NN, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_NN))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_NN))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net had an accuracy score of 84.9%.  First let's find the optimal L2 penalty via a grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'alpha': 0.01}\n",
      "Best Score: 0.850772495193\n",
      "Best Estimator MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.142757</td>\n",
       "      <td>0.049997</td>\n",
       "      <td>0.849977</td>\n",
       "      <td>0.868734</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>{'alpha': 1e-07}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.847008</td>\n",
       "      <td>0.866468</td>\n",
       "      <td>0.846179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852975</td>\n",
       "      <td>0.869866</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>0.869706</td>\n",
       "      <td>0.854585</td>\n",
       "      <td>0.868095</td>\n",
       "      <td>12.059963</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.043809</td>\n",
       "      <td>0.043752</td>\n",
       "      <td>0.848916</td>\n",
       "      <td>0.868560</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.846345</td>\n",
       "      <td>0.866841</td>\n",
       "      <td>0.844522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852312</td>\n",
       "      <td>0.869452</td>\n",
       "      <td>0.848475</td>\n",
       "      <td>0.869581</td>\n",
       "      <td>0.852927</td>\n",
       "      <td>0.867183</td>\n",
       "      <td>11.082648</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.181305</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.849579</td>\n",
       "      <td>0.869372</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.847505</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.845682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850655</td>\n",
       "      <td>0.871358</td>\n",
       "      <td>0.847977</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>0.869007</td>\n",
       "      <td>10.864212</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.993808</td>\n",
       "      <td>0.046880</td>\n",
       "      <td>0.850507</td>\n",
       "      <td>0.868692</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.866799</td>\n",
       "      <td>0.848334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851981</td>\n",
       "      <td>0.870198</td>\n",
       "      <td>0.849469</td>\n",
       "      <td>0.869043</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.868054</td>\n",
       "      <td>10.619945</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.562556</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.849778</td>\n",
       "      <td>0.868402</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.866302</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849826</td>\n",
       "      <td>0.868291</td>\n",
       "      <td>0.850464</td>\n",
       "      <td>0.868960</td>\n",
       "      <td>0.855745</td>\n",
       "      <td>0.869297</td>\n",
       "      <td>4.018548</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73.875046</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.850772</td>\n",
       "      <td>0.865576</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.862821</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>7.449164</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.968775</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.848352</td>\n",
       "      <td>0.852405</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>0.850843</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851815</td>\n",
       "      <td>0.853703</td>\n",
       "      <td>0.856598</td>\n",
       "      <td>0.851678</td>\n",
       "      <td>0.845299</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>8.294496</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.978144</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>0.841821</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>0.842969</td>\n",
       "      <td>0.833085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.843922</td>\n",
       "      <td>0.846320</td>\n",
       "      <td>0.842685</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.843728</td>\n",
       "      <td>6.443358</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.950011</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.839102</td>\n",
       "      <td>0.840122</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.839715</td>\n",
       "      <td>0.839985</td>\n",
       "      <td>0.832587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835737</td>\n",
       "      <td>0.840938</td>\n",
       "      <td>0.845988</td>\n",
       "      <td>0.840116</td>\n",
       "      <td>0.841486</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>3.433784</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      98.142757         0.049997         0.849977          0.868734   \n",
       "1      93.043809         0.043752         0.848916          0.868560   \n",
       "2      91.181305         0.050008         0.849579          0.869372   \n",
       "3      90.993808         0.046880         0.850507          0.868692   \n",
       "4      84.562556         0.043753         0.849778          0.868402   \n",
       "5      73.875046         0.050003         0.850772          0.865576   \n",
       "6      40.968775         0.050000         0.848352          0.852405   \n",
       "7      25.978144         0.043748         0.841821          0.843810   \n",
       "8      21.950011         0.037500         0.839102          0.840122   \n",
       "\n",
       "  param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0       1e-07   {'alpha': 1e-07}                3           0.847008   \n",
       "1       1e-06   {'alpha': 1e-06}                6           0.846345   \n",
       "2       1e-05   {'alpha': 1e-05}                5           0.847505   \n",
       "3      0.0001  {'alpha': 0.0001}                2           0.847174   \n",
       "4       0.001   {'alpha': 0.001}                4           0.846014   \n",
       "5        0.01    {'alpha': 0.01}                1           0.844853   \n",
       "6         0.1     {'alpha': 0.1}                7           0.844688   \n",
       "7         0.3     {'alpha': 0.3}                8           0.843362   \n",
       "8         0.5     {'alpha': 0.5}                9           0.839715   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.866468           0.846179       ...                  0.852975   \n",
       "1            0.866841           0.844522       ...                  0.852312   \n",
       "2            0.867089           0.845682       ...                  0.850655   \n",
       "3            0.866799           0.848334       ...                  0.851981   \n",
       "4            0.866302           0.846842       ...                  0.849826   \n",
       "5            0.866136           0.846014       ...                  0.857285   \n",
       "6            0.850843           0.843362       ...                  0.851815   \n",
       "7            0.842969           0.833085       ...                  0.841372   \n",
       "8            0.839985           0.832587       ...                  0.835737   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.869866           0.849138            0.869706   \n",
       "1            0.869452           0.848475            0.869581   \n",
       "2            0.871358           0.847977            0.869333   \n",
       "3            0.870198           0.849469            0.869043   \n",
       "4            0.868291           0.850464            0.868960   \n",
       "5            0.862821           0.850133            0.866059   \n",
       "6            0.853703           0.856598            0.851678   \n",
       "7            0.843922           0.846320            0.842685   \n",
       "8            0.840938           0.845988            0.840116   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.854585            0.868095     12.059963        0.006250   \n",
       "1           0.852927            0.867183     11.082648        0.006250   \n",
       "2           0.856077            0.869007     10.864212        0.011690   \n",
       "3           0.855580            0.868054     10.619945        0.009880   \n",
       "4           0.855745            0.869297      4.018548        0.011691   \n",
       "5           0.855580            0.866769      7.449164        0.006248   \n",
       "6           0.845299            0.849985      8.294496        0.006251   \n",
       "7           0.844968            0.843728      6.443358        0.006246   \n",
       "8           0.841486            0.840164      3.433784        0.007652   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.003291         0.001297  \n",
       "1        0.003278         0.001272  \n",
       "2        0.003617         0.001399  \n",
       "3        0.002994         0.001169  \n",
       "4        0.003431         0.001106  \n",
       "5        0.004972         0.001402  \n",
       "6        0.005053         0.002105  \n",
       "7        0.004670         0.001071  \n",
       "8        0.004631         0.000490  \n",
       "\n",
       "[9 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'alpha':[.0000001,.000001,.00001,.0001,.001,.01,.1,.3,.5]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_NN, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search found an alpha of 0.01, so let's run the model with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy Score 0.849070385126\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.74      0.59      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10591   769]\n",
      " [ 1504  2196]]\n",
      "Confusion Matrix Percent\n",
      "[[ 70.32536521   5.1062417 ]\n",
      " [  9.98671979  14.58167331]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(alpha=0.01, random_state=123)\n",
    "clf_NN.fit(features_train, target_train)\n",
    "predicted_NN = clf_NN.predict(features_test)\n",
    "print(\"NN Accuracy Score\", accuracy_score(target_test, predicted_NN))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_NN, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_NN))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_NN))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased slightly but still rounds to 84.9%.  Now let's try adjusting the layer sizes (number of neurons) in the neural net via grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'hidden_layer_sizes': (100,)}\n",
      "Best Score: 0.850772495193\n",
      "Best Estimator MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.115970</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.847855</td>\n",
       "      <td>0.850292</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>{'hidden_layer_sizes': (2,)}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.844522</td>\n",
       "      <td>0.851382</td>\n",
       "      <td>0.842035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851152</td>\n",
       "      <td>0.850926</td>\n",
       "      <td>0.851790</td>\n",
       "      <td>0.849192</td>\n",
       "      <td>0.849776</td>\n",
       "      <td>0.848991</td>\n",
       "      <td>3.547946</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.703139</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.848220</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>{'hidden_layer_sizes': (5,)}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>0.849766</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850489</td>\n",
       "      <td>0.848978</td>\n",
       "      <td>0.853282</td>\n",
       "      <td>0.848363</td>\n",
       "      <td>0.848615</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>1.526172</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.193773</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.850043</td>\n",
       "      <td>0.853765</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>{'hidden_layer_sizes': (10,)}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847505</td>\n",
       "      <td>0.855402</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.854739</td>\n",
       "      <td>0.851956</td>\n",
       "      <td>0.852549</td>\n",
       "      <td>0.853921</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>7.829595</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.868785</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.863661</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{'hidden_layer_sizes': (50,)}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.846345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851152</td>\n",
       "      <td>0.863235</td>\n",
       "      <td>0.851127</td>\n",
       "      <td>0.861210</td>\n",
       "      <td>0.854916</td>\n",
       "      <td>0.863827</td>\n",
       "      <td>9.800606</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.787553</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.850772</td>\n",
       "      <td>0.865576</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'hidden_layer_sizes': (100,)}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.862821</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>18.023311</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98.315688</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.849910</td>\n",
       "      <td>0.866256</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>{'hidden_layer_sizes': (200,)}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.845848</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849992</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.854443</td>\n",
       "      <td>0.869167</td>\n",
       "      <td>0.854916</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>15.953529</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.002624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>170.538053</td>\n",
       "      <td>0.146872</td>\n",
       "      <td>0.847722</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>(400,)</td>\n",
       "      <td>{'hidden_layer_sizes': (400,)}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.837394</td>\n",
       "      <td>0.861494</td>\n",
       "      <td>0.845848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854301</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>0.851625</td>\n",
       "      <td>0.871073</td>\n",
       "      <td>0.849445</td>\n",
       "      <td>0.867846</td>\n",
       "      <td>43.205338</td>\n",
       "      <td>0.027242</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      42.115970         0.015623         0.847855          0.850292   \n",
       "1      23.703139         0.015627         0.848220          0.849156   \n",
       "2      33.193773         0.015625         0.850043          0.853765   \n",
       "3      58.868785         0.028125         0.849513          0.863661   \n",
       "4      75.787553         0.046874         0.850772          0.865576   \n",
       "5      98.315688         0.106250         0.849910          0.866256   \n",
       "6     170.538053         0.146872         0.847722          0.867515   \n",
       "\n",
       "  param_hidden_layer_sizes                          params  rank_test_score  \\\n",
       "0                     (2,)    {'hidden_layer_sizes': (2,)}                6   \n",
       "1                     (5,)    {'hidden_layer_sizes': (5,)}                5   \n",
       "2                    (10,)   {'hidden_layer_sizes': (10,)}                2   \n",
       "3                    (50,)   {'hidden_layer_sizes': (50,)}                4   \n",
       "4                   (100,)  {'hidden_layer_sizes': (100,)}                1   \n",
       "5                   (200,)  {'hidden_layer_sizes': (200,)}                3   \n",
       "6                   (400,)  {'hidden_layer_sizes': (400,)}                7   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.844522            0.851382           0.842035       ...          \n",
       "1           0.845019            0.849766           0.843693       ...          \n",
       "2           0.847505            0.855402           0.844688       ...          \n",
       "3           0.844025            0.865183           0.846345       ...          \n",
       "4           0.844853            0.866136           0.846014       ...          \n",
       "5           0.845848            0.867131           0.844356       ...          \n",
       "6           0.837394            0.861494           0.845848       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.851152            0.850926           0.851790   \n",
       "1           0.850489            0.848978           0.853282   \n",
       "2           0.852147            0.854739           0.851956   \n",
       "3           0.851152            0.863235           0.851127   \n",
       "4           0.857285            0.862821           0.850133   \n",
       "5           0.849992            0.867255           0.854443   \n",
       "6           0.854301            0.870736           0.851625   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.849192           0.849776            0.848991      3.547946   \n",
       "1            0.848363           0.848615            0.849447      1.526172   \n",
       "2            0.852549           0.853921            0.852679      7.829595   \n",
       "3            0.861210           0.854916            0.863827      9.800606   \n",
       "4            0.866059           0.855580            0.866769     18.023311   \n",
       "5            0.869167           0.854916            0.861340     15.953529   \n",
       "6            0.871073           0.849445            0.867846     43.205338   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000004        0.003874         0.000995  \n",
       "1        0.000002        0.003512         0.000474  \n",
       "2        0.000006        0.003413         0.001130  \n",
       "3        0.006251        0.003864         0.001411  \n",
       "4        0.013968        0.004972         0.001402  \n",
       "5        0.026882        0.004312         0.002624  \n",
       "6        0.027242        0.005860         0.003481  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'hidden_layer_sizes':[(2,),(5,),(10,),(50,),(100,),(200,),(400,)]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_NN, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid serach determined 100 as the optimal hidden layer size.  Let's do a grid search on the length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'hidden_layer_sizes': (100,)}\n",
      "Best Score: 0.850772495193\n",
      "Best Estimator MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.369224</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.850772</td>\n",
       "      <td>0.865576</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'hidden_layer_sizes': (100,)}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.862821</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>7.075503</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.341985</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.847557</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 2)}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.866219</td>\n",
       "      <td>0.842533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849494</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.851459</td>\n",
       "      <td>0.870990</td>\n",
       "      <td>0.850274</td>\n",
       "      <td>0.870830</td>\n",
       "      <td>14.796522</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.018802</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.848651</td>\n",
       "      <td>0.865592</td>\n",
       "      <td>(100, 4)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 4)}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.848831</td>\n",
       "      <td>0.864520</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848666</td>\n",
       "      <td>0.865473</td>\n",
       "      <td>0.848972</td>\n",
       "      <td>0.869416</td>\n",
       "      <td>0.852429</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>16.146463</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.737539</td>\n",
       "      <td>0.053128</td>\n",
       "      <td>0.849678</td>\n",
       "      <td>0.868618</td>\n",
       "      <td>(100, 6)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 6)}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.850157</td>\n",
       "      <td>0.868581</td>\n",
       "      <td>0.841538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.869410</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.865562</td>\n",
       "      <td>0.855745</td>\n",
       "      <td>0.868965</td>\n",
       "      <td>5.694844</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.001668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.621920</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.870441</td>\n",
       "      <td>(100, 8)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 8)}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.848003</td>\n",
       "      <td>0.874135</td>\n",
       "      <td>0.837560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844522</td>\n",
       "      <td>0.868208</td>\n",
       "      <td>0.849469</td>\n",
       "      <td>0.869001</td>\n",
       "      <td>0.854585</td>\n",
       "      <td>0.871700</td>\n",
       "      <td>17.381836</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.002187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      73.369224         0.043753         0.850772          0.865576   \n",
       "1     114.341985         0.046874         0.847557          0.869588   \n",
       "2      85.018802         0.050005         0.848651          0.865592   \n",
       "3      63.737539         0.053128         0.849678          0.868618   \n",
       "4      73.621920         0.043753         0.846827          0.870441   \n",
       "\n",
       "  param_hidden_layer_sizes                            params  rank_test_score  \\\n",
       "0                   (100,)    {'hidden_layer_sizes': (100,)}                1   \n",
       "1                 (100, 2)  {'hidden_layer_sizes': (100, 2)}                4   \n",
       "2                 (100, 4)  {'hidden_layer_sizes': (100, 4)}                3   \n",
       "3                 (100, 6)  {'hidden_layer_sizes': (100, 6)}                2   \n",
       "4                 (100, 8)  {'hidden_layer_sizes': (100, 8)}                5   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.844853            0.866136           0.846014       ...          \n",
       "1           0.844025            0.866219           0.842533       ...          \n",
       "2           0.848831            0.864520           0.844356       ...          \n",
       "3           0.850157            0.868581           0.841538       ...          \n",
       "4           0.848003            0.874135           0.837560       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.857285            0.862821           0.850133   \n",
       "1           0.849494            0.868167           0.851459   \n",
       "2           0.848666            0.865473           0.848972   \n",
       "3           0.850820            0.869410           0.850133   \n",
       "4           0.844522            0.868208           0.849469   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.866059           0.855580            0.866769      7.075503   \n",
       "1            0.870990           0.850274            0.870830     14.796522   \n",
       "2            0.869416           0.852429            0.865526     16.146463   \n",
       "3            0.865562           0.855745            0.868965      5.694844   \n",
       "4            0.869001           0.854585            0.871700     17.381836   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.006253        0.004972         0.001402  \n",
       "1        0.000002        0.003580         0.002072  \n",
       "2        0.006246        0.002563         0.002115  \n",
       "3        0.007654        0.004578         0.001668  \n",
       "4        0.011694        0.005652         0.002187  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'hidden_layer_sizes':[(100,),(100,2),(100,4),(100,6),(100,8)]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_NN, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default was optimal.  Now let's run the model with the layers/nodes results from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy Score 0.849070385126\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.74      0.59      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10591   769]\n",
      " [ 1504  2196]]\n",
      "Confusion Matrix Percent\n",
      "[[ 70.32536521   5.1062417 ]\n",
      " [  9.98671979  14.58167331]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(alpha=0.01, hidden_layer_sizes=(100, ), random_state=123) \n",
    "clf_NN.fit(features_train, target_train)\n",
    "predicted_NN = clf_NN.predict(features_test)\n",
    "print(\"NN Accuracy Score\", accuracy_score(target_test, predicted_NN))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_NN, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_NN))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_NN))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy was unchanged.  Now let's cross validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.85084521  0.84918794  0.84819357  0.8435532   0.84781167  0.85311671\n",
      "  0.8428382   0.85344828  0.85704809  0.85339967]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84994425291271136"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify NN with Cross Validation\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation results are similar to each other, suggesting the model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to Stochastic Gradient Descent with default settings.  (Exception: the loss function is set to 'log', so it uses a logistic regression, not a linear one.  This is more appropriate for what we're trying to do - predict above/below $50K, and allows for calculation of area under the ROC curve later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=123, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "SGD Accuracy Score 0.829747675963\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.84      0.96      0.89     11360\n",
      "     > $50K       0.78      0.43      0.55      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.81     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10908   452]\n",
      " [ 2112  1588]]\n",
      "Confusion Matrix Percent\n",
      "[[ 72.43027888   3.00132802]\n",
      " [ 14.02390438  10.54448871]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf_sgd = linear_model.SGDClassifier(loss='log', random_state=123)\n",
    "clf_sgd.fit(features_train, target_train)\n",
    "predicted_sgd=clf_sgd.predict(features_test)\n",
    "print(clf_sgd)\n",
    "# summarize the fit of the model\n",
    "print(\"SGD Accuracy Score\", accuracy_score(target_test, predicted_sgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_sgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_sgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_sgd))/len(target_test.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SGD achieved an accuracy of 83.0%  Let's try adjusting the regularization term, alpha, with a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'alpha': 0.0001}\n",
      "Best Score: 0.833830647835\n",
      "Best Estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=123, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362490</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.797825</td>\n",
       "      <td>0.801357</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811371</td>\n",
       "      <td>0.821335</td>\n",
       "      <td>0.805404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823637</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.753813</td>\n",
       "      <td>0.748695</td>\n",
       "      <td>0.794893</td>\n",
       "      <td>0.795284</td>\n",
       "      <td>0.075501</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.028298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.412502</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.833831</td>\n",
       "      <td>0.834129</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831759</td>\n",
       "      <td>0.836338</td>\n",
       "      <td>0.834576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840212</td>\n",
       "      <td>0.839363</td>\n",
       "      <td>0.838196</td>\n",
       "      <td>0.834107</td>\n",
       "      <td>0.824407</td>\n",
       "      <td>0.821226</td>\n",
       "      <td>0.048007</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.006765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412502</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.833366</td>\n",
       "      <td>0.834751</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829604</td>\n",
       "      <td>0.836131</td>\n",
       "      <td>0.829604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831261</td>\n",
       "      <td>0.835426</td>\n",
       "      <td>0.841678</td>\n",
       "      <td>0.833527</td>\n",
       "      <td>0.834687</td>\n",
       "      <td>0.834280</td>\n",
       "      <td>0.032174</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.374999</td>\n",
       "      <td>0.018751</td>\n",
       "      <td>0.817784</td>\n",
       "      <td>0.818621</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.813691</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.815183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819161</td>\n",
       "      <td>0.818517</td>\n",
       "      <td>0.821784</td>\n",
       "      <td>0.817033</td>\n",
       "      <td>0.819101</td>\n",
       "      <td>0.820604</td>\n",
       "      <td>0.048413</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.421874</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.034227</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.063586</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.390626</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>2</td>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.029648</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.412497</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.409374</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.076802</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.362490         0.012496         0.797825          0.801357   \n",
       "1       0.412502         0.009377         0.833831          0.834129   \n",
       "2       0.412502         0.015624         0.833366          0.834751   \n",
       "3       0.374999         0.018751         0.817784          0.818621   \n",
       "4       0.421874         0.006248         0.751078          0.751078   \n",
       "5       0.512500         0.003126         0.751078          0.751078   \n",
       "6       0.400000         0.012502         0.751078          0.751078   \n",
       "7       0.390626         0.009375         0.751078          0.751078   \n",
       "8       0.412497         0.012501         0.751078          0.751078   \n",
       "9       0.409374         0.009375         0.751078          0.751078   \n",
       "\n",
       "  param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0       1e-05   {'alpha': 1e-05}                4           0.811371   \n",
       "1      0.0001  {'alpha': 0.0001}                1           0.831759   \n",
       "2       0.001   {'alpha': 0.001}                2           0.829604   \n",
       "3        0.01    {'alpha': 0.01}                3           0.813691   \n",
       "4         0.1     {'alpha': 0.1}                5           0.751036   \n",
       "5         0.5     {'alpha': 0.5}                5           0.751036   \n",
       "6           1       {'alpha': 1}                5           0.751036   \n",
       "7           2       {'alpha': 2}                5           0.751036   \n",
       "8           5       {'alpha': 5}                5           0.751036   \n",
       "9          10      {'alpha': 10}                5           0.751036   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.821335           0.805404       ...                  0.823637   \n",
       "1            0.836338           0.834576       ...                  0.840212   \n",
       "2            0.836131           0.829604       ...                  0.831261   \n",
       "3            0.817978           0.815183       ...                  0.819161   \n",
       "4            0.751088           0.751036       ...                  0.751036   \n",
       "5            0.751088           0.751036       ...                  0.751036   \n",
       "6            0.751088           0.751036       ...                  0.751036   \n",
       "7            0.751088           0.751036       ...                  0.751036   \n",
       "8            0.751088           0.751036       ...                  0.751036   \n",
       "9            0.751088           0.751036       ...                  0.751036   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.825397           0.753813            0.748695   \n",
       "1            0.839363           0.838196            0.834107   \n",
       "2            0.835426           0.841678            0.833527   \n",
       "3            0.818517           0.821784            0.817033   \n",
       "4            0.751088           0.751160            0.751057   \n",
       "5            0.751088           0.751160            0.751057   \n",
       "6            0.751088           0.751160            0.751057   \n",
       "7            0.751088           0.751160            0.751057   \n",
       "8            0.751088           0.751160            0.751057   \n",
       "9            0.751088           0.751160            0.751057   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.794893            0.795284      0.075501        0.006248   \n",
       "1           0.824407            0.821226      0.048007        0.012503   \n",
       "2           0.834687            0.834280      0.032174        0.013975   \n",
       "3           0.819101            0.820604      0.048413        0.015310   \n",
       "4           0.751119            0.751067      0.034227        0.007653   \n",
       "5           0.751119            0.751067      0.063586        0.006252   \n",
       "6           0.751119            0.751067      0.025388        0.006251   \n",
       "7           0.751119            0.751067      0.029648        0.007655   \n",
       "8           0.751119            0.751067      0.037761        0.006251   \n",
       "9           0.751119            0.751067      0.076802        0.007655   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.023886         0.028298  \n",
       "1        0.005539         0.006765  \n",
       "2        0.004551         0.000918  \n",
       "3        0.002938         0.001183  \n",
       "4        0.000053         0.000013  \n",
       "5        0.000053         0.000013  \n",
       "6        0.000053         0.000013  \n",
       "7        0.000053         0.000013  \n",
       "8        0.000053         0.000013  \n",
       "9        0.000053         0.000013  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"alpha\": [0.00001,0.0001,0.001,0.01,0.1,.5,1,2,5,10]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_sgd, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid serach found an alpha of 0.001 as best, so let's run the model with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy Score 0.834926958831\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.93      0.90     11360\n",
      "     > $50K       0.72      0.53      0.61      3700\n",
      "\n",
      "avg / total       0.83      0.83      0.83     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10596   764]\n",
      " [ 1722  1978]]\n",
      "Confusion Matrix Percent\n",
      "[[ 70.35856574   5.07304117]\n",
      " [ 11.43426295  13.13413015]]\n"
     ]
    }
   ],
   "source": [
    "clf_sgd = linear_model.SGDClassifier(alpha=0.001, loss='log', random_state=123)\n",
    "clf_sgd.fit(features_train, target_train)\n",
    "predicted_sgd=clf_sgd.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"SGD Accuracy Score\", accuracy_score(target_test, predicted_sgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_sgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_sgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_sgd))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased slightly from 83.0% to 83.5%.  Since the default setting relies on L2, let's set the model to L1 and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy Score 0.840239043825\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.94      0.90     11360\n",
      "     > $50K       0.74      0.55      0.63      3700\n",
      "\n",
      "avg / total       0.83      0.84      0.83     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10631   729]\n",
      " [ 1677  2023]]\n",
      "Confusion Matrix Percent\n",
      "[[ 70.59096946   4.84063745]\n",
      " [ 11.13545817  13.43293493]]\n"
     ]
    }
   ],
   "source": [
    "clf_sgd = linear_model.SGDClassifier(alpha=0.001, penalty='l1', loss='log', random_state=123)\n",
    "clf_sgd.fit(features_train, target_train)\n",
    "predicted_sgd=clf_sgd.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"SGD Accuracy Score\", accuracy_score(target_test, predicted_sgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_sgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_sgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_sgd))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy increased slightly using L1, from 83.5% to 84.0%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83427246  0.84023865  0.83791846  0.83162082  0.84084881  0.83852785\n",
      "  0.8418435   0.85079576  0.84809287  0.83217247]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83963316362595486"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify SGD with Cross Validation\n",
    "\n",
    "scores = cross_val_score(clf_sgd, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the SGD are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adaboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to Ada Boost, this time with the Decision Tree as the base learner (with a max depth of 9, which was the best result achieved above).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy Score 0.808897742364\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.89      0.88     11360\n",
      "     > $50K       0.62      0.56      0.59      3700\n",
      "\n",
      "avg / total       0.80      0.81      0.81     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10095  1265]\n",
      " [ 1613  2087]]\n",
      "Confusion Matrix Percent\n",
      "[[ 67.03187251   8.3997344 ]\n",
      " [ 10.71049137  13.85790173]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=9,random_state=123))#, algorithm=\"SAMME\", n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "print(\"Adaboost Accuracy Score\", accuracy_score(target_test, predicted_bdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the decision tree classifier as its base, an accuracy of 80.9% was achieved, which is worse than the 84.2% achieved by the decision tree alone.  Let's try it now with a SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy Score 0.754316069057\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.75      1.00      0.86     11360\n",
      "     > $50K       0.00      0.00      0.00      3700\n",
      "\n",
      "avg / total       0.57      0.75      0.65     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "Confusion Matrix Percent\n",
      "[[ 75.43160691   0.        ]\n",
      " [ 24.56839309   0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "bsgd = AdaBoostClassifier(linear_model.SGDClassifier(alpha=0.001, penalty='l1', loss='log', random_state=123), algorithm='SAMME') #, , n_estimators=200)\n",
    "bsgd.fit(features_train, target_train)\n",
    "predicted_bsgd=bsgd.predict(features_test)\n",
    "print(\"Adaboost Accuracy Score\", accuracy_score(target_test, predicted_bsgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bsgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bsgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bsgd))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model didn't predict any values above $50K!  Obviously we wouldn't use this.  Now let's cross validate the AdaBoost using decisioon tree as the base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.82200862  0.81339079  0.81305933  0.80543586  0.81730769  0.81863395\n",
      "  0.81830239  0.82261273  0.8318408   0.81293532]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81755274806107825"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify ADA Boost with Cross Validation\n",
    "scores = cross_val_score(bdt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the ADA Boost are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the bagging classifier with the decision tree reached above as the base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bagging Classifer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier(base_estimator=(tree.DecisionTreeClassifier(max_depth=9,random_state=123)),random_state=123)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "print(\"Bagging Accuracy Score\", accuracy_score(target_test, predicted_bag))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bag, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bag))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bag))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bagging classifier had an accuracy of 84.6%.  Now let's run a grid search to find the best value of the number of base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [2,5,7,10]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_bag, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search found a value of 200 estimators to be best.  Let's run the model with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bagging Classifer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier(base_estimator=(tree.DecisionTreeClassifier(max_depth=9,random_state=123),n_estimators=200,random_state=123))\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "print(\"Bagging Accuracy Score\", accuracy_score(target_test, predicted_bag))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bag, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bag))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bag))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy improved to 83.7%.  Now let's run a grid search to determine the impact on max sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"max_samples\": [50,100,1000,5000,10000,15000]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_bag, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determmined a max_samples of 5000 was best.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bagging Classifer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier(n_estimators=200,max_samples=5000,random_state=123)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "print(\"Bagging Accuracy Score\", accuracy_score(target_test, predicted_bag))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bag, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bag))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bag))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased to 84.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify Bagging Classifier with Cross Validation\n",
    "scores = cross_val_score(clf_bag, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the bagging classifier are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Gradient Boosting \n",
    "Now we'll run the gradient boosting classifier with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier(random_state=123) #n_estimators=100, learning_rate=1.7, max_depth=1, random_state=0)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "print(clf_GBC)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "print(\"Gradient Boost Accuracy Score\", accuracy_score(target_test, predicted_GBC))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_GBC, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_GBC))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_GBC))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient Boost with default settings found an accuracy of 85.8%.  Let's try a grid search on the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [50,100,250,500,750,1000]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_GBC, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined the best number of estimators to be 500.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GBC = GradientBoostingClassifier(random_state=123, n_estimators=500) \n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "print(\"Gradient Boost Accuracy Score\", accuracy_score(target_test, predicted_GBC))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_GBC, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_GBC))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_GBC))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is virtually unchanged.  Now let's do a grid search on the max depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"max_depth\": [1,2,3,4,6,7]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_GBC, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined a max depth of 3 as optimal, which is the default setting.  Let's try a grid search on the learning rate to see the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"learning_rate\": [0.001,0.01, 0.05, 0.08, 0.1, 0.12, 0.15]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_GBC, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined a learning rate of 0.15 to be optimal.  Let's run the model with that figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_GBC = GradientBoostingClassifier(random_state=123, n_estimators=500, max_depth=3, learning_rate=0.15)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "print(\"Gradient Boost Accuracy Score\", accuracy_score(target_test, predicted_GBC))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_GBC, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_GBC))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_GBC))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performace is virtually unchanged."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we'll cross validate the gradient boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify GB with Cross Validation\n",
    "scores = cross_val_score(clf_GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the gradient boost are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Extra Trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the extra trees classifier with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xdt = ExtraTreesClassifier(random_state=123)\n",
    "xdt.fit(features_train, target_train)\n",
    "print(xdt)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "print(\"Extra Trees Accuracy Score\", accuracy_score(target_test, predicted_xdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_xdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_xdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_xdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy with default settings was 82.3%.  Let's do a grid search on the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [5,10,15,20,50,100]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xdt, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined that 50 was the best value for the number of estimators.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdt = ExtraTreesClassifier(random_state=123, n_estimators=50) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "print(\"Extra Trees Accuracy Score\", accuracy_score(target_test, predicted_xdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_xdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_xdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_xdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved slightly to 82.6%.  Now let's run a grid search on the depth of the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"max_depth\": [5,10,15,20,25,30,35,50,100,250]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xdt, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined 25 to be the best depth.  Let's run the model with that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdt = ExtraTreesClassifier(random_state=123, n_estimators=50, max_depth=25) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "print(\"Extra Trees Accuracy Score\", accuracy_score(target_test, predicted_xdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_xdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_xdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_xdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved to 84.6%.  Now we'll cross validate the extra trees classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify XDT with Cross Validation\n",
    "\n",
    "scores = cross_val_score(xdt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the extra trees classifier are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll stack 3 different models to see the result.  For the first stack we'll use KNN, Random Forest, and Extra Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#stack_ada = AdaBoostClassifier(base_estimator=SVC(C=10, kernel='linear', degree=3, probability=True, random_state=123), algorithm=\"SAMME\")\n",
    "stack_xdt = ExtraTreesClassifier(random_state=123, n_estimators=50, max_depth=25)\n",
    "stack_knn = KNeighborsClassifier(n_neighbors=20, p=2)\n",
    "stack_rf = RandomForestClassifier(n_estimators= 100, random_state=123)\n",
    "#stack_ada = AdaBoostClassifier(base_estimator=LinearSVC(random_state=123, penalty='l1', C=3, dual=False), algorithm=\"SAMME\")\n",
    "stack1 = VotingClassifier(estimators=[('rf', stack_rf), ('knn', stack_knn), ('xdt', stack_xdt)], voting='soft')\n",
    "for MV, label in zip([stack_rf, stack_knn, stack_ada, stack1], ['Random Forest', 'K Nearest Neighbor', 'Extra Trees', 'Ensemble']):\n",
    "\n",
    "    scores2 = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble performed at 86%, or the same as the random forest, so the boost in performance wasn't noticeable.  Perhaps these three models are classifying most of the same instances incorrectly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a different stack with these three models: bagging, decision tree, and SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import linear_model\n",
    "stack_bag = BaggingClassifier(n_estimators=200,max_samples=5000,random_state=123)\n",
    "stack_dt = tree.DecisionTreeClassifier(max_depth=9,random_state=123)\n",
    "stack_sgd = linear_model.SGDClassifier(alpha=0.001, penalty='l1', loss='log', random_state=123)\n",
    "\n",
    "stack2 = VotingClassifier(estimators=[('dt', stack_dt), ('sgd', stack_sgd), ('bag', stack_bag)], voting='soft')\n",
    "for MV, label in zip([stack_dt, stack_sgd, stack_bag, stack2], ['Decision Tree', 'Stochiastic Gradient Descent', 'Bagging', 'Ensemble']):\n",
    "\n",
    "    scores2 = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the ensemble model was the same as the highest rated model input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a different stack with linear SVC, Neural Network, and Gradient Boosting for the three input models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#stack_svml = LinearSVC(random_state=123, penalty='l1', C=3, dual=False)\n",
    "stack_svml = SVC(C=10, kernel='linear', degree=3, probability=True, random_state=123)\n",
    "stack_nn = MLPClassifier(alpha=0.01, hidden_layer_sizes=(100, ), random_state=123)\n",
    "stack_gb = GradientBoostingClassifier(random_state=123, n_estimators=500, max_depth=3, learning_rate=0.15)\n",
    "stack3 = VotingClassifier(estimators=[('svml', stack_svml), ('nn', stack_nn), ('gb', stack_gb)], voting='soft')\n",
    "for MV, label in zip([stack_svml, stack_nn, stack_gb, stack3], ['Linear SVC', 'Neural Net', 'Gradient Boosting', 'Ensemble']):\n",
    "\n",
    "    scores2 = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the ensemble resulted in an accuracy of 0.86, and was actually less accurate the AdaBoost.  Next is some code to make predictions on the final stack that will be used to compare with other models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack3.fit(features_train, target_train)\n",
    "predicted_stack3=stack3.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross validate the final stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verify stack with Cross Validation\n",
    "scores = cross_val_score(stack3, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the stack are fairly close together, suggesting this ensemble isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of these models, we'll take a look at some different metrics.  First, we'll calculate the area under the ROC curves and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate area under ROC curves\n",
    "fpr_knn, tpr_knn, _ = roc_curve(target_test, knn.predict_proba(features_test)[:,1])\n",
    "fpr_dt, tpr_dt, _ = roc_curve(target_test, clf.predict_proba(features_test)[:,1]) \n",
    "fpr_rf, tpr_rf, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "fpr_lsvc, tpr_lsvc, _ = roc_curve(target_test, linsvm.predict_proba(features_test)[:,1]) \n",
    "fpr_rbf, tpr_rbf, _ = roc_curve(target_test, clf_rbf.predict_proba(features_test)[:,1]) \n",
    "fpr_nn, tpr_nn, _ = roc_curve(target_test, clf_NN.predict_proba(features_test)[:,1]) \n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(target_test, clf_sgd.predict_proba(features_test)[:,1]) \n",
    "fpr_bsvc, tpr_bsvc, _ = roc_curve(target_test, bsvc.predict_proba(features_test)[:,1]) \n",
    "fpr_bag, tpr_bag, _ = roc_curve(target_test, clf_bag.predict_proba(features_test)[:,1]) \n",
    "fpr_gbc, tpr_gbc, _ = roc_curve(target_test, clf_GBC.predict_proba(features_test)[:,1]) \n",
    "fpr_xdt, tpr_xdt, _ = roc_curve(target_test, xdt.predict_proba(features_test)[:,1]) \n",
    "fpr_stack, tpr_stack, _ = roc_curve(target_test, stack3.predict_proba(features_test)[:,1]) \n",
    "\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "roc_auc_lsvc = auc(fpr_lsvc, tpr_lsvc) \n",
    "roc_auc_rbf = auc(fpr_rbf, tpr_rbf)\n",
    "roc_auc_nn = auc(fpr_nn, tpr_nn)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) \n",
    "roc_auc_bsvc = auc(fpr_bsvc, tpr_bsvc)\n",
    "roc_auc_bag = auc(fpr_bag, tpr_bag)\n",
    "roc_auc_gbc = auc(fpr_gbc, tpr_gbc)\n",
    "roc_auc_xdt = auc(fpr_xdt, tpr_xdt)\n",
    "roc_auc_stack = auc(fpr_stack, tpr_stack)\n",
    "\n",
    "roc_auc_all =  {'ROC AUC':  [roc_auc_knn,\n",
    "    roc_auc_dt,\n",
    "    roc_auc_rf,\n",
    "    roc_auc_lsvc,\n",
    "    roc_auc_rbf,\n",
    "    roc_auc_nn,\n",
    "    roc_auc_sgd, \n",
    "    roc_auc_bsvc,\n",
    "    roc_auc_bag,\n",
    "    roc_auc_gbc,\n",
    "    roc_auc_xdt\n",
    "    roc_auc_stack\n",
    "]}\n",
    "    \n",
    "#roc_auc_all    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "\n",
    "#plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN (area = %0.3f)' % roc_auc_knn)\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree (area = %0.3f)' % roc_auc_dt)\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (area = %0.3f)' % roc_auc_rf)\n",
    "plt.plot(fpr_lsvc, tpr_lsvc, label='SVM Linear (area = %0.3f)' % roc_auc_lsvc)\n",
    "plt.plot(fpr_rbf, tpr_rbf, label='SVM RBF (area = %0.3f)' % roc_auc_rbf)\n",
    "plt.plot(fpr_nn, tpr_nn, label='ANN (area = %0.3f)' % roc_auc_nn)\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD (area = %0.3f)' % roc_auc_sgd)\n",
    "plt.plot(fpr_bsvc, tpr_bsvc, label='Adaboost (area = %0.3f)' % roc_auc_bsvc)\n",
    "plt.plot(fpr_bag, tpr_bag, label='Bagging (area = %0.3f)' % roc_auc_bag)\n",
    "plt.plot(fpr_gbc, tpr_gbc, label='Gradient Boosting (area = %0.3f)' % roc_auc_gbc)\n",
    "plt.plot(fpr_xdt, tpr_xdt, label='Extra Trees (area = %0.3f)' % roc_auc_xdt)\n",
    "plt.plot(fpr_stack, tpr_stack, label='Stacking (area = %0.3f)' % roc_auc_stack)\n",
    "\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc=\"right\")\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curves are quite close together but it appears ... is the best one.  Let's look at accuracy, precision, recall, ROC AUC, and F1 score for each of the models as tweaked for best perfomance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_data = {'Model': ['KNN',\n",
    "                          'Decision Tree',\n",
    "                          'Random Forest',\n",
    "                          'SVM Linear',\n",
    "                          'SVM RBF',\n",
    "                          'ANN',\n",
    "                          'SGD',\n",
    "                          'Adaboost',\n",
    "                          'Bagging',\n",
    "                          'Gradient Boosting',\n",
    "                          'Extra Trees',\n",
    "                          'Stacking'],\n",
    "    'Accuracy': [accuracy_score(target_test, target_predicted_knn), \n",
    "                 accuracy_score(target_test, target_predicted_dt),\n",
    "                 accuracy_score(target_test, target_predicted_rf),\n",
    "                 accuracy_score(target_test, predicted_SVC),\n",
    "                 accuracy_score(target_test, predicted_rbf),\n",
    "                 accuracy_score(target_test, predicted_NN),\n",
    "                 accuracy_score(target_test, predicted_sgd),\n",
    "                 accuracy_score(target_test, predicted_bsvc),\n",
    "                 accuracy_score(target_test, predicted_bag),\n",
    "                 accuracy_score(target_test, predicted_GBC),\n",
    "                 accuracy_score(target_test, predicted_xdt),\n",
    "                 accuracy_score(target_test, predicted_stack3)], \n",
    "    'Precision': [precision_score(target_test, target_predicted_knn),\n",
    "                  precision_score(target_test, target_predicted_dt),\n",
    "                  precision_score(target_test, target_predicted_rf),\n",
    "                  precision_score(target_test, predicted_SVC),\n",
    "                  precision_score(target_test, predicted_rbf),\n",
    "                  precision_score(target_test, predicted_NN),\n",
    "                  precision_score(target_test, predicted_sgd),\n",
    "                  precision_score(target_test, predicted_bsvc),\n",
    "                  precision_score(target_test, predicted_bag),\n",
    "                  precision_score(target_test, predicted_GBC),\n",
    "                  precision_score(target_test, predicted_xdt),\n",
    "                  precision_score(target_test, predicted_stack3)], \n",
    "        'Recall': [recall_score(target_test, target_predicted_knn), \n",
    "                   recall_score(target_test, target_predicted_dt),\n",
    "                   recall_score(target_test, target_predicted_rf),\n",
    "                   recall_score(target_test, predicted_SVC),\n",
    "                   recall_score(target_test, predicted_rbf),\n",
    "                   recall_score(target_test, predicted_NN),\n",
    "                   recall_score(target_test, predicted_sgd),\n",
    "                   recall_score(target_test, predicted_bsvc),\n",
    "                   recall_score(target_test, predicted_bag),\n",
    "                   recall_score(target_test, predicted_GBC),\n",
    "                   recall_score(target_test, predicted_xdt),\n",
    "                   recall_score(target_test, predicted_stack3)], \n",
    "     'F1 Score': [f1_score(target_test, target_predicted_knn), \n",
    "                  f1_score(target_test, target_predicted_dt),\n",
    "                  f1_score(target_test, target_predicted_rf),\n",
    "                  f1_score(target_test, predicted_SVC),\n",
    "                  f1_score(target_test, predicted_rbf),\n",
    "                  f1_score(target_test, predicted_NN),\n",
    "                  f1_score(target_test, predicted_sgd),\n",
    "                  f1_score(target_test, predicted_bsvc),\n",
    "                  f1_score(target_test, predicted_bag),\n",
    "                  f1_score(target_test, predicted_GBC),\n",
    "                  f1_score(target_test, predicted_xdt),\n",
    "                  f1_score(target_test, predicted_stack3)],\n",
    "               'ROC AUC':  [roc_auc_knn,\n",
    "                            roc_auc_dt,\n",
    "                            roc_auc_rf,\n",
    "                            roc_auc_lsvc,\n",
    "                            roc_auc_rbf,\n",
    "                            roc_auc_nn,\n",
    "                            roc_auc_sgd, \n",
    "                            roc_auc_bsvc,\n",
    "                            roc_auc_bag,\n",
    "                            roc_auc_gbc,\n",
    "                            roc_auc_xdt,\n",
    "                            roc_auc_stack]}\n",
    "\n",
    "model_metrics = pd.DataFrame(data=metrics_data)\n",
    "model_metrics = model_metrics.set_index('Model')\n",
    "pd.options.display.max_rows = 12\n",
    "model_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models overall had very similiar performance with no one model a clear standout from the others.  Overall accuracies were within a few percentage points of each other.  Precision and recall show more variation, with prcision varying between ... and recall varying between ...  Though incomes greater than $50K were the 'target' variable, it wasn't clear from the problem statement whether that was truly more important than predicting incomes below $50K.  If overall accuracy is desired, gradient boost and stacking have a slight edge over the others.  If precision is most important (that is, the smallest number of false positives), gradient boost is the best.  If recall is desired (that is, minimize false negatives) than RBF is best, but it sacrifices overall accuracy by having a large number of false positives.  Stacking and gradient boost had the best F1 scores.  Per previous results, none of the cross validation results showed overfitting.\n",
    "\n",
    "On the whole, it appears that the Gradient Boost is the best model, with Stacking a very close second.    \n",
    "Now, let's look at the list of features by importance for the Gradient Boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Features sorted by their score:\")\n",
    "print(\"Higher the more important\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), clf_GBC.feature_importances_),df.columns[1:20]), \n",
    "             reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
