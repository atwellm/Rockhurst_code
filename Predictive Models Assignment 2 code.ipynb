{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atwell - Assignment 2 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Package import, initial setup, and data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Mike/Desktop'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Change working directory if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\mlatw\\\\Desktop\\\\BIA6303\\\\Assignment_2'\n",
      "/Users/Mike/Desktop\n"
     ]
    }
   ],
   "source": [
    "cd C:\\\\Users\\\\mlatw\\\\Desktop\\\\BIA6303\\\\Assignment_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "The data is contained in two different files (train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_Class</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "      <th>Native_Country</th>\n",
       "      <th>Income_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age         Work_Class  Fnlwgt    Education  Education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            Marital_status          Occupation    Relationship    Race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           Sex  Capital_gain  Capital_loss  Hours_Per_Week  Native_Country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      Income_Class  \n",
       "0            <=50K  \n",
       "1            <=50K  \n",
       "2            <=50K  \n",
       "3            <=50K  \n",
       "4            <=50K  \n",
       "...            ...  \n",
       "32556        <=50K  \n",
       "32557         >50K  \n",
       "32558        <=50K  \n",
       "32559        <=50K  \n",
       "32560         >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import train data\n",
    "pd.options.display.max_rows = 10\n",
    "df_train = pd.read_csv(\"adult_train.data\", header=None, index_col=False, sep=\",\", na_values=\" ?\", names = ['Age','Work_Class','Fnlwgt','Education','Education_num','Marital_status','Occupation','Relationship','Race','Sex','Capital_gain','Capital_loss','Hours_Per_Week','Native_Country','Income_Class'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_Class</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "      <th>Native_Country</th>\n",
       "      <th>Income_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16281</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age     Work_Class    Fnlwgt      Education  Education_num  \\\n",
       "1      25        Private  226802.0           11th            7.0   \n",
       "2      38        Private   89814.0        HS-grad            9.0   \n",
       "3      28      Local-gov  336951.0     Assoc-acdm           12.0   \n",
       "4      44        Private  160323.0   Some-college           10.0   \n",
       "5      18            NaN  103497.0   Some-college           10.0   \n",
       "...    ..            ...       ...            ...            ...   \n",
       "16277  39        Private  215419.0      Bachelors           13.0   \n",
       "16278  64            NaN  321403.0        HS-grad            9.0   \n",
       "16279  38        Private  374983.0      Bachelors           13.0   \n",
       "16280  44        Private   83891.0      Bachelors           13.0   \n",
       "16281  35   Self-emp-inc  182148.0      Bachelors           13.0   \n",
       "\n",
       "            Marital_status          Occupation     Relationship  \\\n",
       "1            Never-married   Machine-op-inspct        Own-child   \n",
       "2       Married-civ-spouse     Farming-fishing          Husband   \n",
       "3       Married-civ-spouse     Protective-serv          Husband   \n",
       "4       Married-civ-spouse   Machine-op-inspct          Husband   \n",
       "5            Never-married                 NaN        Own-child   \n",
       "...                    ...                 ...              ...   \n",
       "16277             Divorced      Prof-specialty    Not-in-family   \n",
       "16278              Widowed                 NaN   Other-relative   \n",
       "16279   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16280             Divorced        Adm-clerical        Own-child   \n",
       "16281   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      Race      Sex  Capital_gain  Capital_loss  \\\n",
       "1                    Black     Male           0.0           0.0   \n",
       "2                    White     Male           0.0           0.0   \n",
       "3                    White     Male           0.0           0.0   \n",
       "4                    Black     Male        7688.0           0.0   \n",
       "5                    White   Female           0.0           0.0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16277                White   Female           0.0           0.0   \n",
       "16278                Black     Male           0.0           0.0   \n",
       "16279                White     Male           0.0           0.0   \n",
       "16280   Asian-Pac-Islander     Male        5455.0           0.0   \n",
       "16281                White     Male           0.0           0.0   \n",
       "\n",
       "       Hours_Per_Week  Native_Country Income_Class  \n",
       "1                40.0   United-States       <=50K.  \n",
       "2                50.0   United-States       <=50K.  \n",
       "3                40.0   United-States        >50K.  \n",
       "4                40.0   United-States        >50K.  \n",
       "5                30.0   United-States       <=50K.  \n",
       "...               ...             ...          ...  \n",
       "16277            36.0   United-States       <=50K.  \n",
       "16278            40.0   United-States       <=50K.  \n",
       "16279            50.0   United-States       <=50K.  \n",
       "16280            40.0   United-States       <=50K.  \n",
       "16281            60.0   United-States        >50K.  \n",
       "\n",
       "[16281 rows x 15 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import test data\n",
    "pd.options.display.max_rows = 10\n",
    "df_test = pd.read_csv(\"adult_test\", sep=\",\", na_values=\" ?\",names = ['Age','Work_Class','Fnlwgt','Education','Education_num','Marital_status','Occupation','Relationship','Race','Sex','Capital_gain','Capital_loss','Hours_Per_Week','Native_Country','Income_Class'])\n",
    "df_test = df_test.drop(df_test.index[0]) #drops initial row of non-data\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the data types of the train and test sets to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Type Age                int64\n",
      "Work_Class        object\n",
      "Fnlwgt             int64\n",
      "Education         object\n",
      "Education_num      int64\n",
      "Marital_status    object\n",
      "Occupation        object\n",
      "Relationship      object\n",
      "Race              object\n",
      "Sex               object\n",
      "Capital_gain       int64\n",
      "Capital_loss       int64\n",
      "Hours_Per_Week     int64\n",
      "Native_Country    object\n",
      "Income_Class      object\n",
      "dtype: object\n",
      "Test Data Type Age                object\n",
      "Work_Class         object\n",
      "Fnlwgt            float64\n",
      "Education          object\n",
      "Education_num     float64\n",
      "Marital_status     object\n",
      "Occupation         object\n",
      "Relationship       object\n",
      "Race               object\n",
      "Sex                object\n",
      "Capital_gain      float64\n",
      "Capital_loss      float64\n",
      "Hours_Per_Week    float64\n",
      "Native_Country     object\n",
      "Income_Class       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 15\n",
    "print(\"Training Data Type\", df_train.dtypes)\n",
    "print(\"Test Data Type\", df_test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Age' column in the test set is an object data type, but otherwise all of the columns with numbers are a numeric data type.  Now let's see if there are any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                  0\n",
       "Work_Class        1836\n",
       "Fnlwgt               0\n",
       "Education            0\n",
       "Education_num        0\n",
       "Marital_status       0\n",
       "Occupation        1843\n",
       "Relationship         0\n",
       "Race                 0\n",
       "Sex                  0\n",
       "Capital_gain         0\n",
       "Capital_loss         0\n",
       "Hours_Per_Week       0\n",
       "Native_Country     583\n",
       "Income_Class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 0\n",
       "Work_Class        963\n",
       "Fnlwgt              0\n",
       "Education           0\n",
       "Education_num       0\n",
       "Marital_status      0\n",
       "Occupation        966\n",
       "Relationship        0\n",
       "Race                0\n",
       "Sex                 0\n",
       "Capital_gain        0\n",
       "Capital_loss        0\n",
       "Hours_Per_Week      0\n",
       "Native_Country    274\n",
       "Income_Class        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three columns in both sets show null values: Work_Class, Occupation, and Native_Country.  Since the datasets are large relative to these values, we'll drop the rows with null values and still have plenty of data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape of Data (30162, 15)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "print(\"Train Shape of Data\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Shape of Data (15060, 15)\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test.dropna()\n",
    "print(\"Test Shape of Data\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the non-numeric columns to see what's in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Work Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set  Private             22286\n",
      " Self-emp-not-inc     2499\n",
      " Local-gov            2067\n",
      " State-gov            1279\n",
      " Self-emp-inc         1074\n",
      " Federal-gov           943\n",
      " Without-pay            14\n",
      "Name: Work_Class, dtype: int64\n",
      "Test Set  Private             11021\n",
      " Self-emp-not-inc     1297\n",
      " Local-gov            1033\n",
      " State-gov             667\n",
      " Self-emp-inc          572\n",
      " Federal-gov           463\n",
      " Without-pay             7\n",
      "Name: Work_Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set\", df_train.Work_Class.value_counts())\n",
    "print(\"Test Set\", df_test.Work_Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities here.  These will have to be converted to dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set  HS-grad         9840\n",
      " Some-college    6678\n",
      " Bachelors       5044\n",
      " Masters         1627\n",
      " Assoc-voc       1307\n",
      " 11th            1048\n",
      " Assoc-acdm      1008\n",
      " 10th             820\n",
      " 7th-8th          557\n",
      " Prof-school      542\n",
      " 9th              455\n",
      " 12th             377\n",
      " Doctorate        375\n",
      " 5th-6th          288\n",
      " 1st-4th          151\n",
      " Preschool         45\n",
      "Name: Education, dtype: int64\n",
      "Test Set  HS-grad         4943\n",
      " Some-college    3221\n",
      " Bachelors       2526\n",
      " Masters          887\n",
      " Assoc-voc        652\n",
      " 11th             571\n",
      " Assoc-acdm       499\n",
      " 10th             403\n",
      " 7th-8th          266\n",
      " Prof-school      243\n",
      " 9th              221\n",
      " 12th             200\n",
      " Doctorate        169\n",
      " 5th-6th          161\n",
      " 1st-4th           71\n",
      " Preschool         27\n",
      "Name: Education, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 16\n",
    "print(\"Train Set\", df_train.Education.value_counts())\n",
    "print(\"Test Set\", df_test.Education.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities here.  The dataset already has a numeric scale from Preschool to Doctorate in the 'Education_num' column, so we can can safely drop the 'Education' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Index(['Age', 'Work_Class', 'Fnlwgt', 'Education_num', 'Marital_status',\n",
      "       'Occupation', 'Relationship', 'Race', 'Sex', 'Capital_gain',\n",
      "       'Capital_loss', 'Hours_Per_Week', 'Native_Country', 'Income_Class'],\n",
      "      dtype='object')\n",
      "Test Set:\n",
      "Index(['Age', 'Work_Class', 'Fnlwgt', 'Education_num', 'Marital_status',\n",
      "       'Occupation', 'Relationship', 'Race', 'Sex', 'Capital_gain',\n",
      "       'Capital_loss', 'Hours_Per_Week', 'Native_Country', 'Income_Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(['Education'],axis=1)\n",
    "print(\"Training Set:\")\n",
    "print(df_train.columns) #verify remaining columns\n",
    "df_test = df_test.drop(['Education'],axis=1)\n",
    "print(\"Test Set:\")\n",
    "print(df_test.columns) #verify remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " Married-civ-spouse       14065\n",
      " Never-married             9726\n",
      " Divorced                  4214\n",
      " Separated                  939\n",
      " Widowed                    827\n",
      " Married-spouse-absent      370\n",
      " Married-AF-spouse           21\n",
      "Name: Marital_status, dtype: int64\n",
      "Test Set:\n",
      " Married-civ-spouse       6990\n",
      " Never-married            4872\n",
      " Divorced                 2083\n",
      " Separated                 472\n",
      " Widowed                   450\n",
      " Married-spouse-absent     182\n",
      " Married-AF-spouse          11\n",
      "Name: Marital_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(df_train.Marital_status.value_counts())\n",
    "print(\"Test Set:\")\n",
    "print(df_test.Marital_status.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularties to be corrected here.  These will have to be converted to dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " Prof-specialty       4038\n",
      " Craft-repair         4030\n",
      " Exec-managerial      3992\n",
      " Adm-clerical         3721\n",
      " Sales                3584\n",
      " Other-service        3212\n",
      " Machine-op-inspct    1966\n",
      " Transport-moving     1572\n",
      " Handlers-cleaners    1350\n",
      " Farming-fishing       989\n",
      " Tech-support          912\n",
      " Protective-serv       644\n",
      " Priv-house-serv       143\n",
      " Armed-Forces            9\n",
      "Name: Occupation, dtype: int64\n",
      "Test Set:\n",
      " Exec-managerial      1992\n",
      " Craft-repair         1990\n",
      " Prof-specialty       1970\n",
      " Sales                1824\n",
      " Adm-clerical         1819\n",
      " Other-service        1596\n",
      " Machine-op-inspct    1004\n",
      " Transport-moving      744\n",
      " Handlers-cleaners     696\n",
      " Tech-support          508\n",
      " Farming-fishing       491\n",
      " Protective-serv       332\n",
      " Priv-house-serv        89\n",
      " Armed-Forces            5\n",
      "Name: Occupation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(df_train.Occupation.value_counts())\n",
    "print(\"Test Set:\")\n",
    "print(df_test.Occupation.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities to be corrected.  These will have to be converted into dummy variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Family Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " Husband           12463\n",
      " Not-in-family      7726\n",
      " Own-child          4466\n",
      " Unmarried          3212\n",
      " Wife               1406\n",
      " Other-relative      889\n",
      "Name: Relationship, dtype: int64\n",
      "Test Set:\n",
      " Husband           6203\n",
      " Not-in-family     3976\n",
      " Own-child         2160\n",
      " Unmarried         1576\n",
      " Wife               685\n",
      " Other-relative     460\n",
      "Name: Relationship, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(df_train.Relationship.value_counts())\n",
    "print(\"Test Set:\")\n",
    "print(df_test.Relationship.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities to be corrected.  These will have to be converted into dummy variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " White                 25933\n",
      " Black                  2817\n",
      " Asian-Pac-Islander      895\n",
      " Amer-Indian-Eskimo      286\n",
      " Other                   231\n",
      "Name: Race, dtype: int64\n",
      "Test Set:\n",
      " White                 12970\n",
      " Black                  1411\n",
      " Asian-Pac-Islander      408\n",
      " Amer-Indian-Eskimo      149\n",
      " Other                   122\n",
      "Name: Race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(df_train.Race.value_counts())\n",
    "print(\"Test Set:\")\n",
    "print(df_test.Race.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities to be corrected.  These will have to be converted into dummy variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " Male      20380\n",
      " Female     9782\n",
      "Name: Sex, dtype: int64\n",
      "Test Set:\n",
      " Male      10147\n",
      " Female     4913\n",
      "Name: Sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(df_train.Sex.value_counts())\n",
    "print(\"Test Set:\")\n",
    "print(df_test.Sex.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities to be corrected.  These will have to be converted into dummy variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Native Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " United-States                 27504\n",
      " Mexico                          610\n",
      " Philippines                     188\n",
      " Germany                         128\n",
      " Puerto-Rico                     109\n",
      " Canada                          107\n",
      " El-Salvador                     100\n",
      " India                           100\n",
      " Cuba                             92\n",
      " England                          86\n",
      " Jamaica                          80\n",
      " South                            71\n",
      " China                            68\n",
      " Italy                            68\n",
      " Dominican-Republic               67\n",
      " Vietnam                          64\n",
      " Guatemala                        63\n",
      " Japan                            59\n",
      " Poland                           56\n",
      " Columbia                         56\n",
      " Haiti                            42\n",
      " Taiwan                           42\n",
      " Iran                             42\n",
      " Portugal                         34\n",
      " Nicaragua                        33\n",
      " Peru                             30\n",
      " Greece                           29\n",
      " Ecuador                          27\n",
      " France                           27\n",
      " Ireland                          24\n",
      " Hong                             19\n",
      " Trinadad&Tobago                  18\n",
      " Cambodia                         18\n",
      " Laos                             17\n",
      " Thailand                         17\n",
      " Yugoslavia                       16\n",
      " Outlying-US(Guam-USVI-etc)       14\n",
      " Hungary                          13\n",
      " Honduras                         12\n",
      " Scotland                         11\n",
      " Holand-Netherlands                1\n",
      "Name: Native_Country, dtype: int64\n",
      "Test Set:\n",
      " United-States                 13788\n",
      " Mexico                          293\n",
      " Philippines                      95\n",
      " Puerto-Rico                      66\n",
      " Germany                          65\n",
      " Canada                           56\n",
      " El-Salvador                      47\n",
      " India                            47\n",
      " China                            45\n",
      " Cuba                             41\n",
      " England                          33\n",
      " Italy                            32\n",
      " South                            30\n",
      " Dominican-Republic               30\n",
      " Japan                            30\n",
      " Portugal                         28\n",
      " Haiti                            27\n",
      " Columbia                         26\n",
      " Poland                           25\n",
      " Guatemala                        23\n",
      " Jamaica                          23\n",
      " Greece                           20\n",
      " Vietnam                          19\n",
      " Ecuador                          16\n",
      " Nicaragua                        15\n",
      " Peru                             15\n",
      " Iran                             14\n",
      " Taiwan                           13\n",
      " Ireland                          12\n",
      " Thailand                         12\n",
      " Scotland                          9\n",
      " Hong                              9\n",
      " France                            9\n",
      " Cambodia                          8\n",
      " Outlying-US(Guam-USVI-etc)        8\n",
      " Trinadad&Tobago                   8\n",
      " Yugoslavia                        7\n",
      " Honduras                          7\n",
      " Hungary                           5\n",
      " Laos                              4\n",
      "Name: Native_Country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 41\n",
    "print(\"Training Set:\")\n",
    "print(df_train.Native_Country.value_counts())\n",
    "print(\"Test Set:\")\n",
    "print(df_test.Native_Country.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data has one value from the Netherlands while the test data has zero, so a column of all zeros for the Netherlands will have to be added to the test dataset.  These will have to be converted into dummy variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Income Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " <=50K    22654\n",
      " >50K      7508\n",
      "Name: Income_Class, dtype: int64\n",
      "Test Set:\n",
      " <=50K.    11360\n",
      " >50K.      3700\n",
      "Name: Income_Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(df_train.Income_Class.value_counts())\n",
    "print(\"Test Set:\")\n",
    "print(df_test.Income_Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any irregularities to be corrected.  As this is the target variable, these will have to be converted to a normalized numeric 1/0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creating a numeric dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create separate dataframes that will be all numeric, and look at and/or convert the data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_num = df_train\n",
    "df_test_num = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to take a look at the train data that's already numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30162.000000</td>\n",
       "      <td>3.016200e+04</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.437902</td>\n",
       "      <td>1.897938e+05</td>\n",
       "      <td>10.121312</td>\n",
       "      <td>1092.007858</td>\n",
       "      <td>88.372489</td>\n",
       "      <td>40.931238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.134665</td>\n",
       "      <td>1.056530e+05</td>\n",
       "      <td>2.549995</td>\n",
       "      <td>7406.346497</td>\n",
       "      <td>404.298370</td>\n",
       "      <td>11.979984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.176272e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.784250e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.376285e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age        Fnlwgt  Education_num  Capital_gain  Capital_loss  \\\n",
       "count  30162.000000  3.016200e+04   30162.000000  30162.000000  30162.000000   \n",
       "mean      38.437902  1.897938e+05      10.121312   1092.007858     88.372489   \n",
       "std       13.134665  1.056530e+05       2.549995   7406.346497    404.298370   \n",
       "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.176272e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.784250e+05      10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.376285e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       Hours_Per_Week  \n",
       "count    30162.000000  \n",
       "mean        40.931238  \n",
       "std         11.979984  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_num.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any outliers in the numeric train data that need to be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at the test numeric data, but first we need to convert the 'Age' column to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_num['Age'] = df_test['Age'].astype(float)  #changes to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>1.506000e+04</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.768327</td>\n",
       "      <td>1.896164e+05</td>\n",
       "      <td>10.112749</td>\n",
       "      <td>1120.301594</td>\n",
       "      <td>89.041899</td>\n",
       "      <td>40.951594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.380676</td>\n",
       "      <td>1.056150e+05</td>\n",
       "      <td>2.558727</td>\n",
       "      <td>7703.181842</td>\n",
       "      <td>406.283245</td>\n",
       "      <td>12.062831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.166550e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.779550e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.385888e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age        Fnlwgt  Education_num  Capital_gain  Capital_loss  \\\n",
       "count  15060.000000  1.506000e+04   15060.000000  15060.000000  15060.000000   \n",
       "mean      38.768327  1.896164e+05      10.112749   1120.301594     89.041899   \n",
       "std       13.380676  1.056150e+05       2.558727   7703.181842    406.283245   \n",
       "min       17.000000  1.349200e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.166550e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.779550e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.385888e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   3770.000000   \n",
       "\n",
       "       Hours_Per_Week  \n",
       "count    15060.000000  \n",
       "mean        40.951594  \n",
       "std         12.062831  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_num.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any outliers in the numeric test data that need to be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert the income class to a 1/0 numeric (where 1 is >50K, 0 is <= 50K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_convert = df_train['Income_Class'].astype(str) #changes to string so we can change on the next line of code\n",
    "train_class_convert = train_class_convert.str.replace('>50K', '1') \n",
    "train_class_convert = train_class_convert.str.replace('<=50K', '0')\n",
    "df_train_num['Income_Class'] = train_class_convert.astype(int) #changes to numeric\n",
    "\n",
    "test_class_convert = df_test['Income_Class'].astype(str) #changes to string so we can change on the next line of code\n",
    "test_class_convert = test_class_convert.str.replace('>50K.', '1') \n",
    "test_class_convert = test_class_convert.str.replace('<=50K.', '0')\n",
    "df_test_num['Income_Class'] = test_class_convert.astype(int) #changes to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll desginate the target variable and move it to the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetName = 'Income_Class' # designate target variable name\n",
    "\n",
    "#training set\n",
    "targetSeries_train = df_train_num[targetName]\n",
    "#remove target from current location and insert in column 0\n",
    "del df_train_num[targetName]\n",
    "df_train_num.insert(0, targetName, targetSeries_train)\n",
    "\n",
    "#test set\n",
    "targetSeries_test = df_test_num[targetName]\n",
    "#remove target from current location and insert in column 0\n",
    "del df_test_num[targetName]\n",
    "df_test_num.insert(0, targetName, targetSeries_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create dummy variables for all of the remaining object columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income_Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "      <th>Work_Class_ Federal-gov</th>\n",
       "      <th>Work_Class_ Local-gov</th>\n",
       "      <th>Work_Class_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>Native_Country_ Portugal</th>\n",
       "      <th>Native_Country_ Puerto-Rico</th>\n",
       "      <th>Native_Country_ Scotland</th>\n",
       "      <th>Native_Country_ South</th>\n",
       "      <th>Native_Country_ Taiwan</th>\n",
       "      <th>Native_Country_ Thailand</th>\n",
       "      <th>Native_Country_ Trinadad&amp;Tobago</th>\n",
       "      <th>Native_Country_ United-States</th>\n",
       "      <th>Native_Country_ Vietnam</th>\n",
       "      <th>Native_Country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income_Class  Age  Fnlwgt  Education_num  Capital_gain  Capital_loss  \\\n",
       "0             0   39   77516             13          2174             0   \n",
       "1             0   50   83311             13             0             0   \n",
       "2             0   38  215646              9             0             0   \n",
       "3             0   53  234721              7             0             0   \n",
       "4             0   28  338409             13             0             0   \n",
       "\n",
       "   Hours_Per_Week  Work_Class_ Federal-gov  Work_Class_ Local-gov  \\\n",
       "0              40                        0                      0   \n",
       "1              13                        0                      0   \n",
       "2              40                        0                      0   \n",
       "3              40                        0                      0   \n",
       "4              40                        0                      0   \n",
       "\n",
       "   Work_Class_ Private             ...              Native_Country_ Portugal  \\\n",
       "0                    0             ...                                     0   \n",
       "1                    0             ...                                     0   \n",
       "2                    1             ...                                     0   \n",
       "3                    1             ...                                     0   \n",
       "4                    1             ...                                     0   \n",
       "\n",
       "   Native_Country_ Puerto-Rico  Native_Country_ Scotland  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "\n",
       "   Native_Country_ South  Native_Country_ Taiwan  Native_Country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   Native_Country_ Trinadad&Tobago  Native_Country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "\n",
       "   Native_Country_ Vietnam  Native_Country_ Yugoslavia  \n",
       "0                        0                           0  \n",
       "1                        0                           0  \n",
       "2                        0                           0  \n",
       "3                        0                           0  \n",
       "4                        0                           0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set\n",
    "# perform data transformation. Creates dummies of any categorical feature\n",
    "for col in df_train_num.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df_train_num[col].dtype\n",
    "\tmissing = pd.isnull(df_train_num[col]).any()\n",
    "\tuniqueCount = len(df_train_num[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf_train_num = pd.concat([df_train_num, pd.get_dummies(df_train_num[col], prefix=col)], axis=1)\n",
    "\t\tdel df_train_num[attName]\n",
    "print(\"Train Set:\")\n",
    "df_train_num.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income_Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "      <th>Work_Class_ Federal-gov</th>\n",
       "      <th>Work_Class_ Local-gov</th>\n",
       "      <th>Work_Class_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>Native_Country_ Portugal</th>\n",
       "      <th>Native_Country_ Puerto-Rico</th>\n",
       "      <th>Native_Country_ Scotland</th>\n",
       "      <th>Native_Country_ South</th>\n",
       "      <th>Native_Country_ Taiwan</th>\n",
       "      <th>Native_Country_ Thailand</th>\n",
       "      <th>Native_Country_ Trinadad&amp;Tobago</th>\n",
       "      <th>Native_Country_ United-States</th>\n",
       "      <th>Native_Country_ Vietnam</th>\n",
       "      <th>Native_Country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>198693.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income_Class   Age    Fnlwgt  Education_num  Capital_gain  Capital_loss  \\\n",
       "1             0  25.0  226802.0            7.0           0.0           0.0   \n",
       "2             0  38.0   89814.0            9.0           0.0           0.0   \n",
       "3             1  28.0  336951.0           12.0           0.0           0.0   \n",
       "4             1  44.0  160323.0           10.0        7688.0           0.0   \n",
       "6             0  34.0  198693.0            6.0           0.0           0.0   \n",
       "\n",
       "   Hours_Per_Week  Work_Class_ Federal-gov  Work_Class_ Local-gov  \\\n",
       "1            40.0                        0                      0   \n",
       "2            50.0                        0                      0   \n",
       "3            40.0                        0                      1   \n",
       "4            40.0                        0                      0   \n",
       "6            30.0                        0                      0   \n",
       "\n",
       "   Work_Class_ Private             ...              Native_Country_ Portugal  \\\n",
       "1                    1             ...                                     0   \n",
       "2                    1             ...                                     0   \n",
       "3                    0             ...                                     0   \n",
       "4                    1             ...                                     0   \n",
       "6                    1             ...                                     0   \n",
       "\n",
       "   Native_Country_ Puerto-Rico  Native_Country_ Scotland  \\\n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "6                            0                         0   \n",
       "\n",
       "   Native_Country_ South  Native_Country_ Taiwan  Native_Country_ Thailand  \\\n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "6                      0                       0                         0   \n",
       "\n",
       "   Native_Country_ Trinadad&Tobago  Native_Country_ United-States  \\\n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              1   \n",
       "6                                0                              1   \n",
       "\n",
       "   Native_Country_ Vietnam  Native_Country_ Yugoslavia  \n",
       "1                        0                           0  \n",
       "2                        0                           0  \n",
       "3                        0                           0  \n",
       "4                        0                           0  \n",
       "6                        0                           0  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "# perform data transformation. Creates dummies of any categorical feature\n",
    "for col in df_test_num.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df_test_num[col].dtype\n",
    "\tmissing = pd.isnull(df_test_num[col]).any()\n",
    "\tuniqueCount = len(df_test_num[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf_test_num = pd.concat([df_test_num, pd.get_dummies(df_test_num[col], prefix=col)], axis=1)\n",
    "\t\tdel df_test_num[attName]\n",
    "print(\"Test Set:\")\n",
    "df_test_num.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll normalize all columns between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income_Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "      <th>Work_Class_ Federal-gov</th>\n",
       "      <th>Work_Class_ Local-gov</th>\n",
       "      <th>Work_Class_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>Native_Country_ Portugal</th>\n",
       "      <th>Native_Country_ Puerto-Rico</th>\n",
       "      <th>Native_Country_ Scotland</th>\n",
       "      <th>Native_Country_ South</th>\n",
       "      <th>Native_Country_ Taiwan</th>\n",
       "      <th>Native_Country_ Thailand</th>\n",
       "      <th>Native_Country_ Trinadad&amp;Tobago</th>\n",
       "      <th>Native_Country_ United-States</th>\n",
       "      <th>Native_Country_ Vietnam</th>\n",
       "      <th>Native_Country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.043338</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.047277</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137244</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150212</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.127620</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.186383</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income_Class       Age    Fnlwgt  Education_num  Capital_gain  \\\n",
       "0               0.0  0.301370  0.043338       0.800000      0.021740   \n",
       "1               0.0  0.452055  0.047277       0.800000      0.000000   \n",
       "2               0.0  0.287671  0.137244       0.533333      0.000000   \n",
       "3               0.0  0.493151  0.150212       0.400000      0.000000   \n",
       "4               0.0  0.150685  0.220703       0.800000      0.000000   \n",
       "...             ...       ...       ...            ...           ...   \n",
       "32556           0.0  0.136986  0.165563       0.733333      0.000000   \n",
       "32557           1.0  0.315068  0.095589       0.533333      0.000000   \n",
       "32558           0.0  0.561644  0.093914       0.533333      0.000000   \n",
       "32559           0.0  0.068493  0.127620       0.533333      0.000000   \n",
       "32560           1.0  0.479452  0.186383       0.533333      0.150242   \n",
       "\n",
       "       Capital_loss  Hours_Per_Week  Work_Class_ Federal-gov  \\\n",
       "0               0.0        0.397959                      0.0   \n",
       "1               0.0        0.122449                      0.0   \n",
       "2               0.0        0.397959                      0.0   \n",
       "3               0.0        0.397959                      0.0   \n",
       "4               0.0        0.397959                      0.0   \n",
       "...             ...             ...                      ...   \n",
       "32556           0.0        0.377551                      0.0   \n",
       "32557           0.0        0.397959                      0.0   \n",
       "32558           0.0        0.397959                      0.0   \n",
       "32559           0.0        0.193878                      0.0   \n",
       "32560           0.0        0.397959                      0.0   \n",
       "\n",
       "       Work_Class_ Local-gov  Work_Class_ Private             ...              \\\n",
       "0                        0.0                  0.0             ...               \n",
       "1                        0.0                  0.0             ...               \n",
       "2                        0.0                  1.0             ...               \n",
       "3                        0.0                  1.0             ...               \n",
       "4                        0.0                  1.0             ...               \n",
       "...                      ...                  ...             ...               \n",
       "32556                    0.0                  1.0             ...               \n",
       "32557                    0.0                  1.0             ...               \n",
       "32558                    0.0                  1.0             ...               \n",
       "32559                    0.0                  1.0             ...               \n",
       "32560                    0.0                  0.0             ...               \n",
       "\n",
       "       Native_Country_ Portugal  Native_Country_ Puerto-Rico  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "...                         ...                          ...   \n",
       "32556                       0.0                          0.0   \n",
       "32557                       0.0                          0.0   \n",
       "32558                       0.0                          0.0   \n",
       "32559                       0.0                          0.0   \n",
       "32560                       0.0                          0.0   \n",
       "\n",
       "       Native_Country_ Scotland  Native_Country_ South  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "...                         ...                    ...   \n",
       "32556                       0.0                    0.0   \n",
       "32557                       0.0                    0.0   \n",
       "32558                       0.0                    0.0   \n",
       "32559                       0.0                    0.0   \n",
       "32560                       0.0                    0.0   \n",
       "\n",
       "       Native_Country_ Taiwan  Native_Country_ Thailand  \\\n",
       "0                         0.0                       0.0   \n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         0.0                       0.0   \n",
       "...                       ...                       ...   \n",
       "32556                     0.0                       0.0   \n",
       "32557                     0.0                       0.0   \n",
       "32558                     0.0                       0.0   \n",
       "32559                     0.0                       0.0   \n",
       "32560                     0.0                       0.0   \n",
       "\n",
       "       Native_Country_ Trinadad&Tobago  Native_Country_ United-States  \\\n",
       "0                                  0.0                            1.0   \n",
       "1                                  0.0                            1.0   \n",
       "2                                  0.0                            1.0   \n",
       "3                                  0.0                            1.0   \n",
       "4                                  0.0                            0.0   \n",
       "...                                ...                            ...   \n",
       "32556                              0.0                            1.0   \n",
       "32557                              0.0                            1.0   \n",
       "32558                              0.0                            1.0   \n",
       "32559                              0.0                            1.0   \n",
       "32560                              0.0                            1.0   \n",
       "\n",
       "       Native_Country_ Vietnam  Native_Country_ Yugoslavia  \n",
       "0                          0.0                         0.0  \n",
       "1                          0.0                         0.0  \n",
       "2                          0.0                         0.0  \n",
       "3                          0.0                         0.0  \n",
       "4                          0.0                         0.0  \n",
       "...                        ...                         ...  \n",
       "32556                      0.0                         0.0  \n",
       "32557                      0.0                         0.0  \n",
       "32558                      0.0                         0.0  \n",
       "32559                      0.0                         0.0  \n",
       "32560                      0.0                         0.0  \n",
       "\n",
       "[30162 rows x 89 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set\n",
    "pd.options.display.max_rows = 10\n",
    "df_train_num = (df_train_num - df_train_num.min())/(df_train_num.max() - df_train_num.min())\n",
    "print(\"Training Set:\")\n",
    "df_train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income_Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fnlwgt</th>\n",
       "      <th>Education_num</th>\n",
       "      <th>Capital_gain</th>\n",
       "      <th>Capital_loss</th>\n",
       "      <th>Hours_Per_Week</th>\n",
       "      <th>Work_Class_ Federal-gov</th>\n",
       "      <th>Work_Class_ Local-gov</th>\n",
       "      <th>Work_Class_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>Native_Country_ Portugal</th>\n",
       "      <th>Native_Country_ Puerto-Rico</th>\n",
       "      <th>Native_Country_ Scotland</th>\n",
       "      <th>Native_Country_ South</th>\n",
       "      <th>Native_Country_ Taiwan</th>\n",
       "      <th>Native_Country_ Thailand</th>\n",
       "      <th>Native_Country_ Trinadad&amp;Tobago</th>\n",
       "      <th>Native_Country_ United-States</th>\n",
       "      <th>Native_Country_ Vietnam</th>\n",
       "      <th>Native_Country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.051677</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.219011</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.099418</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.125398</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.156895</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.136723</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.244762</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.047666</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.054551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16281</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.114195</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows Ã— 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income_Class       Age    Fnlwgt  Education_num  Capital_gain  \\\n",
       "1               0.0  0.109589  0.144430       0.400000      0.000000   \n",
       "2               0.0  0.287671  0.051677       0.533333      0.000000   \n",
       "3               1.0  0.150685  0.219011       0.733333      0.000000   \n",
       "4               1.0  0.369863  0.099418       0.600000      0.076881   \n",
       "6               0.0  0.232877  0.125398       0.333333      0.000000   \n",
       "...             ...       ...       ...            ...           ...   \n",
       "16276           0.0  0.219178  0.156895       0.800000      0.000000   \n",
       "16277           0.0  0.301370  0.136723       0.800000      0.000000   \n",
       "16279           0.0  0.287671  0.244762       0.800000      0.000000   \n",
       "16280           0.0  0.369863  0.047666       0.800000      0.054551   \n",
       "16281           1.0  0.246575  0.114195       0.800000      0.000000   \n",
       "\n",
       "       Capital_loss  Hours_Per_Week  Work_Class_ Federal-gov  \\\n",
       "1               0.0        0.397959                      0.0   \n",
       "2               0.0        0.500000                      0.0   \n",
       "3               0.0        0.397959                      0.0   \n",
       "4               0.0        0.397959                      0.0   \n",
       "6               0.0        0.295918                      0.0   \n",
       "...             ...             ...                      ...   \n",
       "16276           0.0        0.397959                      0.0   \n",
       "16277           0.0        0.357143                      0.0   \n",
       "16279           0.0        0.500000                      0.0   \n",
       "16280           0.0        0.397959                      0.0   \n",
       "16281           0.0        0.602041                      0.0   \n",
       "\n",
       "       Work_Class_ Local-gov  Work_Class_ Private             ...              \\\n",
       "1                        0.0                  1.0             ...               \n",
       "2                        0.0                  1.0             ...               \n",
       "3                        1.0                  0.0             ...               \n",
       "4                        0.0                  1.0             ...               \n",
       "6                        0.0                  1.0             ...               \n",
       "...                      ...                  ...             ...               \n",
       "16276                    0.0                  1.0             ...               \n",
       "16277                    0.0                  1.0             ...               \n",
       "16279                    0.0                  1.0             ...               \n",
       "16280                    0.0                  1.0             ...               \n",
       "16281                    0.0                  0.0             ...               \n",
       "\n",
       "       Native_Country_ Portugal  Native_Country_ Puerto-Rico  \\\n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "6                           0.0                          0.0   \n",
       "...                         ...                          ...   \n",
       "16276                       0.0                          0.0   \n",
       "16277                       0.0                          0.0   \n",
       "16279                       0.0                          0.0   \n",
       "16280                       0.0                          0.0   \n",
       "16281                       0.0                          0.0   \n",
       "\n",
       "       Native_Country_ Scotland  Native_Country_ South  \\\n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "6                           0.0                    0.0   \n",
       "...                         ...                    ...   \n",
       "16276                       0.0                    0.0   \n",
       "16277                       0.0                    0.0   \n",
       "16279                       0.0                    0.0   \n",
       "16280                       0.0                    0.0   \n",
       "16281                       0.0                    0.0   \n",
       "\n",
       "       Native_Country_ Taiwan  Native_Country_ Thailand  \\\n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         0.0                       0.0   \n",
       "6                         0.0                       0.0   \n",
       "...                       ...                       ...   \n",
       "16276                     0.0                       0.0   \n",
       "16277                     0.0                       0.0   \n",
       "16279                     0.0                       0.0   \n",
       "16280                     0.0                       0.0   \n",
       "16281                     0.0                       0.0   \n",
       "\n",
       "       Native_Country_ Trinadad&Tobago  Native_Country_ United-States  \\\n",
       "1                                  0.0                            1.0   \n",
       "2                                  0.0                            1.0   \n",
       "3                                  0.0                            1.0   \n",
       "4                                  0.0                            1.0   \n",
       "6                                  0.0                            1.0   \n",
       "...                                ...                            ...   \n",
       "16276                              0.0                            1.0   \n",
       "16277                              0.0                            1.0   \n",
       "16279                              0.0                            1.0   \n",
       "16280                              0.0                            1.0   \n",
       "16281                              0.0                            1.0   \n",
       "\n",
       "       Native_Country_ Vietnam  Native_Country_ Yugoslavia  \n",
       "1                          0.0                         0.0  \n",
       "2                          0.0                         0.0  \n",
       "3                          0.0                         0.0  \n",
       "4                          0.0                         0.0  \n",
       "6                          0.0                         0.0  \n",
       "...                        ...                         ...  \n",
       "16276                      0.0                         0.0  \n",
       "16277                      0.0                         0.0  \n",
       "16279                      0.0                         0.0  \n",
       "16280                      0.0                         0.0  \n",
       "16281                      0.0                         0.0  \n",
       "\n",
       "[15060 rows x 88 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "df_test_num = (df_test_num - df_test_num.min())/(df_test_num.max() - df_test_num.min())\n",
    "print(\"Test Set:\")\n",
    "df_test_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the test set still has one less column than the training set due to no Netherlands column.  Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Income_Class', 'Age', 'Fnlwgt', 'Education_num', 'Capital_gain',\n",
       "       'Capital_loss', 'Hours_Per_Week', 'Work_Class_ Federal-gov',\n",
       "       'Work_Class_ Local-gov', 'Work_Class_ Private',\n",
       "       'Work_Class_ Self-emp-inc', 'Work_Class_ Self-emp-not-inc',\n",
       "       'Work_Class_ State-gov', 'Work_Class_ Without-pay',\n",
       "       'Marital_status_ Divorced', 'Marital_status_ Married-AF-spouse',\n",
       "       'Marital_status_ Married-civ-spouse',\n",
       "       'Marital_status_ Married-spouse-absent',\n",
       "       'Marital_status_ Never-married', 'Marital_status_ Separated',\n",
       "       'Marital_status_ Widowed', 'Occupation_ Adm-clerical',\n",
       "       'Occupation_ Armed-Forces', 'Occupation_ Craft-repair',\n",
       "       'Occupation_ Exec-managerial', 'Occupation_ Farming-fishing',\n",
       "       'Occupation_ Handlers-cleaners', 'Occupation_ Machine-op-inspct',\n",
       "       'Occupation_ Other-service', 'Occupation_ Priv-house-serv',\n",
       "       'Occupation_ Prof-specialty', 'Occupation_ Protective-serv',\n",
       "       'Occupation_ Sales', 'Occupation_ Tech-support',\n",
       "       'Occupation_ Transport-moving', 'Relationship_ Husband',\n",
       "       'Relationship_ Not-in-family', 'Relationship_ Other-relative',\n",
       "       'Relationship_ Own-child', 'Relationship_ Unmarried',\n",
       "       'Relationship_ Wife', 'Race_ Amer-Indian-Eskimo',\n",
       "       'Race_ Asian-Pac-Islander', 'Race_ Black', 'Race_ Other', 'Race_ White',\n",
       "       'Sex_ Female', 'Sex_ Male', 'Native_Country_ Cambodia',\n",
       "       'Native_Country_ Canada', 'Native_Country_ China',\n",
       "       'Native_Country_ Columbia', 'Native_Country_ Cuba',\n",
       "       'Native_Country_ Dominican-Republic', 'Native_Country_ Ecuador',\n",
       "       'Native_Country_ El-Salvador', 'Native_Country_ England',\n",
       "       'Native_Country_ France', 'Native_Country_ Germany',\n",
       "       'Native_Country_ Greece', 'Native_Country_ Guatemala',\n",
       "       'Native_Country_ Haiti', 'Native_Country_ Honduras',\n",
       "       'Native_Country_ Hong', 'Native_Country_ Hungary',\n",
       "       'Native_Country_ India', 'Native_Country_ Iran',\n",
       "       'Native_Country_ Ireland', 'Native_Country_ Italy',\n",
       "       'Native_Country_ Jamaica', 'Native_Country_ Japan',\n",
       "       'Native_Country_ Laos', 'Native_Country_ Mexico',\n",
       "       'Native_Country_ Nicaragua',\n",
       "       'Native_Country_ Outlying-US(Guam-USVI-etc)', 'Native_Country_ Peru',\n",
       "       'Native_Country_ Philippines', 'Native_Country_ Poland',\n",
       "       'Native_Country_ Portugal', 'Native_Country_ Puerto-Rico',\n",
       "       'Native_Country_ Scotland', 'Native_Country_ South',\n",
       "       'Native_Country_ Taiwan', 'Native_Country_ Thailand',\n",
       "       'Native_Country_ Trinadad&Tobago', 'Native_Country_ United-States',\n",
       "       'Native_Country_ Vietnam', 'Native_Country_ Yugoslavia',\n",
       "       'Native_Country_ Holand-Netherlands'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_num['Native_Country_ Holand-Netherlands'] = 0 #adds column of all zeros\n",
    "df_test_num.columns #verifies that it was added to the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move the column to its equivalent location in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_num.columns.get_loc(\"Native_Country_ Holand-Netherlands\") #gets the column number for Netherlands in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netherlands columns number: 62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    15060.0\n",
       "mean         0.0\n",
       "std          0.0\n",
       "min          0.0\n",
       "25%          0.0\n",
       "50%          0.0\n",
       "75%          0.0\n",
       "max          0.0\n",
       "Name: Native_Country_ Holand-Netherlands, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set\n",
    "NCHN = df_test_num['Native_Country_ Holand-Netherlands']\n",
    "#remove target from current location and insert in column 0\n",
    "del df_test_num['Native_Country_ Holand-Netherlands']\n",
    "df_test_num.insert(62, 'Native_Country_ Holand-Netherlands', NCHN)\n",
    "print(\"Netherlands columns number:\", df_test_num.columns.get_loc(\"Native_Country_ Holand-Netherlands\")) #prints columns number\n",
    "df_test_num['Native_Country_ Holand-Netherlands'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue is fixed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Split\n",
    "The data was already in a test/train split, so here we just have to split off the target variable.  The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = df_train_num[targetName]\n",
    "features_train = df_train_num.drop([targetName],axis=1)\n",
    "\n",
    "target_test = df_test_num[targetName]\n",
    "features_test = df_test_num.drop([targetName],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A view of the size of each test/train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15060, 88)\n",
      "(30162, 88)\n",
      "(15060,)\n",
      "(30162,)\n",
      "Percent of Target that is Yes: 25\n"
     ]
    }
   ],
   "source": [
    "print(features_test.shape)\n",
    "print(features_train.shape)\n",
    "print(target_test.shape)\n",
    "print(target_train.shape)\n",
    "print(\"Percent of Target that is Yes:\", round(100*target_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25% of the training data target variable is >$50K.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same info on the target shown graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x10da47278>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df_train_num.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since an 88x88 correlation matrix would be unweildy, the following displays the top 5 positive and top 5 negative correlations for the target variable.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital_status_ Married-civ-spouse    0.445418\n",
       "Relationship_ Husband                 0.401236\n",
       "Education_num                         0.335286\n",
       "Age                                   0.241998\n",
       "Hours_Per_Week                        0.229480\n",
       "                                        ...   \n",
       "Occupation_ Other-service            -0.165934\n",
       "Relationship_ Not-in-family          -0.193258\n",
       "Sex_ Female                          -0.216699\n",
       "Relationship_ Own-child              -0.226186\n",
       "Marital_status_ Never-married        -0.320053\n",
       "Name: Income_Class, Length: 88, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "correlations = df_train_num.corr()\n",
    "correlations = correlations[targetName]\n",
    "correlations = correlations[1:,] \n",
    "correlations.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real surprises here.  The higher income class category positively correlates most strongly with being married (to a civilian spouse), being a married man, higher education, higher age, and higher hours worked.  The following correlates negatively the strongest: being never married, being a child of the head of the house, being female, being single, or in a service occupation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "Now we'll explore different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "First we'll do a K Nearest Neighbor model with default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "#Call up the model to see the parameters you can tune (and their default setting)\n",
    "print(knn) \n",
    "#Fit knn to the training data\n",
    "knn = knn.fit(features_train, target_train)\n",
    "#Predict clf KNN against test data\n",
    "target_predicted_knn = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.819057104914\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.90      0.88     11360\n",
      "     > $50K       0.65      0.57      0.61      3700\n",
      "\n",
      "avg / total       0.81      0.82      0.81     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10222  1138]\n",
      " [ 1587  2113]]\n",
      "Confusion Matrix Percent\n",
      "[[ 67.875166     7.5564409 ]\n",
      " [ 10.53784861  14.03054449]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_knn))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_knn, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_knn))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_knn))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the KNN classifier with default settings had an accuracy of 81.9%.  Now let's do a grid search on the number of neighbors and see the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 20}\n",
      "Best Score: 0.833698030635\n",
      "Best Estimator KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.009965</td>\n",
       "      <td>51.692430</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.893235</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812863</td>\n",
       "      <td>0.894898</td>\n",
       "      <td>0.815183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818167</td>\n",
       "      <td>0.890961</td>\n",
       "      <td>0.815318</td>\n",
       "      <td>0.893742</td>\n",
       "      <td>0.815785</td>\n",
       "      <td>0.892752</td>\n",
       "      <td>0.431869</td>\n",
       "      <td>0.582183</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.634378</td>\n",
       "      <td>58.908670</td>\n",
       "      <td>0.822359</td>\n",
       "      <td>0.872978</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.816509</td>\n",
       "      <td>0.872850</td>\n",
       "      <td>0.823802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824797</td>\n",
       "      <td>0.873679</td>\n",
       "      <td>0.823442</td>\n",
       "      <td>0.871985</td>\n",
       "      <td>0.823247</td>\n",
       "      <td>0.872778</td>\n",
       "      <td>0.325751</td>\n",
       "      <td>0.702091</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.668756</td>\n",
       "      <td>64.310816</td>\n",
       "      <td>0.827167</td>\n",
       "      <td>0.864357</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.825791</td>\n",
       "      <td>0.864354</td>\n",
       "      <td>0.823305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.862862</td>\n",
       "      <td>0.830570</td>\n",
       "      <td>0.864816</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>0.864614</td>\n",
       "      <td>0.238282</td>\n",
       "      <td>0.797516</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.946881</td>\n",
       "      <td>68.486197</td>\n",
       "      <td>0.830283</td>\n",
       "      <td>0.858572</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.827781</td>\n",
       "      <td>0.858925</td>\n",
       "      <td>0.826952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830764</td>\n",
       "      <td>0.857765</td>\n",
       "      <td>0.835046</td>\n",
       "      <td>0.858931</td>\n",
       "      <td>0.830874</td>\n",
       "      <td>0.858854</td>\n",
       "      <td>0.654360</td>\n",
       "      <td>1.497782</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.846881</td>\n",
       "      <td>72.971177</td>\n",
       "      <td>0.830946</td>\n",
       "      <td>0.852787</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.851755</td>\n",
       "      <td>0.825626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829272</td>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.838859</td>\n",
       "      <td>0.853792</td>\n",
       "      <td>0.832698</td>\n",
       "      <td>0.852596</td>\n",
       "      <td>0.309264</td>\n",
       "      <td>1.431546</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.471877</td>\n",
       "      <td>76.615004</td>\n",
       "      <td>0.832438</td>\n",
       "      <td>0.850797</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829935</td>\n",
       "      <td>0.850015</td>\n",
       "      <td>0.840849</td>\n",
       "      <td>0.850477</td>\n",
       "      <td>0.834190</td>\n",
       "      <td>0.850358</td>\n",
       "      <td>0.260596</td>\n",
       "      <td>1.083131</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.703131</td>\n",
       "      <td>81.219792</td>\n",
       "      <td>0.833698</td>\n",
       "      <td>0.846719</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.829604</td>\n",
       "      <td>0.848564</td>\n",
       "      <td>0.832422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832753</td>\n",
       "      <td>0.846450</td>\n",
       "      <td>0.838528</td>\n",
       "      <td>0.846291</td>\n",
       "      <td>0.835185</td>\n",
       "      <td>0.845966</td>\n",
       "      <td>0.278985</td>\n",
       "      <td>1.451774</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.696878</td>\n",
       "      <td>88.345418</td>\n",
       "      <td>0.833499</td>\n",
       "      <td>0.841829</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_neighbors': 30}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.827449</td>\n",
       "      <td>0.843922</td>\n",
       "      <td>0.830764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832919</td>\n",
       "      <td>0.841311</td>\n",
       "      <td>0.839854</td>\n",
       "      <td>0.840406</td>\n",
       "      <td>0.836511</td>\n",
       "      <td>0.841656</td>\n",
       "      <td>0.511262</td>\n",
       "      <td>1.355827</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.800004</td>\n",
       "      <td>93.644289</td>\n",
       "      <td>0.832836</td>\n",
       "      <td>0.839276</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_neighbors': 40}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.840400</td>\n",
       "      <td>0.828775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832587</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.837837</td>\n",
       "      <td>0.835185</td>\n",
       "      <td>0.839625</td>\n",
       "      <td>0.352641</td>\n",
       "      <td>1.942850</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.884380</td>\n",
       "      <td>96.951520</td>\n",
       "      <td>0.831344</td>\n",
       "      <td>0.836881</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_neighbors': 50}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825791</td>\n",
       "      <td>0.837664</td>\n",
       "      <td>0.827946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829438</td>\n",
       "      <td>0.837167</td>\n",
       "      <td>0.837036</td>\n",
       "      <td>0.835765</td>\n",
       "      <td>0.836511</td>\n",
       "      <td>0.836269</td>\n",
       "      <td>0.465471</td>\n",
       "      <td>4.030956</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       3.009965        51.692430         0.815463          0.893235   \n",
       "1       2.634378        58.908670         0.822359          0.872978   \n",
       "2       2.668756        64.310816         0.827167          0.864357   \n",
       "3       2.946881        68.486197         0.830283          0.858572   \n",
       "4       2.846881        72.971177         0.830946          0.852787   \n",
       "5       2.471877        76.615004         0.832438          0.850797   \n",
       "6       2.703131        81.219792         0.833698          0.846719   \n",
       "7       2.696878        88.345418         0.833499          0.841829   \n",
       "8       2.800004        93.644289         0.832836          0.839276   \n",
       "9       2.884380        96.951520         0.831344          0.836881   \n",
       "\n",
       "  param_n_neighbors               params  rank_test_score  split0_test_score  \\\n",
       "0                 3   {'n_neighbors': 3}               10           0.812863   \n",
       "1                 5   {'n_neighbors': 5}                9           0.816509   \n",
       "2                 7   {'n_neighbors': 7}                8           0.825791   \n",
       "3                 9   {'n_neighbors': 9}                7           0.827781   \n",
       "4                12  {'n_neighbors': 12}                6           0.828278   \n",
       "5                15  {'n_neighbors': 15}                4           0.828941   \n",
       "6                20  {'n_neighbors': 20}                1           0.829604   \n",
       "7                30  {'n_neighbors': 30}                2           0.827449   \n",
       "8                40  {'n_neighbors': 40}                3           0.828278   \n",
       "9                50  {'n_neighbors': 50}                5           0.825791   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.894898           0.815183       ...                  0.818167   \n",
       "1            0.872850           0.823802       ...                  0.824797   \n",
       "2            0.864354           0.823305       ...                  0.828278   \n",
       "3            0.858925           0.826952       ...                  0.830764   \n",
       "4            0.851755           0.825626       ...                  0.829272   \n",
       "5            0.851962           0.828278       ...                  0.829935   \n",
       "6            0.848564           0.832422       ...                  0.832753   \n",
       "7            0.843922           0.830764       ...                  0.832919   \n",
       "8            0.840400           0.828775       ...                  0.832587   \n",
       "9            0.837664           0.827946       ...                  0.829438   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.890961           0.815318            0.893742   \n",
       "1            0.873679           0.823442            0.871985   \n",
       "2            0.862862           0.830570            0.864816   \n",
       "3            0.857765           0.835046            0.858931   \n",
       "4            0.851962           0.838859            0.853792   \n",
       "5            0.850015           0.840849            0.850477   \n",
       "6            0.846450           0.838528            0.846291   \n",
       "7            0.841311           0.839854            0.840406   \n",
       "8            0.839281           0.839357            0.837837   \n",
       "9            0.837167           0.837036            0.835765   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.815785            0.892752      0.431869        0.582183   \n",
       "1           0.823247            0.872778      0.325751        0.702091   \n",
       "2           0.827889            0.864614      0.238282        0.797516   \n",
       "3           0.830874            0.858854      0.654360        1.497782   \n",
       "4           0.832698            0.852596      0.309264        1.431546   \n",
       "5           0.834190            0.850358      0.260596        1.083131   \n",
       "6           0.835185            0.845966      0.278985        1.451774   \n",
       "7           0.836511            0.841656      0.511262        1.355827   \n",
       "8           0.835185            0.839625      0.352641        1.942850   \n",
       "9           0.836511            0.836269      0.465471        4.030956   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.001690         0.001324  \n",
       "1        0.002974         0.000619  \n",
       "2        0.002455         0.000791  \n",
       "3        0.002851         0.000451  \n",
       "4        0.004559         0.000880  \n",
       "5        0.004682         0.000694  \n",
       "6        0.002994         0.000936  \n",
       "7        0.004333         0.001158  \n",
       "8        0.004132         0.000832  \n",
       "9        0.004585         0.000742  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"n_neighbors\": [3,5,7,9,12,15,20,30,40,50]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(knn, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search revealed that n=20 is the best solution.  Let's run the model with that parameter and see the result.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "#Call up the model to see the parameters you can tune (and their default setting)\n",
    "print(knn)\n",
    "#Fit clf to the training data\n",
    "knn = knn.fit(features_train, target_train)\n",
    "#Predict clf KNN against test data\n",
    "target_predicted_knn = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.830942895086\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.92      0.89     11360\n",
      "     > $50K       0.70      0.56      0.62      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10458   902]\n",
      " [ 1644  2056]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.44223108   5.98937583]\n",
      " [ 10.91633466  13.65205843]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_knn))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_knn, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_knn))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_knn))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved from 81.9% to 83.1% using n=20 in the KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use a Manhattan distance in the KNN to see how it compares to the Euclidean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20, p=1)\n",
    "#Fit clf to the training data\n",
    "knn = knn.fit(features_train, target_train)\n",
    "#Predict clf KNN against test data\n",
    "target_predicted_knn = knn.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score 0.830478087649\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.92      0.89     11360\n",
      "     > $50K       0.70      0.54      0.61      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10499   861]\n",
      " [ 1692  2008]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.71447543   5.71713147]\n",
      " [ 11.23505976  13.33333333]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy Score\", accuracy_score(target_test, target_predicted_knn))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_knn, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_knn))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_knn))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy declined slightly when using Manhattan distances.  Thus, Euclidean distance (p=2) was determined to be optimal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83095791  0.83327809  0.83592973  0.83128936  0.83753316  0.82625995\n",
      "  0.83653846  0.84316976  0.8384743   0.8331675 ]\n",
      "Mean cross validation score 0.834659820514\n"
     ]
    }
   ],
   "source": [
    "#verify KNN with Cross Validation\n",
    "knn = KNeighborsClassifier(n_neighbors=20, p=2) #next 3 lines rerun code for best tweaked solution for later use\n",
    "knn.fit(features_train, target_train)\n",
    "target_predicted_knn = knn.predict(features_test)\n",
    "scores_knn = cross_val_score(knn, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores_knn)\n",
    "print(\"Mean cross validation score\", scores_knn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores look consistant, suggesting this model is not overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Now we'll use a decision tree model, starting with default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best')\n",
      "DT Accuracy Score 0.796082337317\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.86      0.86     11360\n",
      "     > $50K       0.58      0.59      0.59      3700\n",
      "\n",
      "avg / total       0.80      0.80      0.80     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[9810 1550]\n",
      " [1521 2179]]\n",
      "Confusion Matrix Percent\n",
      "[[ 65.13944223  10.29216467]\n",
      " [ 10.09960159  14.4687915 ]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "from sklearn import tree \n",
    "clf = tree.DecisionTreeClassifier(random_state=123)\n",
    "print(clf)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_dt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_dt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the decision tree classifier with default settings had an accuracy of 79.6%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tweak the parameters to see if we can get better results.  Let's start with a grid serach on max depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 9}\n",
      "Best Score: 0.853391684902\n",
      "Best Estimator DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best')\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.290104</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.840263</td>\n",
       "      <td>0.840329</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.834245</td>\n",
       "      <td>0.841767</td>\n",
       "      <td>0.835405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843030</td>\n",
       "      <td>0.839654</td>\n",
       "      <td>0.847646</td>\n",
       "      <td>0.838500</td>\n",
       "      <td>0.840988</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>6.249690e-03</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.840926</td>\n",
       "      <td>0.841688</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.833250</td>\n",
       "      <td>0.842264</td>\n",
       "      <td>0.835737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>0.839985</td>\n",
       "      <td>0.846651</td>\n",
       "      <td>0.838707</td>\n",
       "      <td>0.845631</td>\n",
       "      <td>0.845634</td>\n",
       "      <td>0.033656</td>\n",
       "      <td>7.653215e-03</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568757</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.842815</td>\n",
       "      <td>0.845285</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.837063</td>\n",
       "      <td>0.846782</td>\n",
       "      <td>0.837726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842864</td>\n",
       "      <td>0.843881</td>\n",
       "      <td>0.845159</td>\n",
       "      <td>0.841442</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.850193</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>2.953312e-06</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.790628</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.854490</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851649</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.851790</td>\n",
       "      <td>0.849399</td>\n",
       "      <td>0.851932</td>\n",
       "      <td>0.852223</td>\n",
       "      <td>0.077562</td>\n",
       "      <td>6.247902e-03</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.850540</td>\n",
       "      <td>0.855033</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.856273</td>\n",
       "      <td>0.846677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852312</td>\n",
       "      <td>0.853247</td>\n",
       "      <td>0.854277</td>\n",
       "      <td>0.853378</td>\n",
       "      <td>0.853424</td>\n",
       "      <td>0.856202</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>1.169240e-02</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.071879</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.851668</td>\n",
       "      <td>0.859252</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.861412</td>\n",
       "      <td>0.849494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850157</td>\n",
       "      <td>0.856190</td>\n",
       "      <td>0.856432</td>\n",
       "      <td>0.857315</td>\n",
       "      <td>0.855414</td>\n",
       "      <td>0.860387</td>\n",
       "      <td>0.046978</td>\n",
       "      <td>9.881439e-03</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.081253</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>0.853392</td>\n",
       "      <td>0.864772</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847340</td>\n",
       "      <td>0.866095</td>\n",
       "      <td>0.850986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854136</td>\n",
       "      <td>0.864147</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.862578</td>\n",
       "      <td>0.856740</td>\n",
       "      <td>0.865401</td>\n",
       "      <td>0.084085</td>\n",
       "      <td>1.249890e-02</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.001273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.956254</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.852066</td>\n",
       "      <td>0.869107</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>0.870529</td>\n",
       "      <td>0.848997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854799</td>\n",
       "      <td>0.868664</td>\n",
       "      <td>0.857593</td>\n",
       "      <td>0.866639</td>\n",
       "      <td>0.855248</td>\n",
       "      <td>0.870167</td>\n",
       "      <td>0.028641</td>\n",
       "      <td>2.198628e-06</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.001387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.271877</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.838207</td>\n",
       "      <td>0.901979</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 15}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.835903</td>\n",
       "      <td>0.904347</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835571</td>\n",
       "      <td>0.899001</td>\n",
       "      <td>0.847480</td>\n",
       "      <td>0.901699</td>\n",
       "      <td>0.838501</td>\n",
       "      <td>0.901040</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>8.529922e-07</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.303129</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.825608</td>\n",
       "      <td>0.938714</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.944631</td>\n",
       "      <td>0.820322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826455</td>\n",
       "      <td>0.934933</td>\n",
       "      <td>0.834218</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>0.828718</td>\n",
       "      <td>0.935767</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>7.653682e-03</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.003771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.290104         0.012499         0.840263          0.840329   \n",
       "1       0.475000         0.009373         0.840926          0.841688   \n",
       "2       0.568757         0.015624         0.842815          0.845285   \n",
       "3       0.790628         0.018746         0.848783          0.851800   \n",
       "4       0.912500         0.012500         0.850540          0.855033   \n",
       "5       1.071879         0.015624         0.851668          0.859252   \n",
       "6       1.081253         0.021876         0.853392          0.864772   \n",
       "7       0.956254         0.015625         0.852066          0.869107   \n",
       "8       1.271877         0.015624         0.838207          0.901979   \n",
       "9       1.303129         0.009374         0.825608          0.938714   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "0               3   {'max_depth': 3}                8           0.834245   \n",
       "1               4   {'max_depth': 4}                7           0.833250   \n",
       "2               5   {'max_depth': 5}                6           0.837063   \n",
       "3               6   {'max_depth': 6}                5           0.844853   \n",
       "4               7   {'max_depth': 7}                4           0.846014   \n",
       "5               8   {'max_depth': 8}                3           0.846842   \n",
       "6               9   {'max_depth': 9}                1           0.847340   \n",
       "7              10  {'max_depth': 10}                2           0.843693   \n",
       "8              15  {'max_depth': 15}                9           0.835903   \n",
       "9              20  {'max_depth': 20}               10           0.818333   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.841767           0.835405       ...                  0.843030   \n",
       "1            0.842264           0.835737       ...                  0.843362   \n",
       "2            0.846782           0.837726       ...                  0.842864   \n",
       "3            0.854490           0.843693       ...                  0.851649   \n",
       "4            0.856273           0.846677       ...                  0.852312   \n",
       "5            0.861412           0.849494       ...                  0.850157   \n",
       "6            0.866095           0.850986       ...                  0.854136   \n",
       "7            0.870529           0.848997       ...                  0.854799   \n",
       "8            0.904347           0.833582       ...                  0.835571   \n",
       "9            0.944631           0.820322       ...                  0.826455   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.839654           0.847646            0.838500   \n",
       "1            0.839985           0.846651            0.838707   \n",
       "2            0.843881           0.845159            0.841442   \n",
       "3            0.850139           0.851790            0.849399   \n",
       "4            0.853247           0.854277            0.853378   \n",
       "5            0.856190           0.856432            0.857315   \n",
       "6            0.864147           0.857759            0.862578   \n",
       "7            0.868664           0.857593            0.866639   \n",
       "8            0.899001           0.847480            0.901699   \n",
       "9            0.934933           0.834218            0.936593   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.840988            0.840164      0.030796    6.249690e-03   \n",
       "1           0.845631            0.845634      0.033656    7.653215e-03   \n",
       "2           0.851268            0.850193      0.041457    2.953312e-06   \n",
       "3           0.851932            0.852223      0.077562    6.247902e-03   \n",
       "4           0.853424            0.856202      0.041458    1.169240e-02   \n",
       "5           0.855414            0.860387      0.046978    9.881439e-03   \n",
       "6           0.856740            0.865401      0.084085    1.249890e-02   \n",
       "7           0.855248            0.870167      0.028641    2.198628e-06   \n",
       "8           0.838501            0.901040      0.033658    8.529922e-07   \n",
       "9           0.828718            0.935767      0.095089    7.653682e-03   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.004950         0.001218  \n",
       "1        0.005416         0.002354  \n",
       "2        0.005214         0.002980  \n",
       "3        0.003702         0.001835  \n",
       "4        0.003488         0.001407  \n",
       "5        0.003661         0.002097  \n",
       "6        0.003828         0.001273  \n",
       "7        0.005053         0.001387  \n",
       "8        0.004893         0.001938  \n",
       "9        0.005751         0.003771  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": [3,4,5,6,7,8,9,10,15,20]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search showed that the best max depth is 9.  Let's run the model again with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.8419654714475432\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.91      0.90     11360\n",
      "     > $50K       0.70      0.63      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10347  1013]\n",
      " [ 1367  2333]]\n",
      "Confusion Matrix Percent\n",
      "[[68.70517928  6.72642762]\n",
      " [ 9.07702523 15.49136786]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=9,random_state=123)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_dt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_dt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased from 79.6% to 84.2% with this change.  The number of false positives in particular dropped significantly, from 10.3% to 6.7%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the decision tree using information gain vice Gini impurity for the split quality criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.840637450199\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.91      0.90     11360\n",
      "     > $50K       0.69      0.63      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10335  1025]\n",
      " [ 1375  2325]]\n",
      "Confusion Matrix Percent\n",
      "[[ 68.62549801   6.8061089 ]\n",
      " [  9.13014608  15.43824701]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=9,random_state=123)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print(\"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_dt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_dt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy dropped slightly using information gain (84.1% vice 84.2%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the decision tree, using the Gini impurity as that was more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83990719  0.84852502  0.85382831  0.84686775  0.84714854  0.85377984\n",
      "  0.85046419  0.85775862  0.85936982  0.85207297]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85097222528225969"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "clf = tree.DecisionTreeClassifier(max_depth=9,random_state=123)\n",
    "clf = clf.fit(features_train, target_train)\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the decision tree are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forest\n",
    "Now we'll try the random forest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "RF Accuracy Score 0.837383798141\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.92      0.90     11360\n",
      "     > $50K       0.71      0.57      0.63      3700\n",
      "\n",
      "avg / total       0.83      0.84      0.83     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10505   855]\n",
      " [ 1594  2106]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.75431607   5.67729084]\n",
      " [ 10.58432935  13.98406375]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=123)\n",
    "rf = rf.fit(features_train, target_train)\n",
    "print(rf)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"RF Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_rf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest with default settings had an accuracy of 83.7%.  Let's do a grid seach of the numner of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 100}\n",
      "Best Score: 0.854154233804\n",
      "Best Estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.637499</td>\n",
       "      <td>0.065628</td>\n",
       "      <td>0.846031</td>\n",
       "      <td>0.987592</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.845185</td>\n",
       "      <td>0.988769</td>\n",
       "      <td>0.843196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.987235</td>\n",
       "      <td>0.853780</td>\n",
       "      <td>0.986780</td>\n",
       "      <td>0.843973</td>\n",
       "      <td>0.986863</td>\n",
       "      <td>0.132724</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.790419</td>\n",
       "      <td>0.165627</td>\n",
       "      <td>0.850176</td>\n",
       "      <td>0.995740</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.850655</td>\n",
       "      <td>0.995938</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>0.995980</td>\n",
       "      <td>0.854609</td>\n",
       "      <td>0.995276</td>\n",
       "      <td>0.848615</td>\n",
       "      <td>0.995442</td>\n",
       "      <td>0.318657</td>\n",
       "      <td>0.028979</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.896889</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.851867</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_estimators': 40}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.851152</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.849329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849660</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>0.856101</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.853092</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.498883</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.809397</td>\n",
       "      <td>0.412503</td>\n",
       "      <td>0.852430</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>60</td>\n",
       "      <td>{'n_estimators': 60}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.858753</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.852761</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.309741</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.493070</td>\n",
       "      <td>0.528126</td>\n",
       "      <td>0.853325</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>80</td>\n",
       "      <td>{'n_estimators': 80}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.848997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853638</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.857924</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.853424</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.124685</td>\n",
       "      <td>0.041224</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48.385806</td>\n",
       "      <td>1.609378</td>\n",
       "      <td>0.853226</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>250</td>\n",
       "      <td>{'n_estimators': 250}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.853307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851318</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.858090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853092</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.499808</td>\n",
       "      <td>0.211256</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57.736316</td>\n",
       "      <td>1.828129</td>\n",
       "      <td>0.853259</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>300</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.858256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853590</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67.482784</td>\n",
       "      <td>2.142336</td>\n",
       "      <td>0.853624</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>350</td>\n",
       "      <td>{'n_estimators': 350}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.854136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.857593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854750</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.217008</td>\n",
       "      <td>0.060649</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>77.473933</td>\n",
       "      <td>2.734377</td>\n",
       "      <td>0.853591</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>400</td>\n",
       "      <td>{'n_estimators': 400}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.854136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853473</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.857427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854585</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.399607</td>\n",
       "      <td>0.368566</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>91.475545</td>\n",
       "      <td>3.065631</td>\n",
       "      <td>0.853988</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852975</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.857924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855414</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>5.917007</td>\n",
       "      <td>0.478991</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        1.637499         0.065628         0.846031          0.987592   \n",
       "1        3.790419         0.165627         0.850176          0.995740   \n",
       "2        7.896889         0.262500         0.851867          0.998939   \n",
       "3       11.809397         0.412503         0.852430          0.999776   \n",
       "4       15.493070         0.528126         0.853325          0.999851   \n",
       "..            ...              ...              ...               ...   \n",
       "8       48.385806         1.609378         0.853226          0.999975   \n",
       "9       57.736316         1.828129         0.853259          0.999975   \n",
       "10      67.482784         2.142336         0.853624          0.999975   \n",
       "11      77.473933         2.734377         0.853591          0.999975   \n",
       "12      91.475545         3.065631         0.853988          0.999975   \n",
       "\n",
       "   param_n_estimators                 params  rank_test_score  \\\n",
       "0                  10   {'n_estimators': 10}               13   \n",
       "1                  20   {'n_estimators': 20}               12   \n",
       "2                  40   {'n_estimators': 40}               11   \n",
       "3                  60   {'n_estimators': 60}               10   \n",
       "4                  80   {'n_estimators': 80}                7   \n",
       "..                ...                    ...              ...   \n",
       "8                 250  {'n_estimators': 250}                9   \n",
       "9                 300  {'n_estimators': 300}                8   \n",
       "10                350  {'n_estimators': 350}                4   \n",
       "11                400  {'n_estimators': 400}                5   \n",
       "12                500  {'n_estimators': 500}                2   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0            0.845185            0.988769           0.843196       ...          \n",
       "1            0.850655            0.995938           0.848500       ...          \n",
       "2            0.851152            0.999254           0.849329       ...          \n",
       "3            0.852644            0.999834           0.847174       ...          \n",
       "4            0.852644            0.999793           0.848997       ...          \n",
       "..                ...                 ...                ...       ...          \n",
       "8            0.853307            1.000000           0.850323       ...          \n",
       "9            0.852644            1.000000           0.849660       ...          \n",
       "10           0.854136            1.000000           0.849494       ...          \n",
       "11           0.854136            1.000000           0.848334       ...          \n",
       "12           0.854799            1.000000           0.848831       ...          \n",
       "\n",
       "    split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0            0.844025            0.987235           0.853780   \n",
       "1            0.848500            0.995980           0.854609   \n",
       "2            0.849660            0.998922           0.856101   \n",
       "3            0.850820            0.999751           0.858753   \n",
       "4            0.853638            0.999917           0.857924   \n",
       "..                ...                 ...                ...   \n",
       "8            0.851318            0.999959           0.858090   \n",
       "9            0.852147            0.999959           0.858256   \n",
       "10           0.852147            0.999959           0.857593   \n",
       "11           0.853473            0.999959           0.857427   \n",
       "12           0.852975            0.999959           0.857924   \n",
       "\n",
       "    split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0             0.986780           0.843973            0.986863      0.132724   \n",
       "1             0.995276           0.848615            0.995442      0.318657   \n",
       "2             0.999047           0.853092            0.998384      0.498883   \n",
       "3             0.999834           0.852761            0.999668      0.309741   \n",
       "4             0.999917           0.853424            0.999876      0.124685   \n",
       "..                 ...                ...                 ...           ...   \n",
       "8             1.000000           0.853092            0.999959      0.499808   \n",
       "9             1.000000           0.853590            0.999959      0.373205   \n",
       "10            1.000000           0.854750            0.999959      0.217008   \n",
       "11            1.000000           0.854585            0.999959      0.399607   \n",
       "12            1.000000           0.855414            0.999959      5.917007   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.011688        0.003926         0.000803  \n",
       "1         0.028979        0.002364         0.000318  \n",
       "2         0.015312        0.002500         0.000297  \n",
       "3         0.060600        0.003751         0.000062  \n",
       "4         0.041224        0.002845         0.000067  \n",
       "..             ...             ...              ...  \n",
       "8         0.211256        0.002674         0.000020  \n",
       "9         0.022097        0.002816         0.000020  \n",
       "10        0.060649        0.002703         0.000020  \n",
       "11        0.368566        0.002955         0.000020  \n",
       "12        0.478991        0.003027         0.000020  \n",
       "\n",
       "[13 rows x 21 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [10,20,40,60,80,100,150,200,250,300,350,400,500]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined a n estimators value of 100 as optimal.  Now let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score 0.8440903054448872\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.92      0.90     11360\n",
      "     > $50K       0.72      0.60      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10480   880]\n",
      " [ 1468  2232]]\n",
      "Confusion Matrix Percent\n",
      "[[69.58831341  5.84329349]\n",
      " [ 9.74767596 14.82071713]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 100, random_state=123)\n",
    "rf = rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"RF Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_rf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model improved with a modest rise in accuracy from 83.7% to 84.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try chaning the class weight to the 'balanced', where columns with a greater count have more weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score 0.84395750332\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.72      0.60      0.65      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10508   852]\n",
      " [ 1498  2202]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.77423639   5.65737052]\n",
      " [  9.94687915  14.62151394]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 100, class_weight='balanced', random_state=123)\n",
    "rf = rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print(\"RF Accuracy Score\", accuracy_score(target_test, target_predicted_rf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, target_predicted_rf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy decreased slightly but still rounds to 84.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross validate the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83891283  0.85946304  0.85051376  0.8471992   0.85709549  0.8494695\n",
      "  0.8561008   0.85941645  0.85903814  0.84875622]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85259654196059564"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "rf = RandomForestClassifier(n_estimators= 100, random_state=123) #best tweaked solution above\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print(\"Cross Validation Score for each K\",scores_rf)\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation results are consistant, suggesting the model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Support Vector Machine - Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a linear SVM with default settings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "other svc Accuracy Score 0.847543160691\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.60      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10530   830]\n",
      " [ 1466  2234]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.92031873   5.51128818]\n",
      " [  9.73439575  14.83399734]]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "linsvm = SVC(kernel='linear', probability=True, random_state=123) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "linsvm.fit(features_train, target_train)\n",
    "predicted_linsvm=linsvm.predict(features_test)\n",
    "print(linsvm)\n",
    "print(\"other svc Accuracy Score\", accuracy_score(target_test, predicted_linsvm))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_linsvm, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_linsvm))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_linsvm))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default settings produced an accuracy of 84.8%.  Let's try a grid search of the penalty parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 10}\n",
      "Best Score: 0.846827133479\n",
      "Best Estimator SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1213.355169</td>\n",
       "      <td>24.631265</td>\n",
       "      <td>0.845932</td>\n",
       "      <td>0.848037</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.848730</td>\n",
       "      <td>0.842533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.848481</td>\n",
       "      <td>0.848972</td>\n",
       "      <td>0.846498</td>\n",
       "      <td>0.849610</td>\n",
       "      <td>0.847085</td>\n",
       "      <td>7.905853</td>\n",
       "      <td>0.461572</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280.917448</td>\n",
       "      <td>23.718765</td>\n",
       "      <td>0.846595</td>\n",
       "      <td>0.848949</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.843030</td>\n",
       "      <td>0.850305</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847340</td>\n",
       "      <td>0.849559</td>\n",
       "      <td>0.848806</td>\n",
       "      <td>0.846830</td>\n",
       "      <td>0.850274</td>\n",
       "      <td>0.847913</td>\n",
       "      <td>10.501179</td>\n",
       "      <td>0.230276</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1340.921759</td>\n",
       "      <td>23.459390</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.847120</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>8.364369</td>\n",
       "      <td>0.553893</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1393.728676</td>\n",
       "      <td>23.118766</td>\n",
       "      <td>0.846794</td>\n",
       "      <td>0.848966</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C': 15}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.847244</td>\n",
       "      <td>0.850605</td>\n",
       "      <td>0.847748</td>\n",
       "      <td>15.020301</td>\n",
       "      <td>0.532957</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307.180304</td>\n",
       "      <td>19.578143</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.848941</td>\n",
       "      <td>20</td>\n",
       "      <td>{'C': 20}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.844190</td>\n",
       "      <td>0.850097</td>\n",
       "      <td>0.843196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846677</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.847120</td>\n",
       "      <td>0.850439</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>239.990557</td>\n",
       "      <td>4.501596</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0    1213.355169        24.631265         0.845932          0.848037       1   \n",
       "1    1280.917448        23.718765         0.846595          0.848949       5   \n",
       "2    1340.921759        23.459390         0.846827          0.849007      10   \n",
       "3    1393.728676        23.118766         0.846794          0.848966      15   \n",
       "4    1307.180304        19.578143         0.846562          0.848941      20   \n",
       "\n",
       "      params  rank_test_score  split0_test_score  split0_train_score  \\\n",
       "0   {'C': 1}                5           0.841372            0.848730   \n",
       "1   {'C': 5}                3           0.843030            0.850305   \n",
       "2  {'C': 10}                1           0.844025            0.850139   \n",
       "3  {'C': 15}                2           0.844356            0.850139   \n",
       "4  {'C': 20}                4           0.844190            0.850097   \n",
       "\n",
       "   split1_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.842533       ...                  0.847174            0.848481   \n",
       "1           0.843527       ...                  0.847340            0.849559   \n",
       "2           0.843693       ...                  0.846842            0.849683   \n",
       "3           0.843527       ...                  0.847174            0.849434   \n",
       "4           0.843196       ...                  0.846677            0.849434   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.848972            0.846498           0.849610   \n",
       "1           0.848806            0.846830           0.850274   \n",
       "2           0.848641            0.847120           0.850937   \n",
       "3           0.848309            0.847244           0.850605   \n",
       "4           0.848309            0.847120           0.850439   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.847085      7.905853        0.461572        0.003366   \n",
       "1            0.847913     10.501179        0.230276        0.002867   \n",
       "2            0.847872      8.364369        0.553893        0.002751   \n",
       "3            0.847748     15.020301        0.532957        0.002591   \n",
       "4            0.847789    239.990557        4.501596        0.002648   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.001076  \n",
       "1         0.001356  \n",
       "2         0.001270  \n",
       "3         0.001243  \n",
       "4         0.001263  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[1,5,10,15,20]}\n",
    "\n",
    "grid_search = GridSearchCV(linsvm, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search revealed a C of 10 as best. Let's run the model with that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other svc Accuracy Score 0.847875166003\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.61      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10519   841]\n",
      " [ 1450  2250]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.84727756   5.58432935]\n",
      " [  9.62815405  14.94023904]]\n"
     ]
    }
   ],
   "source": [
    "linsvm = SVC(C=10, kernel='linear', probability=True, random_state=123) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "linsvm.fit(features_train, target_train)\n",
    "predicted_linsvm=linsvm.predict(features_test)\n",
    "print(\"other svc Accuracy Score\", accuracy_score(target_test, predicted_linsvm))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_linsvm, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_linsvm))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_linsvm))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased slightly but is virtually unchanged.  Now let's try a grid search of the degree of the polynomial function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'degree': 1}\n",
      "Best Score: 0.846827133479\n",
      "Best Estimator SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=1, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1342.590867</td>\n",
       "      <td>23.746890</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>1</td>\n",
       "      <td>{'degree': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>12.942726</td>\n",
       "      <td>0.742633</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1339.347711</td>\n",
       "      <td>23.265639</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>2</td>\n",
       "      <td>{'degree': 2}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>10.185917</td>\n",
       "      <td>0.512253</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1338.544585</td>\n",
       "      <td>23.462514</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>3</td>\n",
       "      <td>{'degree': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>14.793538</td>\n",
       "      <td>0.305004</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.397711</td>\n",
       "      <td>23.290639</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>4</td>\n",
       "      <td>{'degree': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>13.677162</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1212.723884</td>\n",
       "      <td>21.259387</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.849007</td>\n",
       "      <td>5</td>\n",
       "      <td>{'degree': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.850139</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.84712</td>\n",
       "      <td>0.850937</td>\n",
       "      <td>0.847872</td>\n",
       "      <td>250.364330</td>\n",
       "      <td>4.835949</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.00127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0    1342.590867        23.746890         0.846827          0.849007   \n",
       "1    1339.347711        23.265639         0.846827          0.849007   \n",
       "2    1338.544585        23.462514         0.846827          0.849007   \n",
       "3    1338.397711        23.290639         0.846827          0.849007   \n",
       "4    1212.723884        21.259387         0.846827          0.849007   \n",
       "\n",
       "  param_degree         params  rank_test_score  split0_test_score  \\\n",
       "0            1  {'degree': 1}                1           0.844025   \n",
       "1            2  {'degree': 2}                1           0.844025   \n",
       "2            3  {'degree': 3}                1           0.844025   \n",
       "3            4  {'degree': 4}                1           0.844025   \n",
       "4            5  {'degree': 5}                1           0.844025   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.850139           0.843693       ...                  0.846842   \n",
       "1            0.850139           0.843693       ...                  0.846842   \n",
       "2            0.850139           0.843693       ...                  0.846842   \n",
       "3            0.850139           0.843693       ...                  0.846842   \n",
       "4            0.850139           0.843693       ...                  0.846842   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.849683           0.848641             0.84712   \n",
       "1            0.849683           0.848641             0.84712   \n",
       "2            0.849683           0.848641             0.84712   \n",
       "3            0.849683           0.848641             0.84712   \n",
       "4            0.849683           0.848641             0.84712   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.850937            0.847872     12.942726        0.742633   \n",
       "1           0.850937            0.847872     10.185917        0.512253   \n",
       "2           0.850937            0.847872     14.793538        0.305004   \n",
       "3           0.850937            0.847872     13.677162        0.501815   \n",
       "4           0.850937            0.847872    250.364330        4.835949   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.002751          0.00127  \n",
       "1        0.002751          0.00127  \n",
       "2        0.002751          0.00127  \n",
       "3        0.002751          0.00127  \n",
       "4        0.002751          0.00127  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'degree':[1,2,3,4,5]}\n",
    "\n",
    "grid_search = GridSearchCV(linsvm, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search revelaed a degree of 1 to be best, though it's effectivly tied with the other degrees per the grid search above.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other svc Accuracy Score 0.847875166002656\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.61      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10519   841]\n",
      " [ 1450  2250]]\n",
      "Confusion Matrix Percent\n",
      "[[69.84727756  5.58432935]\n",
      " [ 9.62815405 14.94023904]]\n"
     ]
    }
   ],
   "source": [
    "linsvm = SVC(C=10, kernel='linear', degree=1, probability=True, random_state=123) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "linsvm.fit(features_train, target_train)\n",
    "predicted_linsvm=linsvm.predict(features_test)\n",
    "print(\"other svc Accuracy Score\", accuracy_score(target_test, predicted_linsvm))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_linsvm, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_linsvm))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_linsvm))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is virtually unchanged.  Now let's cross validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.8435532   0.84653629  0.84819357  0.83924428  0.84615385  0.85013263\n",
      "  0.84615385  0.84913793  0.85538972  0.84742952]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84719248315292117"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Linear SVC with Cross Validation\n",
    "scores = cross_val_score(linsvm, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the linear SVC are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###SVM-RBF \n",
    "Now let's try the SVM-RBF with default parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "RBF Accuracy Score 0.8272244355909695\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.91      0.89     11360\n",
      "     > $50K       0.68      0.57      0.62      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10358  1002]\n",
      " [ 1600  2100]]\n",
      "Confusion Matrix Percent\n",
      "[[68.77822045  6.65338645]\n",
      " [10.62416999 13.94422311]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_rbf = SVC(kernel='rbf', random_state=123) \n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "print(clf_rbf)\n",
    "print(\"RBF Accuracy Score\", accuracy_score(target_test, predicted_rbf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_rbf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_rbf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_rbf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model calculates 82.7% accuracy.  Now let's run a grid search of the penalty parameter, C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 20}\n",
      "Best Score: 0.843147006167\n",
      "Best Estimator SVC(C=20, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=123, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199.820558</td>\n",
       "      <td>29.068766</td>\n",
       "      <td>0.818679</td>\n",
       "      <td>0.819118</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.822311</td>\n",
       "      <td>0.820962</td>\n",
       "      <td>0.813691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.817813</td>\n",
       "      <td>0.829410</td>\n",
       "      <td>0.821384</td>\n",
       "      <td>0.815785</td>\n",
       "      <td>0.817165</td>\n",
       "      <td>1.626299</td>\n",
       "      <td>0.382428</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196.542675</td>\n",
       "      <td>28.128142</td>\n",
       "      <td>0.823122</td>\n",
       "      <td>0.823984</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826952</td>\n",
       "      <td>0.827137</td>\n",
       "      <td>0.817006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.822330</td>\n",
       "      <td>0.834052</td>\n",
       "      <td>0.825528</td>\n",
       "      <td>0.820262</td>\n",
       "      <td>0.822096</td>\n",
       "      <td>1.025101</td>\n",
       "      <td>0.448240</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183.084490</td>\n",
       "      <td>26.428143</td>\n",
       "      <td>0.835522</td>\n",
       "      <td>0.836931</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.835074</td>\n",
       "      <td>0.838410</td>\n",
       "      <td>0.830433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835074</td>\n",
       "      <td>0.836089</td>\n",
       "      <td>0.841844</td>\n",
       "      <td>0.835433</td>\n",
       "      <td>0.835185</td>\n",
       "      <td>0.836352</td>\n",
       "      <td>1.443149</td>\n",
       "      <td>0.484385</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181.390741</td>\n",
       "      <td>25.881264</td>\n",
       "      <td>0.838439</td>\n",
       "      <td>0.840238</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.838720</td>\n",
       "      <td>0.841436</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839383</td>\n",
       "      <td>0.839073</td>\n",
       "      <td>0.843170</td>\n",
       "      <td>0.839121</td>\n",
       "      <td>0.837340</td>\n",
       "      <td>0.840454</td>\n",
       "      <td>2.196188</td>\n",
       "      <td>0.462943</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181.381365</td>\n",
       "      <td>25.903141</td>\n",
       "      <td>0.841058</td>\n",
       "      <td>0.843106</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C': 15}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.841870</td>\n",
       "      <td>0.844005</td>\n",
       "      <td>0.837394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840875</td>\n",
       "      <td>0.841104</td>\n",
       "      <td>0.845656</td>\n",
       "      <td>0.842644</td>\n",
       "      <td>0.839496</td>\n",
       "      <td>0.842858</td>\n",
       "      <td>3.169261</td>\n",
       "      <td>0.263205</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>158.227068</td>\n",
       "      <td>21.637511</td>\n",
       "      <td>0.843147</td>\n",
       "      <td>0.845203</td>\n",
       "      <td>20</td>\n",
       "      <td>{'C': 20}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>0.846160</td>\n",
       "      <td>0.838555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842864</td>\n",
       "      <td>0.843549</td>\n",
       "      <td>0.848806</td>\n",
       "      <td>0.844965</td>\n",
       "      <td>0.840822</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>30.621704</td>\n",
       "      <td>4.281204</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0     199.820558        29.068766         0.818679          0.819118     0.5   \n",
       "1     196.542675        28.128142         0.823122          0.823984       1   \n",
       "2     183.084490        26.428143         0.835522          0.836931       5   \n",
       "3     181.390741        25.881264         0.838439          0.840238      10   \n",
       "4     181.381365        25.903141         0.841058          0.843106      15   \n",
       "5     158.227068        21.637511         0.843147          0.845203      20   \n",
       "\n",
       "       params  rank_test_score  split0_test_score  split0_train_score  \\\n",
       "0  {'C': 0.5}                6           0.822311            0.820962   \n",
       "1    {'C': 1}                5           0.826952            0.827137   \n",
       "2    {'C': 5}                4           0.835074            0.838410   \n",
       "3   {'C': 10}                3           0.838720            0.841436   \n",
       "4   {'C': 15}                2           0.841870            0.844005   \n",
       "5   {'C': 20}                1           0.844688            0.846160   \n",
       "\n",
       "   split1_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.813691       ...                  0.812200            0.817813   \n",
       "1           0.817006       ...                  0.817338            0.822330   \n",
       "2           0.830433       ...                  0.835074            0.836089   \n",
       "3           0.833582       ...                  0.839383            0.839073   \n",
       "4           0.837394       ...                  0.840875            0.841104   \n",
       "5           0.838555       ...                  0.842864            0.843549   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.829410            0.821384           0.815785   \n",
       "1           0.834052            0.825528           0.820262   \n",
       "2           0.841844            0.835433           0.835185   \n",
       "3           0.843170            0.839121           0.837340   \n",
       "4           0.845656            0.842644           0.839496   \n",
       "5           0.848806            0.844965           0.840822   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.817165      1.626299        0.382428        0.006381   \n",
       "1            0.822096      1.025101        0.448240        0.006529   \n",
       "2            0.836352      1.443149        0.484385        0.003644   \n",
       "3            0.840454      2.196188        0.462943        0.003103   \n",
       "4            0.842858      3.169261        0.263205        0.002746   \n",
       "5            0.844101     30.621704        4.281204        0.003492   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.001719  \n",
       "1         0.001998  \n",
       "2         0.001228  \n",
       "3         0.000983  \n",
       "4         0.001294  \n",
       "5         0.001346  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[.5,1,5,10,15,20]}\n",
    "grid_search = GridSearchCV(clf_rbf, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search shows that the best C is 20.  Let's run the model with that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Accuracy Score 0.8427622841965472\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.93      0.90     11360\n",
      "     > $50K       0.73      0.58      0.64      3700\n",
      "\n",
      "avg / total       0.84      0.84      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10551   809]\n",
      " [ 1559  2141]]\n",
      "Confusion Matrix Percent\n",
      "[[70.05976096  5.37184595]\n",
      " [10.35192563 14.21646746]]\n"
     ]
    }
   ],
   "source": [
    "clf_rbf = SVC(kernel='rbf', C=20.0, random_state=123) \n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"RBF Accuracy Score\", accuracy_score(target_test, predicted_rbf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_rbf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_rbf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_rbf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model showed am improvement from 82.7% to 84.3% accuracy.  Now let's try it with a class weight of balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Accuracy Score 0.791965471448\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.94      0.77      0.85     11360\n",
      "     > $50K       0.55      0.85      0.67      3700\n",
      "\n",
      "avg / total       0.85      0.79      0.80     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[8771 2589]\n",
      " [ 544 3156]]\n",
      "Confusion Matrix Percent\n",
      "[[ 58.24037185  17.19123506]\n",
      " [  3.6122178   20.9561753 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=20, random_state=123, class_weight='balanced') #degree=3, gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"RBF Accuracy Score\", accuracy_score(target_test, predicted_rbf))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_rbf, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_rbf))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_rbf))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance dropped from 84.3% to 79.2% accuracy with the balanced setting, so we won't use that setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the SVC-RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.83891283 0.84852502 0.84255883 0.833941   0.8494695  0.83919098\n",
      " 0.84980106 0.84781167 0.84676617 0.8371476 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8434124660503338"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify SVC-RBF with Cross Validation\n",
    "clf_rbf = SVC(kernel='rbf', C=20.0, random_state=123, probability=True) \n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "scores = cross_val_score(clf_rbf, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the SVC-RBF are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the ANN with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "NN Accuracy Score 0.848671978752\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.61      0.67      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10518   842]\n",
      " [ 1437  2263]]\n",
      "Confusion Matrix Percent\n",
      "[[ 69.84063745   5.59096946]\n",
      " [  9.54183267  15.02656042]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(random_state=123) \n",
    "clf_NN.fit(features_train, target_train)\n",
    "predicted_NN = clf_NN.predict(features_test)\n",
    "print(clf_NN)\n",
    "print(\"NN Accuracy Score\", accuracy_score(target_test, predicted_NN))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_NN, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_NN))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_NN))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net had an accuracy score of 84.9%.  First let's find the optimal L2 penalty via a grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'alpha': 0.01}\n",
      "Best Score: 0.850772495193\n",
      "Best Estimator MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.142757</td>\n",
       "      <td>0.049997</td>\n",
       "      <td>0.849977</td>\n",
       "      <td>0.868734</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>{'alpha': 1e-07}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.847008</td>\n",
       "      <td>0.866468</td>\n",
       "      <td>0.846179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852975</td>\n",
       "      <td>0.869866</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>0.869706</td>\n",
       "      <td>0.854585</td>\n",
       "      <td>0.868095</td>\n",
       "      <td>12.059963</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.043809</td>\n",
       "      <td>0.043752</td>\n",
       "      <td>0.848916</td>\n",
       "      <td>0.868560</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.846345</td>\n",
       "      <td>0.866841</td>\n",
       "      <td>0.844522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852312</td>\n",
       "      <td>0.869452</td>\n",
       "      <td>0.848475</td>\n",
       "      <td>0.869581</td>\n",
       "      <td>0.852927</td>\n",
       "      <td>0.867183</td>\n",
       "      <td>11.082648</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.181305</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.849579</td>\n",
       "      <td>0.869372</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.847505</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.845682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850655</td>\n",
       "      <td>0.871358</td>\n",
       "      <td>0.847977</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>0.869007</td>\n",
       "      <td>10.864212</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.993808</td>\n",
       "      <td>0.046880</td>\n",
       "      <td>0.850507</td>\n",
       "      <td>0.868692</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847174</td>\n",
       "      <td>0.866799</td>\n",
       "      <td>0.848334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851981</td>\n",
       "      <td>0.870198</td>\n",
       "      <td>0.849469</td>\n",
       "      <td>0.869043</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.868054</td>\n",
       "      <td>10.619945</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.562556</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.849778</td>\n",
       "      <td>0.868402</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>0.866302</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849826</td>\n",
       "      <td>0.868291</td>\n",
       "      <td>0.850464</td>\n",
       "      <td>0.868960</td>\n",
       "      <td>0.855745</td>\n",
       "      <td>0.869297</td>\n",
       "      <td>4.018548</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73.875046</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.850772</td>\n",
       "      <td>0.865576</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.862821</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>7.449164</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.968775</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.848352</td>\n",
       "      <td>0.852405</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>0.850843</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851815</td>\n",
       "      <td>0.853703</td>\n",
       "      <td>0.856598</td>\n",
       "      <td>0.851678</td>\n",
       "      <td>0.845299</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>8.294496</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.978144</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>0.841821</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.843362</td>\n",
       "      <td>0.842969</td>\n",
       "      <td>0.833085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.843922</td>\n",
       "      <td>0.846320</td>\n",
       "      <td>0.842685</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.843728</td>\n",
       "      <td>6.443358</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.950011</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.839102</td>\n",
       "      <td>0.840122</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.839715</td>\n",
       "      <td>0.839985</td>\n",
       "      <td>0.832587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835737</td>\n",
       "      <td>0.840938</td>\n",
       "      <td>0.845988</td>\n",
       "      <td>0.840116</td>\n",
       "      <td>0.841486</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>3.433784</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      98.142757         0.049997         0.849977          0.868734   \n",
       "1      93.043809         0.043752         0.848916          0.868560   \n",
       "2      91.181305         0.050008         0.849579          0.869372   \n",
       "3      90.993808         0.046880         0.850507          0.868692   \n",
       "4      84.562556         0.043753         0.849778          0.868402   \n",
       "5      73.875046         0.050003         0.850772          0.865576   \n",
       "6      40.968775         0.050000         0.848352          0.852405   \n",
       "7      25.978144         0.043748         0.841821          0.843810   \n",
       "8      21.950011         0.037500         0.839102          0.840122   \n",
       "\n",
       "  param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0       1e-07   {'alpha': 1e-07}                3           0.847008   \n",
       "1       1e-06   {'alpha': 1e-06}                6           0.846345   \n",
       "2       1e-05   {'alpha': 1e-05}                5           0.847505   \n",
       "3      0.0001  {'alpha': 0.0001}                2           0.847174   \n",
       "4       0.001   {'alpha': 0.001}                4           0.846014   \n",
       "5        0.01    {'alpha': 0.01}                1           0.844853   \n",
       "6         0.1     {'alpha': 0.1}                7           0.844688   \n",
       "7         0.3     {'alpha': 0.3}                8           0.843362   \n",
       "8         0.5     {'alpha': 0.5}                9           0.839715   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.866468           0.846179       ...                  0.852975   \n",
       "1            0.866841           0.844522       ...                  0.852312   \n",
       "2            0.867089           0.845682       ...                  0.850655   \n",
       "3            0.866799           0.848334       ...                  0.851981   \n",
       "4            0.866302           0.846842       ...                  0.849826   \n",
       "5            0.866136           0.846014       ...                  0.857285   \n",
       "6            0.850843           0.843362       ...                  0.851815   \n",
       "7            0.842969           0.833085       ...                  0.841372   \n",
       "8            0.839985           0.832587       ...                  0.835737   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.869866           0.849138            0.869706   \n",
       "1            0.869452           0.848475            0.869581   \n",
       "2            0.871358           0.847977            0.869333   \n",
       "3            0.870198           0.849469            0.869043   \n",
       "4            0.868291           0.850464            0.868960   \n",
       "5            0.862821           0.850133            0.866059   \n",
       "6            0.853703           0.856598            0.851678   \n",
       "7            0.843922           0.846320            0.842685   \n",
       "8            0.840938           0.845988            0.840116   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.854585            0.868095     12.059963        0.006250   \n",
       "1           0.852927            0.867183     11.082648        0.006250   \n",
       "2           0.856077            0.869007     10.864212        0.011690   \n",
       "3           0.855580            0.868054     10.619945        0.009880   \n",
       "4           0.855745            0.869297      4.018548        0.011691   \n",
       "5           0.855580            0.866769      7.449164        0.006248   \n",
       "6           0.845299            0.849985      8.294496        0.006251   \n",
       "7           0.844968            0.843728      6.443358        0.006246   \n",
       "8           0.841486            0.840164      3.433784        0.007652   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.003291         0.001297  \n",
       "1        0.003278         0.001272  \n",
       "2        0.003617         0.001399  \n",
       "3        0.002994         0.001169  \n",
       "4        0.003431         0.001106  \n",
       "5        0.004972         0.001402  \n",
       "6        0.005053         0.002105  \n",
       "7        0.004670         0.001071  \n",
       "8        0.004631         0.000490  \n",
       "\n",
       "[9 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'alpha':[.0000001,.000001,.00001,.0001,.001,.01,.1,.3,.5]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_NN, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search found an alpha of 0.01, so let's run the model with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy Score 0.849070385126\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.74      0.59      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10591   769]\n",
      " [ 1504  2196]]\n",
      "Confusion Matrix Percent\n",
      "[[ 70.32536521   5.1062417 ]\n",
      " [  9.98671979  14.58167331]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(alpha=0.01, random_state=123)\n",
    "clf_NN.fit(features_train, target_train)\n",
    "predicted_NN = clf_NN.predict(features_test)\n",
    "print(\"NN Accuracy Score\", accuracy_score(target_test, predicted_NN))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_NN, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_NN))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_NN))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased slightly but still rounds to 84.9%.  Now let's try adjusting the layer sizes (number of neurons) in the neural net via grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'hidden_layer_sizes': (100,)}\n",
      "Best Score: 0.850772495193\n",
      "Best Estimator MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.115970</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.847855</td>\n",
       "      <td>0.850292</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>{'hidden_layer_sizes': (2,)}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.844522</td>\n",
       "      <td>0.851382</td>\n",
       "      <td>0.842035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851152</td>\n",
       "      <td>0.850926</td>\n",
       "      <td>0.851790</td>\n",
       "      <td>0.849192</td>\n",
       "      <td>0.849776</td>\n",
       "      <td>0.848991</td>\n",
       "      <td>3.547946</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.703139</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.848220</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>{'hidden_layer_sizes': (5,)}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>0.849766</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850489</td>\n",
       "      <td>0.848978</td>\n",
       "      <td>0.853282</td>\n",
       "      <td>0.848363</td>\n",
       "      <td>0.848615</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>1.526172</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.193773</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.850043</td>\n",
       "      <td>0.853765</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>{'hidden_layer_sizes': (10,)}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847505</td>\n",
       "      <td>0.855402</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.854739</td>\n",
       "      <td>0.851956</td>\n",
       "      <td>0.852549</td>\n",
       "      <td>0.853921</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>7.829595</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.868785</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.863661</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{'hidden_layer_sizes': (50,)}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.846345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851152</td>\n",
       "      <td>0.863235</td>\n",
       "      <td>0.851127</td>\n",
       "      <td>0.861210</td>\n",
       "      <td>0.854916</td>\n",
       "      <td>0.863827</td>\n",
       "      <td>9.800606</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.787553</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.850772</td>\n",
       "      <td>0.865576</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'hidden_layer_sizes': (100,)}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.862821</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>18.023311</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98.315688</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.849910</td>\n",
       "      <td>0.866256</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>{'hidden_layer_sizes': (200,)}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.845848</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849992</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.854443</td>\n",
       "      <td>0.869167</td>\n",
       "      <td>0.854916</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>15.953529</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.002624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>170.538053</td>\n",
       "      <td>0.146872</td>\n",
       "      <td>0.847722</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>(400,)</td>\n",
       "      <td>{'hidden_layer_sizes': (400,)}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.837394</td>\n",
       "      <td>0.861494</td>\n",
       "      <td>0.845848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854301</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>0.851625</td>\n",
       "      <td>0.871073</td>\n",
       "      <td>0.849445</td>\n",
       "      <td>0.867846</td>\n",
       "      <td>43.205338</td>\n",
       "      <td>0.027242</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      42.115970         0.015623         0.847855          0.850292   \n",
       "1      23.703139         0.015627         0.848220          0.849156   \n",
       "2      33.193773         0.015625         0.850043          0.853765   \n",
       "3      58.868785         0.028125         0.849513          0.863661   \n",
       "4      75.787553         0.046874         0.850772          0.865576   \n",
       "5      98.315688         0.106250         0.849910          0.866256   \n",
       "6     170.538053         0.146872         0.847722          0.867515   \n",
       "\n",
       "  param_hidden_layer_sizes                          params  rank_test_score  \\\n",
       "0                     (2,)    {'hidden_layer_sizes': (2,)}                6   \n",
       "1                     (5,)    {'hidden_layer_sizes': (5,)}                5   \n",
       "2                    (10,)   {'hidden_layer_sizes': (10,)}                2   \n",
       "3                    (50,)   {'hidden_layer_sizes': (50,)}                4   \n",
       "4                   (100,)  {'hidden_layer_sizes': (100,)}                1   \n",
       "5                   (200,)  {'hidden_layer_sizes': (200,)}                3   \n",
       "6                   (400,)  {'hidden_layer_sizes': (400,)}                7   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.844522            0.851382           0.842035       ...          \n",
       "1           0.845019            0.849766           0.843693       ...          \n",
       "2           0.847505            0.855402           0.844688       ...          \n",
       "3           0.844025            0.865183           0.846345       ...          \n",
       "4           0.844853            0.866136           0.846014       ...          \n",
       "5           0.845848            0.867131           0.844356       ...          \n",
       "6           0.837394            0.861494           0.845848       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.851152            0.850926           0.851790   \n",
       "1           0.850489            0.848978           0.853282   \n",
       "2           0.852147            0.854739           0.851956   \n",
       "3           0.851152            0.863235           0.851127   \n",
       "4           0.857285            0.862821           0.850133   \n",
       "5           0.849992            0.867255           0.854443   \n",
       "6           0.854301            0.870736           0.851625   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.849192           0.849776            0.848991      3.547946   \n",
       "1            0.848363           0.848615            0.849447      1.526172   \n",
       "2            0.852549           0.853921            0.852679      7.829595   \n",
       "3            0.861210           0.854916            0.863827      9.800606   \n",
       "4            0.866059           0.855580            0.866769     18.023311   \n",
       "5            0.869167           0.854916            0.861340     15.953529   \n",
       "6            0.871073           0.849445            0.867846     43.205338   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000004        0.003874         0.000995  \n",
       "1        0.000002        0.003512         0.000474  \n",
       "2        0.000006        0.003413         0.001130  \n",
       "3        0.006251        0.003864         0.001411  \n",
       "4        0.013968        0.004972         0.001402  \n",
       "5        0.026882        0.004312         0.002624  \n",
       "6        0.027242        0.005860         0.003481  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'hidden_layer_sizes':[(2,),(5,),(10,),(50,),(100,),(200,),(400,)]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_NN, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid serach determined 100 as the optimal hidden layer size.  Let's do a grid search on the length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'hidden_layer_sizes': (100,)}\n",
      "Best Score: 0.850772495193\n",
      "Best Estimator MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=123,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.369224</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.850772</td>\n",
       "      <td>0.865576</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'hidden_layer_sizes': (100,)}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844853</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.862821</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.866059</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.866769</td>\n",
       "      <td>7.075503</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.341985</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.847557</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>(100, 2)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 2)}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.844025</td>\n",
       "      <td>0.866219</td>\n",
       "      <td>0.842533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849494</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.851459</td>\n",
       "      <td>0.870990</td>\n",
       "      <td>0.850274</td>\n",
       "      <td>0.870830</td>\n",
       "      <td>14.796522</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.018802</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.848651</td>\n",
       "      <td>0.865592</td>\n",
       "      <td>(100, 4)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 4)}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.848831</td>\n",
       "      <td>0.864520</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848666</td>\n",
       "      <td>0.865473</td>\n",
       "      <td>0.848972</td>\n",
       "      <td>0.869416</td>\n",
       "      <td>0.852429</td>\n",
       "      <td>0.865526</td>\n",
       "      <td>16.146463</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.737539</td>\n",
       "      <td>0.053128</td>\n",
       "      <td>0.849678</td>\n",
       "      <td>0.868618</td>\n",
       "      <td>(100, 6)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 6)}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.850157</td>\n",
       "      <td>0.868581</td>\n",
       "      <td>0.841538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.869410</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.865562</td>\n",
       "      <td>0.855745</td>\n",
       "      <td>0.868965</td>\n",
       "      <td>5.694844</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.001668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.621920</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>0.846827</td>\n",
       "      <td>0.870441</td>\n",
       "      <td>(100, 8)</td>\n",
       "      <td>{'hidden_layer_sizes': (100, 8)}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.848003</td>\n",
       "      <td>0.874135</td>\n",
       "      <td>0.837560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844522</td>\n",
       "      <td>0.868208</td>\n",
       "      <td>0.849469</td>\n",
       "      <td>0.869001</td>\n",
       "      <td>0.854585</td>\n",
       "      <td>0.871700</td>\n",
       "      <td>17.381836</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.002187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      73.369224         0.043753         0.850772          0.865576   \n",
       "1     114.341985         0.046874         0.847557          0.869588   \n",
       "2      85.018802         0.050005         0.848651          0.865592   \n",
       "3      63.737539         0.053128         0.849678          0.868618   \n",
       "4      73.621920         0.043753         0.846827          0.870441   \n",
       "\n",
       "  param_hidden_layer_sizes                            params  rank_test_score  \\\n",
       "0                   (100,)    {'hidden_layer_sizes': (100,)}                1   \n",
       "1                 (100, 2)  {'hidden_layer_sizes': (100, 2)}                4   \n",
       "2                 (100, 4)  {'hidden_layer_sizes': (100, 4)}                3   \n",
       "3                 (100, 6)  {'hidden_layer_sizes': (100, 6)}                2   \n",
       "4                 (100, 8)  {'hidden_layer_sizes': (100, 8)}                5   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.844853            0.866136           0.846014       ...          \n",
       "1           0.844025            0.866219           0.842533       ...          \n",
       "2           0.848831            0.864520           0.844356       ...          \n",
       "3           0.850157            0.868581           0.841538       ...          \n",
       "4           0.848003            0.874135           0.837560       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.857285            0.862821           0.850133   \n",
       "1           0.849494            0.868167           0.851459   \n",
       "2           0.848666            0.865473           0.848972   \n",
       "3           0.850820            0.869410           0.850133   \n",
       "4           0.844522            0.868208           0.849469   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.866059           0.855580            0.866769      7.075503   \n",
       "1            0.870990           0.850274            0.870830     14.796522   \n",
       "2            0.869416           0.852429            0.865526     16.146463   \n",
       "3            0.865562           0.855745            0.868965      5.694844   \n",
       "4            0.869001           0.854585            0.871700     17.381836   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.006253        0.004972         0.001402  \n",
       "1        0.000002        0.003580         0.002072  \n",
       "2        0.006246        0.002563         0.002115  \n",
       "3        0.007654        0.004578         0.001668  \n",
       "4        0.011694        0.005652         0.002187  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'hidden_layer_sizes':[(100,),(100,2),(100,4),(100,6),(100,8)]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_NN, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_)\n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default was optimal.  Now let's run the model with the layers/nodes results from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy Score 0.8490703851261621\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.74      0.59      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10591   769]\n",
      " [ 1504  2196]]\n",
      "Confusion Matrix Percent\n",
      "[[70.32536521  5.1062417 ]\n",
      " [ 9.98671979 14.58167331]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(alpha=0.01, hidden_layer_sizes=(100, ), random_state=123) \n",
    "clf_NN.fit(features_train, target_train)\n",
    "predicted_NN = clf_NN.predict(features_test)\n",
    "print(\"NN Accuracy Score\", accuracy_score(target_test, predicted_NN))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_NN, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_NN))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_NN))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy was unchanged.  Now let's cross validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.85084521  0.84918794  0.84819357  0.8435532   0.84781167  0.85311671\n",
      "  0.8428382   0.85344828  0.85704809  0.85339967]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84994425291271136"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify NN with Cross Validation\n",
    "\n",
    "scores = cross_val_score(clf_NN, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation results are similar to each other, suggesting the model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to Stochastic Gradient Descent with default settings.  (Exception: the loss function is set to 'log', so it uses a logistic regression, not a linear one.  This is more appropriate for what we're trying to do - predict above/below $50K, and allows for calculation of area under the ROC curve later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=123, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "SGD Accuracy Score 0.829747675963\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.84      0.96      0.89     11360\n",
      "     > $50K       0.78      0.43      0.55      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.81     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10908   452]\n",
      " [ 2112  1588]]\n",
      "Confusion Matrix Percent\n",
      "[[ 72.43027888   3.00132802]\n",
      " [ 14.02390438  10.54448871]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf_sgd = linear_model.SGDClassifier(loss='log', random_state=123)\n",
    "clf_sgd.fit(features_train, target_train)\n",
    "predicted_sgd=clf_sgd.predict(features_test)\n",
    "print(clf_sgd)\n",
    "# summarize the fit of the model\n",
    "print(\"SGD Accuracy Score\", accuracy_score(target_test, predicted_sgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_sgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_sgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_sgd))/len(target_test.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SGD achieved an accuracy of 83.0%  Let's try adjusting the regularization term, alpha, with a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'alpha': 0.0001}\n",
      "Best Score: 0.833830647835\n",
      "Best Estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=123, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362490</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.797825</td>\n",
       "      <td>0.801357</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811371</td>\n",
       "      <td>0.821335</td>\n",
       "      <td>0.805404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823637</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.753813</td>\n",
       "      <td>0.748695</td>\n",
       "      <td>0.794893</td>\n",
       "      <td>0.795284</td>\n",
       "      <td>0.075501</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>0.028298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.412502</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.833831</td>\n",
       "      <td>0.834129</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831759</td>\n",
       "      <td>0.836338</td>\n",
       "      <td>0.834576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840212</td>\n",
       "      <td>0.839363</td>\n",
       "      <td>0.838196</td>\n",
       "      <td>0.834107</td>\n",
       "      <td>0.824407</td>\n",
       "      <td>0.821226</td>\n",
       "      <td>0.048007</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.006765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412502</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.833366</td>\n",
       "      <td>0.834751</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829604</td>\n",
       "      <td>0.836131</td>\n",
       "      <td>0.829604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831261</td>\n",
       "      <td>0.835426</td>\n",
       "      <td>0.841678</td>\n",
       "      <td>0.833527</td>\n",
       "      <td>0.834687</td>\n",
       "      <td>0.834280</td>\n",
       "      <td>0.032174</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.374999</td>\n",
       "      <td>0.018751</td>\n",
       "      <td>0.817784</td>\n",
       "      <td>0.818621</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.813691</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.815183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819161</td>\n",
       "      <td>0.818517</td>\n",
       "      <td>0.821784</td>\n",
       "      <td>0.817033</td>\n",
       "      <td>0.819101</td>\n",
       "      <td>0.820604</td>\n",
       "      <td>0.048413</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.421874</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.034227</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.063586</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.390626</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>2</td>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.029648</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.412497</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.409374</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751036</td>\n",
       "      <td>0.751088</td>\n",
       "      <td>0.751160</td>\n",
       "      <td>0.751057</td>\n",
       "      <td>0.751119</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.076802</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.362490         0.012496         0.797825          0.801357   \n",
       "1       0.412502         0.009377         0.833831          0.834129   \n",
       "2       0.412502         0.015624         0.833366          0.834751   \n",
       "3       0.374999         0.018751         0.817784          0.818621   \n",
       "4       0.421874         0.006248         0.751078          0.751078   \n",
       "5       0.512500         0.003126         0.751078          0.751078   \n",
       "6       0.400000         0.012502         0.751078          0.751078   \n",
       "7       0.390626         0.009375         0.751078          0.751078   \n",
       "8       0.412497         0.012501         0.751078          0.751078   \n",
       "9       0.409374         0.009375         0.751078          0.751078   \n",
       "\n",
       "  param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0       1e-05   {'alpha': 1e-05}                4           0.811371   \n",
       "1      0.0001  {'alpha': 0.0001}                1           0.831759   \n",
       "2       0.001   {'alpha': 0.001}                2           0.829604   \n",
       "3        0.01    {'alpha': 0.01}                3           0.813691   \n",
       "4         0.1     {'alpha': 0.1}                5           0.751036   \n",
       "5         0.5     {'alpha': 0.5}                5           0.751036   \n",
       "6           1       {'alpha': 1}                5           0.751036   \n",
       "7           2       {'alpha': 2}                5           0.751036   \n",
       "8           5       {'alpha': 5}                5           0.751036   \n",
       "9          10      {'alpha': 10}                5           0.751036   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0            0.821335           0.805404       ...                  0.823637   \n",
       "1            0.836338           0.834576       ...                  0.840212   \n",
       "2            0.836131           0.829604       ...                  0.831261   \n",
       "3            0.817978           0.815183       ...                  0.819161   \n",
       "4            0.751088           0.751036       ...                  0.751036   \n",
       "5            0.751088           0.751036       ...                  0.751036   \n",
       "6            0.751088           0.751036       ...                  0.751036   \n",
       "7            0.751088           0.751036       ...                  0.751036   \n",
       "8            0.751088           0.751036       ...                  0.751036   \n",
       "9            0.751088           0.751036       ...                  0.751036   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.825397           0.753813            0.748695   \n",
       "1            0.839363           0.838196            0.834107   \n",
       "2            0.835426           0.841678            0.833527   \n",
       "3            0.818517           0.821784            0.817033   \n",
       "4            0.751088           0.751160            0.751057   \n",
       "5            0.751088           0.751160            0.751057   \n",
       "6            0.751088           0.751160            0.751057   \n",
       "7            0.751088           0.751160            0.751057   \n",
       "8            0.751088           0.751160            0.751057   \n",
       "9            0.751088           0.751160            0.751057   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.794893            0.795284      0.075501        0.006248   \n",
       "1           0.824407            0.821226      0.048007        0.012503   \n",
       "2           0.834687            0.834280      0.032174        0.013975   \n",
       "3           0.819101            0.820604      0.048413        0.015310   \n",
       "4           0.751119            0.751067      0.034227        0.007653   \n",
       "5           0.751119            0.751067      0.063586        0.006252   \n",
       "6           0.751119            0.751067      0.025388        0.006251   \n",
       "7           0.751119            0.751067      0.029648        0.007655   \n",
       "8           0.751119            0.751067      0.037761        0.006251   \n",
       "9           0.751119            0.751067      0.076802        0.007655   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.023886         0.028298  \n",
       "1        0.005539         0.006765  \n",
       "2        0.004551         0.000918  \n",
       "3        0.002938         0.001183  \n",
       "4        0.000053         0.000013  \n",
       "5        0.000053         0.000013  \n",
       "6        0.000053         0.000013  \n",
       "7        0.000053         0.000013  \n",
       "8        0.000053         0.000013  \n",
       "9        0.000053         0.000013  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"alpha\": [0.00001,0.0001,0.001,0.01,0.1,.5,1,2,5,10]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_sgd, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid serach found an alpha of 0.001 as best, so let's run the model with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy Score 0.834926958831\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.93      0.90     11360\n",
      "     > $50K       0.72      0.53      0.61      3700\n",
      "\n",
      "avg / total       0.83      0.83      0.83     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10596   764]\n",
      " [ 1722  1978]]\n",
      "Confusion Matrix Percent\n",
      "[[ 70.35856574   5.07304117]\n",
      " [ 11.43426295  13.13413015]]\n"
     ]
    }
   ],
   "source": [
    "clf_sgd = linear_model.SGDClassifier(alpha=0.001, loss='log', random_state=123)\n",
    "clf_sgd.fit(features_train, target_train)\n",
    "predicted_sgd=clf_sgd.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"SGD Accuracy Score\", accuracy_score(target_test, predicted_sgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_sgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_sgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_sgd))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy increased slightly from 83.0% to 83.5%.  Since the default setting relies on L2, let's set the model to L1 and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy Score 0.8402390438247012\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.94      0.90     11360\n",
      "     > $50K       0.74      0.55      0.63      3700\n",
      "\n",
      "avg / total       0.83      0.84      0.83     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10631   729]\n",
      " [ 1677  2023]]\n",
      "Confusion Matrix Percent\n",
      "[[70.59096946  4.84063745]\n",
      " [11.13545817 13.43293493]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_sgd = linear_model.SGDClassifier(alpha=0.001, penalty='l1', loss='log', random_state=123)\n",
    "clf_sgd.fit(features_train, target_train)\n",
    "predicted_sgd=clf_sgd.predict(features_test)\n",
    "# summarize the fit of the model\n",
    "print(\"SGD Accuracy Score\", accuracy_score(target_test, predicted_sgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_sgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_sgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_sgd))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy increased slightly using L1, from 83.5% to 84.0%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.83427246  0.84023865  0.83791846  0.83162082  0.84084881  0.83852785\n",
      "  0.8418435   0.85079576  0.84809287  0.83217247]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83963316362595486"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify SGD with Cross Validation\n",
    "\n",
    "scores = cross_val_score(clf_sgd, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the SGD are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adaboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to Ada Boost, this time with the Decision Tree as the base learner (with a max depth of 9, which was the best result achieved above).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy Score 0.8111553784860558\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.89      0.88     11360\n",
      "     > $50K       0.63      0.56      0.59      3700\n",
      "\n",
      "avg / total       0.80      0.81      0.81     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10141  1219]\n",
      " [ 1625  2075]]\n",
      "Confusion Matrix Percent\n",
      "[[67.3373174   8.09428951]\n",
      " [10.79017264 13.77822045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=9,random_state=123))#, algorithm=\"SAMME\", n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "print(\"Adaboost Accuracy Score\", accuracy_score(target_test, predicted_bdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the decision tree classifier as its base, an accuracy of 80.9% was achieved, which is worse than the 84.2% achieved by the decision tree alone.  Let's try it now with a SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy Score 0.754316069057\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.75      1.00      0.86     11360\n",
      "     > $50K       0.00      0.00      0.00      3700\n",
      "\n",
      "avg / total       0.57      0.75      0.65     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "Confusion Matrix Percent\n",
      "[[ 75.43160691   0.        ]\n",
      " [ 24.56839309   0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\mlatw\\Anaconda36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "bsgd = AdaBoostClassifier(linear_model.SGDClassifier(alpha=0.001, penalty='l1', loss='log', random_state=123), algorithm='SAMME') #, , n_estimators=200)\n",
    "bsgd.fit(features_train, target_train)\n",
    "predicted_bsgd=bsgd.predict(features_test)\n",
    "print(\"Adaboost Accuracy Score\", accuracy_score(target_test, predicted_bsgd))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bsgd, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bsgd))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bsgd))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model didn't predict any values above $50K!  Obviously we wouldn't use this.  Now let's cross validate the AdaBoost using decisioon tree as the base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.82200862  0.81339079  0.81305933  0.80543586  0.81730769  0.81863395\n",
      "  0.81830239  0.82261273  0.8318408   0.81293532]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81755274806107825"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify ADA Boost with Cross Validation\n",
    "scores = cross_val_score(bdt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the ADA Boost are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the bagging classifier with the decision tree reached above as the base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=123, verbose=0, warm_start=False)\n",
      "Bagging Accuracy Score 0.8469455511288181\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.95      0.90     11360\n",
      "     > $50K       0.77      0.54      0.64      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10747   613]\n",
      " [ 1692  2008]]\n",
      "Confusion Matrix Percent\n",
      "[[71.36122178  4.07038513]\n",
      " [11.23505976 13.33333333]]\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifer\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier(base_estimator=(tree.DecisionTreeClassifier(max_depth=9,random_state=123)),random_state=123)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "print(\"Bagging Accuracy Score\", accuracy_score(target_test, predicted_bag))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bag, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bag))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bag))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bagging classifier had an accuracy of 84.7%.  Now let's run a grid search to find the best value of the number of base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 7}\n",
      "Best Score: 0.8564087262117897\n",
      "Best Estimator BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=7, n_jobs=1, oob_score=False,\n",
      "         random_state=123, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.280507</td>\n",
       "      <td>0.042491</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 2}</td>\n",
       "      <td>0.842864</td>\n",
       "      <td>0.849163</td>\n",
       "      <td>0.854301</td>\n",
       "      <td>0.856764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851535</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>7</td>\n",
       "      <td>0.866095</td>\n",
       "      <td>0.864561</td>\n",
       "      <td>0.863732</td>\n",
       "      <td>0.860588</td>\n",
       "      <td>0.863951</td>\n",
       "      <td>0.863786</td>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.629973</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>0.028244</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "      <td>0.848168</td>\n",
       "      <td>0.853638</td>\n",
       "      <td>0.856953</td>\n",
       "      <td>0.861240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855679</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>6</td>\n",
       "      <td>0.869990</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.866426</td>\n",
       "      <td>0.865520</td>\n",
       "      <td>0.866023</td>\n",
       "      <td>0.867259</td>\n",
       "      <td>0.001665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.795765</td>\n",
       "      <td>0.018201</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_estimators': 7}</td>\n",
       "      <td>0.850655</td>\n",
       "      <td>0.852810</td>\n",
       "      <td>0.857782</td>\n",
       "      <td>0.861074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856409</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.868623</td>\n",
       "      <td>0.866468</td>\n",
       "      <td>0.865106</td>\n",
       "      <td>0.866272</td>\n",
       "      <td>0.867308</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.023563</td>\n",
       "      <td>0.010763</td>\n",
       "      <td>0.035950</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>0.857616</td>\n",
       "      <td>0.859085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>4</td>\n",
       "      <td>0.870944</td>\n",
       "      <td>0.868001</td>\n",
       "      <td>0.866634</td>\n",
       "      <td>0.866846</td>\n",
       "      <td>0.865857</td>\n",
       "      <td>0.867656</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.990594</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.062433</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.851981</td>\n",
       "      <td>0.853307</td>\n",
       "      <td>0.858114</td>\n",
       "      <td>0.859085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856276</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>2</td>\n",
       "      <td>0.870281</td>\n",
       "      <td>0.868540</td>\n",
       "      <td>0.865888</td>\n",
       "      <td>0.866971</td>\n",
       "      <td>0.867266</td>\n",
       "      <td>0.867789</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.938093</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>0.152515</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.850157</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.857451</td>\n",
       "      <td>0.860245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>3</td>\n",
       "      <td>0.868789</td>\n",
       "      <td>0.867918</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.867302</td>\n",
       "      <td>0.868468</td>\n",
       "      <td>0.867532</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.760172</td>\n",
       "      <td>0.585971</td>\n",
       "      <td>0.276963</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.850820</td>\n",
       "      <td>0.852975</td>\n",
       "      <td>0.856953</td>\n",
       "      <td>0.859582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>4</td>\n",
       "      <td>0.868706</td>\n",
       "      <td>0.868125</td>\n",
       "      <td>0.865722</td>\n",
       "      <td>0.867426</td>\n",
       "      <td>0.868385</td>\n",
       "      <td>0.867673</td>\n",
       "      <td>0.001063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.280507      0.042491         0.015619        0.004611   \n",
       "1       0.629973      0.020761         0.028244        0.007569   \n",
       "2       0.795765      0.018201         0.025990        0.000886   \n",
       "3       1.023563      0.010763         0.035950        0.003151   \n",
       "4       1.990594      0.005550         0.062433        0.001228   \n",
       "5       4.938093      0.031658         0.152515        0.007893   \n",
       "6       9.760172      0.585971         0.276963        0.027283   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                  2    {'n_estimators': 2}           0.842864   \n",
       "1                  5    {'n_estimators': 5}           0.848168   \n",
       "2                  7    {'n_estimators': 7}           0.850655   \n",
       "3                 10   {'n_estimators': 10}           0.852147   \n",
       "4                 20   {'n_estimators': 20}           0.851981   \n",
       "5                 50   {'n_estimators': 50}           0.850157   \n",
       "6                100  {'n_estimators': 100}           0.850820   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.849163           0.854301           0.856764       ...          \n",
       "1           0.853638           0.856953           0.861240       ...          \n",
       "2           0.852810           0.857782           0.861074       ...          \n",
       "3           0.852644           0.857616           0.859085       ...          \n",
       "4           0.853307           0.858114           0.859085       ...          \n",
       "5           0.852147           0.857451           0.860245       ...          \n",
       "6           0.852975           0.856953           0.859582       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.851535        0.005002                7            0.866095   \n",
       "1         0.855679        0.004484                6            0.869990   \n",
       "2         0.856409        0.004018                1            0.870073   \n",
       "3         0.855978        0.002966                4            0.870944   \n",
       "4         0.856276        0.003013                2            0.870281   \n",
       "5         0.856077        0.004203                3            0.868789   \n",
       "6         0.855978        0.003532                4            0.868706   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.864561            0.863732            0.860588   \n",
       "1            0.868333            0.866426            0.865520   \n",
       "2            0.868623            0.866468            0.865106   \n",
       "3            0.868001            0.866634            0.866846   \n",
       "4            0.868540            0.865888            0.866971   \n",
       "5            0.867918            0.865183            0.867302   \n",
       "6            0.868125            0.865722            0.867426   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.863951          0.863786         0.001799  \n",
       "1            0.866023          0.867259         0.001665  \n",
       "2            0.866272          0.867308         0.001789  \n",
       "3            0.865857          0.867656         0.001781  \n",
       "4            0.867266          0.867789         0.001505  \n",
       "5            0.868468          0.867532         0.001279  \n",
       "6            0.868385          0.867673         0.001063  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [2,5,7,10,20,50,100]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_bag, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search found a value of 7 estimators to be best.  Let's run the model with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=7, n_jobs=1, oob_score=False,\n",
      "         random_state=123, verbose=0, warm_start=False)\n",
      "Bagging Accuracy Score 0.8482735723771581\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.94      0.90     11360\n",
      "     > $50K       0.76      0.55      0.64      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10722   638]\n",
      " [ 1647  2053]]\n",
      "Confusion Matrix Percent\n",
      "[[71.19521912  4.23638778]\n",
      " [10.93625498 13.63213811]]\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier(base_estimator=(tree.DecisionTreeClassifier(max_depth=9,random_state=123)),n_estimators=7,random_state=123)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "print(\"Bagging Accuracy Score\", accuracy_score(target_test, predicted_bag))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bag, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bag))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bag))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy improved slightly to 84.8%.  Now let's run a grid search to determine the impact on max sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_samples': 15000}\n",
      "Best Score: 0.8553146343080698\n",
      "Best Estimator BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=15000, n_estimators=7, n_jobs=1, oob_score=False,\n",
      "         random_state=123, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167360</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_samples': 50}</td>\n",
       "      <td>0.806067</td>\n",
       "      <td>0.815017</td>\n",
       "      <td>0.809050</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816093</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>6</td>\n",
       "      <td>0.815533</td>\n",
       "      <td>0.815077</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.817074</td>\n",
       "      <td>0.825909</td>\n",
       "      <td>0.816690</td>\n",
       "      <td>0.005211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133294</td>\n",
       "      <td>0.022749</td>\n",
       "      <td>0.027499</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 100}</td>\n",
       "      <td>0.816178</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.816343</td>\n",
       "      <td>0.837865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825708</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826599</td>\n",
       "      <td>0.824609</td>\n",
       "      <td>0.819014</td>\n",
       "      <td>0.832283</td>\n",
       "      <td>0.832953</td>\n",
       "      <td>0.827092</td>\n",
       "      <td>0.005157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.189957</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.028977</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 1000}</td>\n",
       "      <td>0.841041</td>\n",
       "      <td>0.837063</td>\n",
       "      <td>0.846511</td>\n",
       "      <td>0.845491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843213</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>4</td>\n",
       "      <td>0.849932</td>\n",
       "      <td>0.849269</td>\n",
       "      <td>0.851589</td>\n",
       "      <td>0.847161</td>\n",
       "      <td>0.847541</td>\n",
       "      <td>0.849098</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342811</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.030637</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'max_samples': 5000}</td>\n",
       "      <td>0.849660</td>\n",
       "      <td>0.846179</td>\n",
       "      <td>0.855793</td>\n",
       "      <td>0.859582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852662</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864893</td>\n",
       "      <td>0.864437</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>0.862122</td>\n",
       "      <td>0.859848</td>\n",
       "      <td>0.862567</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493749</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_samples': 10000}</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.851815</td>\n",
       "      <td>0.854301</td>\n",
       "      <td>0.860411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854585</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>2</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.865349</td>\n",
       "      <td>0.863484</td>\n",
       "      <td>0.863780</td>\n",
       "      <td>0.865277</td>\n",
       "      <td>0.864805</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.579125</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>15000</td>\n",
       "      <td>{'max_samples': 15000}</td>\n",
       "      <td>0.849163</td>\n",
       "      <td>0.851152</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>0.859085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855315</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868291</td>\n",
       "      <td>0.866261</td>\n",
       "      <td>0.865846</td>\n",
       "      <td>0.864484</td>\n",
       "      <td>0.866810</td>\n",
       "      <td>0.866338</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.167360      0.024942         0.027988        0.004003   \n",
       "1       0.133294      0.022749         0.027499        0.005313   \n",
       "2       0.189957      0.011494         0.028977        0.005111   \n",
       "3       0.342811      0.015081         0.030637        0.004303   \n",
       "4       0.493749      0.030830         0.025749        0.000842   \n",
       "5       0.579125      0.043451         0.024136        0.001774   \n",
       "\n",
       "  param_max_samples                  params  split0_test_score  \\\n",
       "0                50     {'max_samples': 50}           0.806067   \n",
       "1               100    {'max_samples': 100}           0.816178   \n",
       "2              1000   {'max_samples': 1000}           0.841041   \n",
       "3              5000   {'max_samples': 5000}           0.849660   \n",
       "4             10000  {'max_samples': 10000}           0.850323   \n",
       "5             15000  {'max_samples': 15000}           0.849163   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.815017           0.809050           0.827586       ...          \n",
       "1           0.828941           0.816343           0.837865       ...          \n",
       "2           0.837063           0.846511           0.845491       ...          \n",
       "3           0.846179           0.855793           0.859582       ...          \n",
       "4           0.851815           0.854301           0.860411       ...          \n",
       "5           0.851152           0.858611           0.859085       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.816093        0.008095                6            0.815533   \n",
       "1         0.825708        0.008355                5            0.826599   \n",
       "2         0.843213        0.003638                4            0.849932   \n",
       "3         0.852662        0.004670                3            0.864893   \n",
       "4         0.854585        0.003524                2            0.866136   \n",
       "5         0.855315        0.004262                1            0.868291   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.815077            0.809855            0.817074   \n",
       "1            0.824609            0.819014            0.832283   \n",
       "2            0.849269            0.851589            0.847161   \n",
       "3            0.864437            0.861536            0.862122   \n",
       "4            0.865349            0.863484            0.863780   \n",
       "5            0.866261            0.865846            0.864484   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.825909          0.816690         0.005211  \n",
       "1            0.832953          0.827092         0.005157  \n",
       "2            0.847541          0.849098         0.001619  \n",
       "3            0.859848          0.862567         0.001874  \n",
       "4            0.865277          0.864805         0.001009  \n",
       "5            0.866810          0.866338         0.001243  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"max_samples\": [50,100,1000,5000,10000,15000]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_bag, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined a max_samples of 15000 was best.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
      "            splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=15000, n_estimators=7, n_jobs=1, oob_score=False,\n",
      "         random_state=123, verbose=0, warm_start=False)\n",
      "Bagging Accuracy Score 0.845883134130146\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.94      0.90     11360\n",
      "     > $50K       0.76      0.55      0.64      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10708   652]\n",
      " [ 1669  2031]]\n",
      "Confusion Matrix Percent\n",
      "[[71.10225764  4.32934927]\n",
      " [11.08233732 13.48605578]]\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier(base_estimator=(tree.DecisionTreeClassifier(max_depth=9,random_state=123)),n_estimators=7,max_samples=15000,random_state=123)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "print(\"Bagging Accuracy Score\", accuracy_score(target_test, predicted_bag))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_bag, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_bag))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_bag))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy decreased slightly to 84.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll cross validate the bagging classifier without the max_samples input since that decreased accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.84322174 0.85647995 0.85548558 0.84852502 0.85842175 0.85941645\n",
      " 0.85709549 0.8627321  0.85936982 0.85638474]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8557132640007807"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Bagging Classifier with Cross Validation\n",
    "clf_bag = BaggingClassifier(base_estimator=(tree.DecisionTreeClassifier(max_depth=9,random_state=123)),n_estimators=7,random_state=123)\n",
    "scores = cross_val_score(clf_bag, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the bagging classifier are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Gradient Boosting \n",
    "Now we'll run the gradient boosting classifier with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=123, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "Gradient Boost Accuracy Score 0.8578353253652058\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.94      0.91     11360\n",
      "     > $50K       0.77      0.59      0.67      3700\n",
      "\n",
      "avg / total       0.85      0.86      0.85     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10720   640]\n",
      " [ 1501  2199]]\n",
      "Confusion Matrix Percent\n",
      "[[71.18193891  4.24966799]\n",
      " [ 9.96679947 14.60159363]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier(random_state=123) \n",
    "clf_GBC.fit(features_train, target_train)\n",
    "print(clf_GBC)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "print(\"Gradient Boost Accuracy Score\", accuracy_score(target_test, predicted_GBC))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_GBC, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_GBC))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_GBC))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient Boost with default settings found an accuracy of 85.8%.  Let's try a grid search on the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 500}\n",
      "Best Score: 0.8698030634573304\n",
      "Best Estimator GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=123, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.372371</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.011949</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.852478</td>\n",
       "      <td>0.850157</td>\n",
       "      <td>0.856788</td>\n",
       "      <td>0.858256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855315</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>6</td>\n",
       "      <td>0.858718</td>\n",
       "      <td>0.859049</td>\n",
       "      <td>0.856811</td>\n",
       "      <td>0.857232</td>\n",
       "      <td>0.857652</td>\n",
       "      <td>0.857892</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.702408</td>\n",
       "      <td>0.132315</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.857782</td>\n",
       "      <td>0.857119</td>\n",
       "      <td>0.864247</td>\n",
       "      <td>0.866214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861979</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>5</td>\n",
       "      <td>0.867545</td>\n",
       "      <td>0.867794</td>\n",
       "      <td>0.866343</td>\n",
       "      <td>0.865935</td>\n",
       "      <td>0.865484</td>\n",
       "      <td>0.866620</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.153043</td>\n",
       "      <td>0.195295</td>\n",
       "      <td>0.031452</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>250</td>\n",
       "      <td>{'n_estimators': 250}</td>\n",
       "      <td>0.865407</td>\n",
       "      <td>0.860600</td>\n",
       "      <td>0.870380</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867416</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>4</td>\n",
       "      <td>0.878569</td>\n",
       "      <td>0.877865</td>\n",
       "      <td>0.877160</td>\n",
       "      <td>0.875964</td>\n",
       "      <td>0.877129</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.039151</td>\n",
       "      <td>1.087205</td>\n",
       "      <td>0.056887</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.871540</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869803</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887646</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.885490</td>\n",
       "      <td>0.885661</td>\n",
       "      <td>0.885251</td>\n",
       "      <td>0.886239</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.856477</td>\n",
       "      <td>0.408240</td>\n",
       "      <td>0.074196</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>750</td>\n",
       "      <td>{'n_estimators': 750}</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.866236</td>\n",
       "      <td>0.871871</td>\n",
       "      <td>0.871187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869505</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>2</td>\n",
       "      <td>0.893448</td>\n",
       "      <td>0.894318</td>\n",
       "      <td>0.891749</td>\n",
       "      <td>0.891670</td>\n",
       "      <td>0.892048</td>\n",
       "      <td>0.892646</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43.524375</td>\n",
       "      <td>2.170845</td>\n",
       "      <td>0.085920</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'n_estimators': 1000}</td>\n",
       "      <td>0.863252</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.871374</td>\n",
       "      <td>0.871021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868344</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>3</td>\n",
       "      <td>0.899043</td>\n",
       "      <td>0.898877</td>\n",
       "      <td>0.898338</td>\n",
       "      <td>0.898425</td>\n",
       "      <td>0.898139</td>\n",
       "      <td>0.898564</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.372371      0.057325         0.011949        0.000915   \n",
       "1       5.702408      0.132315         0.018940        0.004088   \n",
       "2      13.153043      0.195295         0.031452        0.004680   \n",
       "3      25.039151      1.087205         0.056887        0.006140   \n",
       "4      33.856477      0.408240         0.074196        0.003372   \n",
       "5      43.524375      2.170845         0.085920        0.013461   \n",
       "\n",
       "  param_n_estimators                  params  split0_test_score  \\\n",
       "0                 50    {'n_estimators': 50}           0.852478   \n",
       "1                100   {'n_estimators': 100}           0.857782   \n",
       "2                250   {'n_estimators': 250}           0.865407   \n",
       "3                500   {'n_estimators': 500}           0.865738   \n",
       "4                750   {'n_estimators': 750}           0.865241   \n",
       "5               1000  {'n_estimators': 1000}           0.863252   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.850157           0.856788           0.858256       ...          \n",
       "1           0.857119           0.864247           0.866214       ...          \n",
       "2           0.860600           0.870380           0.870855       ...          \n",
       "3           0.866733           0.871540           0.870855       ...          \n",
       "4           0.866236           0.871871           0.871187       ...          \n",
       "5           0.866733           0.871374           0.871021       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.855315        0.003414                6            0.858718   \n",
       "1         0.861979        0.003764                5            0.867545   \n",
       "2         0.867416        0.003924                4            0.878569   \n",
       "3         0.869803        0.003129                1            0.887646   \n",
       "4         0.869505        0.003145                2            0.893448   \n",
       "5         0.868344        0.003029                3            0.899043   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.859049            0.856811            0.857232   \n",
       "1            0.867794            0.866343            0.865935   \n",
       "2            0.877865            0.877160            0.875964   \n",
       "3            0.887148            0.885490            0.885661   \n",
       "4            0.894318            0.891749            0.891670   \n",
       "5            0.898877            0.898338            0.898425   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.857652          0.857892         0.000858  \n",
       "1            0.865484          0.866620         0.000902  \n",
       "2            0.877129          0.877337         0.000867  \n",
       "3            0.885251          0.886239         0.000967  \n",
       "4            0.892048          0.892646         0.001054  \n",
       "5            0.898139          0.898564         0.000340  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [50,100,250,500,750,1000]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_GBC, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined the best number of estimators to be 500.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Accuracy Score 0.8565737051792829\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.94      0.91     11360\n",
      "     > $50K       0.76      0.61      0.68      3700\n",
      "\n",
      "avg / total       0.85      0.86      0.85     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10635   725]\n",
      " [ 1435  2265]]\n",
      "Confusion Matrix Percent\n",
      "[[70.61752988  4.81407703]\n",
      " [ 9.52855246 15.03984064]]\n"
     ]
    }
   ],
   "source": [
    "clf_GBC = GradientBoostingClassifier(random_state=123, n_estimators=500) \n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "print(\"Gradient Boost Accuracy Score\", accuracy_score(target_test, predicted_GBC))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_GBC, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_GBC))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_GBC))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is virtually unchanged.  Now let's do a grid search on the max depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 3}\n",
      "Best Score: 0.8698030634573304\n",
      "Best Estimator GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=123, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.771890</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.030634</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>0.852147</td>\n",
       "      <td>0.858445</td>\n",
       "      <td>0.861240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857238</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>6</td>\n",
       "      <td>0.859629</td>\n",
       "      <td>0.859712</td>\n",
       "      <td>0.858469</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.857611</td>\n",
       "      <td>0.858663</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.240651</td>\n",
       "      <td>0.195101</td>\n",
       "      <td>0.039350</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.862258</td>\n",
       "      <td>0.860103</td>\n",
       "      <td>0.868556</td>\n",
       "      <td>0.871353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866521</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873265</td>\n",
       "      <td>0.875503</td>\n",
       "      <td>0.874798</td>\n",
       "      <td>0.873021</td>\n",
       "      <td>0.873980</td>\n",
       "      <td>0.874113</td>\n",
       "      <td>0.000931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.006098</td>\n",
       "      <td>0.363155</td>\n",
       "      <td>0.054196</td>\n",
       "      <td>0.007927</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.871540</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869803</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887646</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.885490</td>\n",
       "      <td>0.885661</td>\n",
       "      <td>0.885251</td>\n",
       "      <td>0.886239</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.954880</td>\n",
       "      <td>0.709358</td>\n",
       "      <td>0.062958</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>0.866070</td>\n",
       "      <td>0.867562</td>\n",
       "      <td>0.872534</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869372</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>2</td>\n",
       "      <td>0.900825</td>\n",
       "      <td>0.901032</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.899544</td>\n",
       "      <td>0.898471</td>\n",
       "      <td>0.899857</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.751495</td>\n",
       "      <td>1.073335</td>\n",
       "      <td>0.081728</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>0.861926</td>\n",
       "      <td>0.865407</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.865882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864664</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>4</td>\n",
       "      <td>0.940901</td>\n",
       "      <td>0.940114</td>\n",
       "      <td>0.940860</td>\n",
       "      <td>0.942022</td>\n",
       "      <td>0.940699</td>\n",
       "      <td>0.940919</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97.226998</td>\n",
       "      <td>4.557043</td>\n",
       "      <td>0.088619</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>0.859274</td>\n",
       "      <td>0.862258</td>\n",
       "      <td>0.865904</td>\n",
       "      <td>0.866048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863371</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965809</td>\n",
       "      <td>0.967425</td>\n",
       "      <td>0.967052</td>\n",
       "      <td>0.967385</td>\n",
       "      <td>0.966267</td>\n",
       "      <td>0.966788</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       5.771890      0.033345         0.030634        0.004408   \n",
       "1      13.240651      0.195101         0.039350        0.001021   \n",
       "2      23.006098      0.363155         0.054196        0.007927   \n",
       "3      34.954880      0.709358         0.062958        0.000952   \n",
       "4      71.751495      1.073335         0.081728        0.003100   \n",
       "5      97.226998      4.557043         0.088619        0.007539   \n",
       "\n",
       "  param_max_depth            params  split0_test_score  split1_test_score  \\\n",
       "0               1  {'max_depth': 1}           0.852644           0.852147   \n",
       "1               2  {'max_depth': 2}           0.862258           0.860103   \n",
       "2               3  {'max_depth': 3}           0.865738           0.866733   \n",
       "3               4  {'max_depth': 4}           0.866070           0.867562   \n",
       "4               6  {'max_depth': 6}           0.861926           0.865407   \n",
       "5               7  {'max_depth': 7}           0.859274           0.862258   \n",
       "\n",
       "   split2_test_score  split3_test_score       ...         mean_test_score  \\\n",
       "0           0.858445           0.861240       ...                0.857238   \n",
       "1           0.868556           0.871353       ...                0.866521   \n",
       "2           0.871540           0.870855       ...                0.869803   \n",
       "3           0.872534           0.870855       ...                0.869372   \n",
       "4           0.866733           0.865882       ...                0.864664   \n",
       "5           0.865904           0.866048       ...                0.863371   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.004112                6            0.859629            0.859712   \n",
       "1        0.004504                3            0.873265            0.875503   \n",
       "2        0.003129                1            0.887646            0.887148   \n",
       "3        0.002307                2            0.900825            0.901032   \n",
       "4        0.001760                4            0.940901            0.940114   \n",
       "5        0.002514                5            0.965809            0.967425   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.858469            0.857895            0.857611   \n",
       "1            0.874798            0.873021            0.873980   \n",
       "2            0.885490            0.885661            0.885251   \n",
       "3            0.899416            0.899544            0.898471   \n",
       "4            0.940860            0.942022            0.940699   \n",
       "5            0.967052            0.967385            0.966267   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.858663         0.000868  \n",
       "1          0.874113         0.000931  \n",
       "2          0.886239         0.000967  \n",
       "3          0.899857         0.000952  \n",
       "4          0.940919         0.000619  \n",
       "5          0.966788         0.000642  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": [1,2,3,4,6,7]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_GBC, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined a max depth of 3 as optimal, which is the default setting.  Let's try a grid search on the learning rate to see the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'learning_rate': 0.15}\n",
      "Best Score: 0.869968834957894\n",
      "Best Estimator GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.15, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=123, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.286677</td>\n",
       "      <td>0.152505</td>\n",
       "      <td>0.065475</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'learning_rate': 0.001}</td>\n",
       "      <td>0.797447</td>\n",
       "      <td>0.794298</td>\n",
       "      <td>0.797282</td>\n",
       "      <td>0.797248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797228</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>7</td>\n",
       "      <td>0.797174</td>\n",
       "      <td>0.797961</td>\n",
       "      <td>0.797298</td>\n",
       "      <td>0.797348</td>\n",
       "      <td>0.796942</td>\n",
       "      <td>0.797344</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.080606</td>\n",
       "      <td>0.169734</td>\n",
       "      <td>0.063980</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01}</td>\n",
       "      <td>0.851981</td>\n",
       "      <td>0.849494</td>\n",
       "      <td>0.857451</td>\n",
       "      <td>0.858256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855016</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>6</td>\n",
       "      <td>0.858428</td>\n",
       "      <td>0.858966</td>\n",
       "      <td>0.857184</td>\n",
       "      <td>0.856734</td>\n",
       "      <td>0.856657</td>\n",
       "      <td>0.857594</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.152896</td>\n",
       "      <td>0.369478</td>\n",
       "      <td>0.049824</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>0.863915</td>\n",
       "      <td>0.861760</td>\n",
       "      <td>0.869551</td>\n",
       "      <td>0.870524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>5</td>\n",
       "      <td>0.877036</td>\n",
       "      <td>0.877367</td>\n",
       "      <td>0.876580</td>\n",
       "      <td>0.876254</td>\n",
       "      <td>0.876176</td>\n",
       "      <td>0.876683</td>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.293711</td>\n",
       "      <td>0.207067</td>\n",
       "      <td>0.050473</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.08</td>\n",
       "      <td>{'learning_rate': 0.08}</td>\n",
       "      <td>0.866236</td>\n",
       "      <td>0.865904</td>\n",
       "      <td>0.871374</td>\n",
       "      <td>0.871684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869637</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>3</td>\n",
       "      <td>0.883294</td>\n",
       "      <td>0.883999</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.882346</td>\n",
       "      <td>0.882558</td>\n",
       "      <td>0.882916</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.847318</td>\n",
       "      <td>0.252674</td>\n",
       "      <td>0.050394</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>0.865738</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.871540</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869803</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887646</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.885490</td>\n",
       "      <td>0.885661</td>\n",
       "      <td>0.885251</td>\n",
       "      <td>0.886239</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.245830</td>\n",
       "      <td>0.230250</td>\n",
       "      <td>0.050801</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.12</td>\n",
       "      <td>{'learning_rate': 0.12}</td>\n",
       "      <td>0.866236</td>\n",
       "      <td>0.865407</td>\n",
       "      <td>0.872203</td>\n",
       "      <td>0.873342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869637</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>3</td>\n",
       "      <td>0.889469</td>\n",
       "      <td>0.890174</td>\n",
       "      <td>0.889511</td>\n",
       "      <td>0.889308</td>\n",
       "      <td>0.888028</td>\n",
       "      <td>0.889298</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.500419</td>\n",
       "      <td>0.842472</td>\n",
       "      <td>0.042510</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'learning_rate': 0.15}</td>\n",
       "      <td>0.867230</td>\n",
       "      <td>0.866236</td>\n",
       "      <td>0.871706</td>\n",
       "      <td>0.872679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869969</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893945</td>\n",
       "      <td>0.895686</td>\n",
       "      <td>0.892536</td>\n",
       "      <td>0.893618</td>\n",
       "      <td>0.892794</td>\n",
       "      <td>0.893716</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      35.286677      0.152505         0.065475        0.001757   \n",
       "1      31.080606      0.169734         0.063980        0.007677   \n",
       "2      23.152896      0.369478         0.049824        0.000695   \n",
       "3      22.293711      0.207067         0.050473        0.002020   \n",
       "4      21.847318      0.252674         0.050394        0.003218   \n",
       "5      22.245830      0.230250         0.050801        0.004974   \n",
       "6      21.500419      0.842472         0.042510        0.004035   \n",
       "\n",
       "  param_learning_rate                    params  split0_test_score  \\\n",
       "0               0.001  {'learning_rate': 0.001}           0.797447   \n",
       "1                0.01   {'learning_rate': 0.01}           0.851981   \n",
       "2                0.05   {'learning_rate': 0.05}           0.863915   \n",
       "3                0.08   {'learning_rate': 0.08}           0.866236   \n",
       "4                 0.1    {'learning_rate': 0.1}           0.865738   \n",
       "5                0.12   {'learning_rate': 0.12}           0.866236   \n",
       "6                0.15   {'learning_rate': 0.15}           0.867230   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.794298           0.797282           0.797248       ...          \n",
       "1           0.849494           0.857451           0.858256       ...          \n",
       "2           0.861760           0.869551           0.870524       ...          \n",
       "3           0.865904           0.871374           0.871684       ...          \n",
       "4           0.866733           0.871540           0.870855       ...          \n",
       "5           0.865407           0.872203           0.873342       ...          \n",
       "6           0.866236           0.871706           0.872679       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.797228        0.001766                7            0.797174   \n",
       "1         0.855016        0.003590                6            0.858428   \n",
       "2         0.867250        0.003684                5            0.877036   \n",
       "3         0.869637        0.002965                3            0.883294   \n",
       "4         0.869803        0.003129                2            0.887646   \n",
       "5         0.869637        0.003214                3            0.889469   \n",
       "6         0.869969        0.002680                1            0.893945   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.797961            0.797298            0.797348   \n",
       "1            0.858966            0.857184            0.856734   \n",
       "2            0.877367            0.876580            0.876254   \n",
       "3            0.883999            0.882382            0.882346   \n",
       "4            0.887148            0.885490            0.885661   \n",
       "5            0.890174            0.889511            0.889308   \n",
       "6            0.895686            0.892536            0.893618   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.796942          0.797344         0.000339  \n",
       "1            0.856657          0.857594         0.000934  \n",
       "2            0.876176          0.876683         0.000457  \n",
       "3            0.882558          0.882916         0.000641  \n",
       "4            0.885251          0.886239         0.000967  \n",
       "5            0.888028          0.889298         0.000701  \n",
       "6            0.892794          0.893716         0.001112  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"learning_rate\": [0.001,0.01, 0.05, 0.08, 0.1, 0.12, 0.15]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf_GBC, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined a learning rate of 0.15 to be optimal.  Let's run the model with that figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Accuracy Score 0.8562416998671979\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.91     11360\n",
      "     > $50K       0.75      0.62      0.68      3700\n",
      "\n",
      "avg / total       0.85      0.86      0.85     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10606   754]\n",
      " [ 1411  2289]]\n",
      "Confusion Matrix Percent\n",
      "[[70.4249668   5.00664011]\n",
      " [ 9.36918991 15.19920319]]\n"
     ]
    }
   ],
   "source": [
    "clf_GBC = GradientBoostingClassifier(random_state=123, n_estimators=500, max_depth=3, learning_rate=0.15)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "print(\"Gradient Boost Accuracy Score\", accuracy_score(target_test, predicted_GBC))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_GBC, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_GBC))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_GBC))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performace is virtually unchanged."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we'll cross validate the gradient boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.8694067  0.86741796 0.8694067  0.86509778 0.86870027 0.87135279\n",
      " 0.8693634  0.87433687 0.87495854 0.86368159]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8693722583222072"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify GB with Cross Validation\n",
    "scores = cross_val_score(clf_GBC, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the gradient boost are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Extra Trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the extra trees classifier with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "Extra Trees Accuracy Score 0.8225099601593625\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.86      0.91      0.89     11360\n",
      "     > $50K       0.67      0.55      0.60      3700\n",
      "\n",
      "avg / total       0.81      0.82      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10341  1019]\n",
      " [ 1654  2046]]\n",
      "Confusion Matrix Percent\n",
      "[[68.66533865  6.76626826]\n",
      " [10.98273572 13.58565737]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xdt = ExtraTreesClassifier(random_state=123)\n",
    "xdt.fit(features_train, target_train)\n",
    "print(xdt)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "print(\"Extra Trees Accuracy Score\", accuracy_score(target_test, predicted_xdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_xdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_xdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_xdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy with default settings was 82.3%.  Let's do a grid search on the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 50}\n",
      "Best Score: 0.8347258139380678\n",
      "Best Estimator ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "           oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.237105</td>\n",
       "      <td>0.010313</td>\n",
       "      <td>0.018988</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "      <td>0.824797</td>\n",
       "      <td>0.815183</td>\n",
       "      <td>0.821482</td>\n",
       "      <td>0.821452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821796</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.412672</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.830267</td>\n",
       "      <td>0.825294</td>\n",
       "      <td>0.828112</td>\n",
       "      <td>0.835378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830847</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594261</td>\n",
       "      <td>0.013417</td>\n",
       "      <td>0.045402</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_estimators': 15}</td>\n",
       "      <td>0.831759</td>\n",
       "      <td>0.825957</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.835378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831013</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.846595</td>\n",
       "      <td>0.042281</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.831593</td>\n",
       "      <td>0.827615</td>\n",
       "      <td>0.831096</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832604</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.895301</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>0.135817</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.834908</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.831096</td>\n",
       "      <td>0.840186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.578789</td>\n",
       "      <td>0.195488</td>\n",
       "      <td>0.249742</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.835074</td>\n",
       "      <td>0.827449</td>\n",
       "      <td>0.833913</td>\n",
       "      <td>0.839191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834593</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.237105      0.010313         0.018988        0.001303   \n",
       "1       0.412672      0.015424         0.029004        0.000918   \n",
       "2       0.594261      0.013417         0.045402        0.003766   \n",
       "3       0.846595      0.042281         0.068195        0.010191   \n",
       "4       1.895301      0.037769         0.135817        0.003375   \n",
       "5       3.578789      0.195488         0.249742        0.013021   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                  5    {'n_estimators': 5}           0.824797   \n",
       "1                 10   {'n_estimators': 10}           0.830267   \n",
       "2                 15   {'n_estimators': 15}           0.831759   \n",
       "3                 20   {'n_estimators': 20}           0.831593   \n",
       "4                 50   {'n_estimators': 50}           0.834908   \n",
       "5                100  {'n_estimators': 100}           0.835074   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score       ...         \\\n",
       "0           0.815183           0.821482           0.821452       ...          \n",
       "1           0.825294           0.828112           0.835378       ...          \n",
       "2           0.825957           0.828941           0.835378       ...          \n",
       "3           0.827615           0.831096           0.836207       ...          \n",
       "4           0.828278           0.831096           0.840186       ...          \n",
       "5           0.827449           0.833913           0.839191       ...          \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.821796        0.003773                6                 1.0   \n",
       "1         0.830847        0.003950                5                 1.0   \n",
       "2         0.831013        0.003272                4                 1.0   \n",
       "3         0.832604        0.003360                3                 1.0   \n",
       "4         0.834726        0.004567                1                 1.0   \n",
       "5         0.834593        0.004011                2                 1.0   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.999959            0.999959                 1.0   \n",
       "1            0.999959            0.999959                 1.0   \n",
       "2            0.999959            0.999959                 1.0   \n",
       "3            0.999959            0.999959                 1.0   \n",
       "4            0.999959            0.999959                 1.0   \n",
       "5            0.999959            0.999959                 1.0   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.999959          0.999975          0.00002  \n",
       "1            0.999959          0.999975          0.00002  \n",
       "2            0.999959          0.999975          0.00002  \n",
       "3            0.999959          0.999975          0.00002  \n",
       "4            0.999959          0.999975          0.00002  \n",
       "5            0.999959          0.999975          0.00002  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [5,10,15,20,50,100]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xdt, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined that 50 was the best value for the number of estimators.  Let's run the model with that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Accuracy Score 0.8262284196547145\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.87      0.90      0.89     11360\n",
      "     > $50K       0.67      0.58      0.62      3700\n",
      "\n",
      "avg / total       0.82      0.83      0.82     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10280  1080]\n",
      " [ 1537  2163]]\n",
      "Confusion Matrix Percent\n",
      "[[68.26029216  7.17131474]\n",
      " [10.20584329 14.3625498 ]]\n"
     ]
    }
   ],
   "source": [
    "xdt = ExtraTreesClassifier(random_state=123, n_estimators=50)\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "print(\"Extra Trees Accuracy Score\", accuracy_score(target_test, predicted_xdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_xdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_xdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_xdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved slightly from 82.3% to 82.6%.  Now let's run a grid search on the depth of the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 25}\n",
      "Best Score: 0.8473244479809031\n",
      "Best Estimator ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "           oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.429977</td>\n",
       "      <td>0.017994</td>\n",
       "      <td>0.031691</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.806730</td>\n",
       "      <td>0.802420</td>\n",
       "      <td>0.805072</td>\n",
       "      <td>0.811008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806512</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>8</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.803556</td>\n",
       "      <td>0.807493</td>\n",
       "      <td>0.811231</td>\n",
       "      <td>0.804069</td>\n",
       "      <td>0.807017</td>\n",
       "      <td>0.002885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.712067</td>\n",
       "      <td>0.017741</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>0.824797</td>\n",
       "      <td>0.823471</td>\n",
       "      <td>0.829272</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826106</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>7</td>\n",
       "      <td>0.829873</td>\n",
       "      <td>0.835012</td>\n",
       "      <td>0.834722</td>\n",
       "      <td>0.832781</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.832587</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.055942</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 15}</td>\n",
       "      <td>0.840709</td>\n",
       "      <td>0.834908</td>\n",
       "      <td>0.840709</td>\n",
       "      <td>0.842507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839135</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>5</td>\n",
       "      <td>0.864810</td>\n",
       "      <td>0.864561</td>\n",
       "      <td>0.865142</td>\n",
       "      <td>0.865396</td>\n",
       "      <td>0.864282</td>\n",
       "      <td>0.864838</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.256748</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.075388</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>0.838389</td>\n",
       "      <td>0.847671</td>\n",
       "      <td>0.849967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845269</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>3</td>\n",
       "      <td>0.899126</td>\n",
       "      <td>0.899084</td>\n",
       "      <td>0.897385</td>\n",
       "      <td>0.900746</td>\n",
       "      <td>0.899963</td>\n",
       "      <td>0.899261</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.540372</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>0.090206</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 25}</td>\n",
       "      <td>0.848003</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.849329</td>\n",
       "      <td>0.852619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847324</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932322</td>\n",
       "      <td>0.931120</td>\n",
       "      <td>0.929545</td>\n",
       "      <td>0.931745</td>\n",
       "      <td>0.928971</td>\n",
       "      <td>0.930741</td>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.627664</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.110447</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 30}</td>\n",
       "      <td>0.846677</td>\n",
       "      <td>0.842864</td>\n",
       "      <td>0.845682</td>\n",
       "      <td>0.850962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846761</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>2</td>\n",
       "      <td>0.960504</td>\n",
       "      <td>0.964400</td>\n",
       "      <td>0.962825</td>\n",
       "      <td>0.961998</td>\n",
       "      <td>0.964527</td>\n",
       "      <td>0.962851</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.723523</td>\n",
       "      <td>0.028280</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>35</td>\n",
       "      <td>{'max_depth': 35}</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.839549</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843445</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983754</td>\n",
       "      <td>0.984086</td>\n",
       "      <td>0.983049</td>\n",
       "      <td>0.979072</td>\n",
       "      <td>0.981476</td>\n",
       "      <td>0.982287</td>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.837337</td>\n",
       "      <td>0.064417</td>\n",
       "      <td>0.130883</td>\n",
       "      <td>0.008426</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 50}</td>\n",
       "      <td>0.833250</td>\n",
       "      <td>0.831759</td>\n",
       "      <td>0.837229</td>\n",
       "      <td>0.840020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835488</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.429977      0.017994         0.031691        0.002764   \n",
       "1       0.712067      0.017741         0.042182        0.001235   \n",
       "2       0.999986      0.006241         0.055942        0.001806   \n",
       "3       1.256748      0.008723         0.075388        0.007428   \n",
       "4       1.540372      0.051432         0.090206        0.007833   \n",
       "5       1.627664      0.020736         0.110447        0.004450   \n",
       "6       1.723523      0.028280         0.120700        0.002844   \n",
       "7       1.837337      0.064417         0.130883        0.008426   \n",
       "\n",
       "  param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0               5   {'max_depth': 5}           0.806730           0.802420   \n",
       "1              10  {'max_depth': 10}           0.824797           0.823471   \n",
       "2              15  {'max_depth': 15}           0.840709           0.834908   \n",
       "3              20  {'max_depth': 20}           0.844688           0.838389   \n",
       "4              25  {'max_depth': 25}           0.848003           0.841372   \n",
       "5              30  {'max_depth': 30}           0.846677           0.842864   \n",
       "6              35  {'max_depth': 35}           0.841372           0.839549   \n",
       "7              50  {'max_depth': 50}           0.833250           0.831759   \n",
       "\n",
       "   split2_test_score  split3_test_score       ...         mean_test_score  \\\n",
       "0           0.805072           0.811008       ...                0.806512   \n",
       "1           0.829272           0.829907       ...                0.826106   \n",
       "2           0.840709           0.842507       ...                0.839135   \n",
       "3           0.847671           0.849967       ...                0.845269   \n",
       "4           0.849329           0.852619       ...                0.847324   \n",
       "5           0.845682           0.850962       ...                0.846761   \n",
       "6           0.841372           0.849138       ...                0.843445   \n",
       "7           0.837229           0.840020       ...                0.835488   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.002819                8            0.808736            0.803556   \n",
       "1        0.002908                7            0.829873            0.835012   \n",
       "2        0.002809                5            0.864810            0.864561   \n",
       "3        0.003890                3            0.899126            0.899084   \n",
       "4        0.003796                1            0.932322            0.931120   \n",
       "5        0.002636                2            0.960504            0.964400   \n",
       "6        0.003513                4            0.983754            0.984086   \n",
       "7        0.002918                6            1.000000            0.999959   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.807493            0.811231            0.804069   \n",
       "1            0.834722            0.832781            0.830550   \n",
       "2            0.865142            0.865396            0.864282   \n",
       "3            0.897385            0.900746            0.899963   \n",
       "4            0.929545            0.931745            0.928971   \n",
       "5            0.962825            0.961998            0.964527   \n",
       "6            0.983049            0.979072            0.981476   \n",
       "7            0.999959            1.000000            0.999959   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.807017         0.002885  \n",
       "1          0.832587         0.002097  \n",
       "2          0.864838         0.000397  \n",
       "3          0.899261         0.001120  \n",
       "4          0.930741         0.001282  \n",
       "5          0.962851         0.001513  \n",
       "6          0.982287         0.001842  \n",
       "7          0.999975         0.000020  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": [5,10,15,20,25,30,35,50]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(xdt, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Best Params:\", grid_search.best_params_) \n",
    "print(\"Best Score:\", grid_search.best_score_) \n",
    "print(\"Best Estimator\", grid_search.best_estimator_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search determined 25 to be the best depth.  Let's run the model with that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Accuracy Score 0.8460823373173971\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    <= $50K       0.88      0.93      0.90     11360\n",
      "     > $50K       0.73      0.60      0.66      3700\n",
      "\n",
      "avg / total       0.84      0.85      0.84     15060\n",
      "\n",
      "Confusion Matrix\n",
      "[[10539   821]\n",
      " [ 1497  2203]]\n",
      "Confusion Matrix Percent\n",
      "[[69.98007968  5.45152722]\n",
      " [ 9.94023904 14.62815405]]\n"
     ]
    }
   ],
   "source": [
    "xdt = ExtraTreesClassifier(random_state=123, n_estimators=50, max_depth=25) #max_depth=3,n_estimators=10,class_weight='balanced')\n",
    "xdt.fit(features_train, target_train)\n",
    "predicted_xdt=xdt.predict(features_test)\n",
    "print(\"Extra Trees Accuracy Score\", accuracy_score(target_test, predicted_xdt))\n",
    "target_names = [\"<= $50K\", \"> $50K\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(target_test, predicted_xdt, target_names=target_names))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(target_test, predicted_xdt))\n",
    "print(\"Confusion Matrix Percent\")\n",
    "print(100*(confusion_matrix(target_test, predicted_xdt))/len(target_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved to 84.6%.  Now we'll cross validate the extra trees classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.84255883 0.85117667 0.84885648 0.83858137 0.84748011 0.84383289\n",
      " 0.85079576 0.85046419 0.85174129 0.84212272]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8467610308575019"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify XDT with Cross Validation\n",
    "\n",
    "scores = cross_val_score(xdt, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the extra trees classifier are fairly close together, suggesting this model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll stack 3 different models to see the result.  For the first stack we'll use KNN, Random Forest, and Extra Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.83 (+/- 0.00) [K Nearest Neighbor]\n",
      "Accuracy: 0.85 (+/- 0.00) [Extra Trees]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.00) [Ensemble]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "stack_xdt = ExtraTreesClassifier(random_state=123, n_estimators=50, max_depth=25)\n",
    "stack_knn = KNeighborsClassifier(n_neighbors=20, p=2)\n",
    "stack_rf = RandomForestClassifier(n_estimators= 100, random_state=123)\n",
    "stack1 = VotingClassifier(estimators=[('rf', stack_rf), ('knn', stack_knn), ('xdt', stack_xdt)], voting='soft')\n",
    "for MV, label in zip([stack_rf, stack_knn, stack_xdt, stack1], ['Random Forest', 'K Nearest Neighbor', 'Extra Trees', 'Ensemble']):\n",
    "\n",
    "    scores2 = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble performed at 85%, or the same as the random forest and the extra trees, so the boost in performance wasn't noticeable.  Perhaps these three models are classifying most of the same instances incorrectly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a different stack with these three models: bagging, neural net, and SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.00) [Neural Net]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84 (+/- 0.00) [Stochiastic Gradient Descent]\n",
      "Accuracy: 0.86 (+/- 0.00) [Bagging]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 (+/- 0.00) [Ensemble]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "stack_bag = BaggingClassifier(base_estimator=(tree.DecisionTreeClassifier(max_depth=9,random_state=123)),n_estimators=7,random_state=123)\n",
    "stack_sgd = linear_model.SGDClassifier(alpha=0.001, penalty='l1', loss='log', random_state=123)\n",
    "stack_nn = MLPClassifier(alpha=0.01, hidden_layer_sizes=(100, ), random_state=123)\n",
    "stack2 = VotingClassifier(estimators=[('nn', stack_nn), ('sgd', stack_sgd), ('bag', stack_bag)], voting='soft')\n",
    "for MV, label in zip([stack_nn, stack_sgd, stack_bag, stack2], ['Neural Net', 'Stochiastic Gradient Descent', 'Bagging', 'Ensemble']):\n",
    "\n",
    "    scores2 = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the ensemble model was the same as the highest rated model input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a different stack with linear SVC, Decision Tree, and Gradient Boosting for the three input models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.00) [Linear SVC]\n",
      "Accuracy: 0.85 (+/- 0.00) [Decision Tree]\n",
      "Accuracy: 0.87 (+/- 0.00) [Gradient Boosting]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86 (+/- 0.00) [Ensemble]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "\n",
    "stack_dt = tree.DecisionTreeClassifier(max_depth=9,random_state=123)\n",
    "stack_svml = SVC(C=10, kernel='linear', degree=3, probability=True, random_state=123)\n",
    "stack_gb = GradientBoostingClassifier(random_state=123, n_estimators=500, max_depth=3, learning_rate=0.15)\n",
    "stack3 = VotingClassifier(estimators=[('svml', stack_svml), ('dt', stack_dt), ('gb', stack_gb)], voting='soft')\n",
    "for MV, label in zip([stack_svml, stack_dt, stack_gb, stack3], ['Linear SVC', 'Decision Tree', 'Gradient Boosting', 'Ensemble']):\n",
    "\n",
    "    scores2 = cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the ensemble resulted in an accuracy of 0.86, and was actually less accurate than the Gradient Boost.  Next is some code to make predictions on the final stack that will be used to compare with other models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "stack3.fit(features_train, target_train)\n",
    "predicted_stack3=stack3.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross validate the final stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.85747431 0.86609214 0.8664236  0.85780577 0.86604775 0.86737401\n",
      " 0.86339523 0.86969496 0.86865672 0.86268657]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8645651043587506"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify stack with Cross Validation\n",
    "scores = cross_val_score(stack3, features_train, target_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation scores for the stack are fairly close together, suggesting this ensemble isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of these models, we'll take a look at some different metrics.  First, we'll calculate the area under the ROC curves and plot them (I was unable to do so for the stack):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate area under ROC curves\n",
    "fpr_knn, tpr_knn, _ = roc_curve(target_test, knn.predict_proba(features_test)[:,1])\n",
    "fpr_dt, tpr_dt, _ = roc_curve(target_test, clf.predict_proba(features_test)[:,1]) \n",
    "fpr_rf, tpr_rf, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "fpr_lsvc, tpr_lsvc, _ = roc_curve(target_test, linsvm.predict_proba(features_test)[:,1]) \n",
    "fpr_rbf, tpr_rbf, _ = roc_curve(target_test, clf_rbf.predict_proba(features_test)[:,1]) \n",
    "fpr_nn, tpr_nn, _ = roc_curve(target_test, clf_NN.predict_proba(features_test)[:,1]) \n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(target_test, clf_sgd.predict_proba(features_test)[:,1]) \n",
    "fpr_bdt, tpr_bdt, _ = roc_curve(target_test, bdt.predict_proba(features_test)[:,1]) \n",
    "fpr_bag, tpr_bag, _ = roc_curve(target_test, clf_bag.predict_proba(features_test)[:,1]) \n",
    "fpr_gbc, tpr_gbc, _ = roc_curve(target_test, clf_GBC.predict_proba(features_test)[:,1]) \n",
    "fpr_xdt, tpr_xdt, _ = roc_curve(target_test, xdt.predict_proba(features_test)[:,1]) \n",
    "fpr_stack, tpr_stack, _ = roc_curve(target_test, stack3.predict_proba(features_test)[:,1]) \n",
    "\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "roc_auc_lsvc = auc(fpr_lsvc, tpr_lsvc) \n",
    "roc_auc_rbf = auc(fpr_rbf, tpr_rbf)\n",
    "roc_auc_nn = auc(fpr_nn, tpr_nn)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) \n",
    "roc_auc_bdt = auc(fpr_bdt, tpr_bdt)\n",
    "roc_auc_bag = auc(fpr_bag, tpr_bag)\n",
    "roc_auc_gbc = auc(fpr_gbc, tpr_gbc)\n",
    "roc_auc_xdt = auc(fpr_xdt, tpr_xdt)\n",
    "#roc_auc_stac = auc(fpr_stack, tpr_stack)\n",
    "\n",
    "roc_auc_all =  {'ROC AUC':  [roc_auc_knn,\n",
    "    roc_auc_dt,\n",
    "    roc_auc_rf,\n",
    "    roc_auc_lsvc,\n",
    "    roc_auc_rbf,\n",
    "    roc_auc_nn,\n",
    "    roc_auc_sgd, \n",
    "    roc_auc_bdt,\n",
    "    roc_auc_bag,\n",
    "    roc_auc_gbc,\n",
    "    roc_auc_xdt\n",
    "    #roc_auc_stac\n",
    "]}\n",
    "    \n",
    "#roc_auc_all    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "\n",
    "#plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN (area = %0.3f)' % roc_auc_knn)\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree (area = %0.3f)' % roc_auc_dt)\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (area = %0.3f)' % roc_auc_rf)\n",
    "plt.plot(fpr_lsvc, tpr_lsvc, label='SVM Linear (area = %0.3f)' % roc_auc_lsvc)\n",
    "plt.plot(fpr_rbf, tpr_rbf, label='SVM RBF (area = %0.3f)' % roc_auc_rbf)\n",
    "plt.plot(fpr_nn, tpr_nn, label='ANN (area = %0.3f)' % roc_auc_nn)\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD (area = %0.3f)' % roc_auc_sgd)\n",
    "plt.plot(fpr_bdt, tpr_bdt, label='Adaboost (area = %0.3f)' % roc_auc_bdt)\n",
    "plt.plot(fpr_bag, tpr_bag, label='Bagging (area = %0.3f)' % roc_auc_bag)\n",
    "plt.plot(fpr_gbc, tpr_gbc, label='Gradient Boosting (area = %0.3f)' % roc_auc_gbc)\n",
    "plt.plot(fpr_xdt, tpr_xdt, label='Extra Trees (area = %0.3f)' % roc_auc_xdt)\n",
    "#plt.plot(fpr_stack, tpr_stack, label='Stacking (area = %0.3f)' % roc_auc_stack)\n",
    "\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curves are quite close together (except for the AdaBoost, which is noticeably below) but it appears Gradient Boosting is the best one.  Let's look at accuracy, precision, recall, ROC AUC, and F1 score for each of the models as tweaked for best perfomance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.830943</td>\n",
       "      <td>0.695064</td>\n",
       "      <td>0.555676</td>\n",
       "      <td>0.617603</td>\n",
       "      <td>0.876791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.841965</td>\n",
       "      <td>0.697250</td>\n",
       "      <td>0.630541</td>\n",
       "      <td>0.662220</td>\n",
       "      <td>0.883526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.844090</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.603243</td>\n",
       "      <td>0.655314</td>\n",
       "      <td>0.895084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Linear</th>\n",
       "      <td>0.847875</td>\n",
       "      <td>0.727920</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.662642</td>\n",
       "      <td>0.900654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM RBF</th>\n",
       "      <td>0.842762</td>\n",
       "      <td>0.725763</td>\n",
       "      <td>0.578649</td>\n",
       "      <td>0.643910</td>\n",
       "      <td>0.896814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANN</th>\n",
       "      <td>0.849070</td>\n",
       "      <td>0.740641</td>\n",
       "      <td>0.593514</td>\n",
       "      <td>0.658965</td>\n",
       "      <td>0.906096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.840239</td>\n",
       "      <td>0.735102</td>\n",
       "      <td>0.546757</td>\n",
       "      <td>0.627092</td>\n",
       "      <td>0.893962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>0.811155</td>\n",
       "      <td>0.629933</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.593366</td>\n",
       "      <td>0.837436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.848274</td>\n",
       "      <td>0.762913</td>\n",
       "      <td>0.554865</td>\n",
       "      <td>0.642466</td>\n",
       "      <td>0.897686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.856242</td>\n",
       "      <td>0.752218</td>\n",
       "      <td>0.618649</td>\n",
       "      <td>0.678926</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Trees</th>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.728505</td>\n",
       "      <td>0.595405</td>\n",
       "      <td>0.655265</td>\n",
       "      <td>0.897817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking</th>\n",
       "      <td>0.860691</td>\n",
       "      <td>0.779289</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>0.680572</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
       "Model                                                               \n",
       "KNN                0.830943   0.695064  0.555676  0.617603  0.876791\n",
       "Decision Tree      0.841965   0.697250  0.630541  0.662220  0.883526\n",
       "Random Forest      0.844090   0.717224  0.603243  0.655314  0.895084\n",
       "SVM Linear         0.847875   0.727920  0.608108  0.662642  0.900654\n",
       "SVM RBF            0.842762   0.725763  0.578649  0.643910  0.896814\n",
       "ANN                0.849070   0.740641  0.593514  0.658965  0.906096\n",
       "SGD                0.840239   0.735102  0.546757  0.627092  0.893962\n",
       "Adaboost           0.811155   0.629933  0.560811  0.593366  0.837436\n",
       "Bagging            0.848274   0.762913  0.554865  0.642466  0.897686\n",
       "Gradient Boosting  0.856242   0.752218  0.618649  0.678926  0.910663\n",
       "Extra Trees        0.846082   0.728505  0.595405  0.655265  0.897817\n",
       "Stacking           0.860691   0.779289  0.604054  0.680572       N/A"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data = {'Model': ['KNN',\n",
    "                          'Decision Tree',\n",
    "                          'Random Forest',\n",
    "                          'SVM Linear',\n",
    "                          'SVM RBF',\n",
    "                          'ANN',\n",
    "                          'SGD',\n",
    "                          'Adaboost',\n",
    "                          'Bagging',\n",
    "                          'Gradient Boosting',\n",
    "                          'Extra Trees',\n",
    "                          'Stacking'],\n",
    "    'Accuracy': [accuracy_score(target_test, target_predicted_knn), \n",
    "                 accuracy_score(target_test, target_predicted_dt),\n",
    "                 accuracy_score(target_test, target_predicted_rf),\n",
    "                 accuracy_score(target_test, predicted_linsvm),\n",
    "                 accuracy_score(target_test, predicted_rbf),\n",
    "                 accuracy_score(target_test, predicted_NN),\n",
    "                 accuracy_score(target_test, predicted_sgd),\n",
    "                 accuracy_score(target_test, predicted_bdt),\n",
    "                 accuracy_score(target_test, predicted_bag),\n",
    "                 accuracy_score(target_test, predicted_GBC),\n",
    "                 accuracy_score(target_test, predicted_xdt),\n",
    "                 accuracy_score(target_test, predicted_stack3)], \n",
    "    'Precision': [precision_score(target_test, target_predicted_knn),\n",
    "                  precision_score(target_test, target_predicted_dt),\n",
    "                  precision_score(target_test, target_predicted_rf),\n",
    "                  precision_score(target_test, predicted_linsvm),\n",
    "                  precision_score(target_test, predicted_rbf),\n",
    "                  precision_score(target_test, predicted_NN),\n",
    "                  precision_score(target_test, predicted_sgd),\n",
    "                  precision_score(target_test, predicted_bdt),\n",
    "                  precision_score(target_test, predicted_bag),\n",
    "                  precision_score(target_test, predicted_GBC),\n",
    "                  precision_score(target_test, predicted_xdt),\n",
    "                  precision_score(target_test, predicted_stack3)], \n",
    "        'Recall': [recall_score(target_test, target_predicted_knn), \n",
    "                   recall_score(target_test, target_predicted_dt),\n",
    "                   recall_score(target_test, target_predicted_rf),\n",
    "                   recall_score(target_test, predicted_linsvm),\n",
    "                   recall_score(target_test, predicted_rbf),\n",
    "                   recall_score(target_test, predicted_NN),\n",
    "                   recall_score(target_test, predicted_sgd),\n",
    "                   recall_score(target_test, predicted_bdt),\n",
    "                   recall_score(target_test, predicted_bag),\n",
    "                   recall_score(target_test, predicted_GBC),\n",
    "                   recall_score(target_test, predicted_xdt),\n",
    "                   recall_score(target_test, predicted_stack3)], \n",
    "     'F1 Score': [f1_score(target_test, target_predicted_knn), \n",
    "                  f1_score(target_test, target_predicted_dt),\n",
    "                  f1_score(target_test, target_predicted_rf),\n",
    "                  f1_score(target_test, predicted_linsvm),\n",
    "                  f1_score(target_test, predicted_rbf),\n",
    "                  f1_score(target_test, predicted_NN),\n",
    "                  f1_score(target_test, predicted_sgd),\n",
    "                  f1_score(target_test, predicted_bdt),\n",
    "                  f1_score(target_test, predicted_bag),\n",
    "                  f1_score(target_test, predicted_GBC),\n",
    "                  f1_score(target_test, predicted_xdt),\n",
    "                  f1_score(target_test, predicted_stack3)],\n",
    "               'ROC AUC':  [roc_auc_knn,\n",
    "                            roc_auc_dt,\n",
    "                            roc_auc_rf,\n",
    "                            roc_auc_lsvc,\n",
    "                            roc_auc_rbf,\n",
    "                            roc_auc_nn,\n",
    "                            roc_auc_sgd, \n",
    "                            roc_auc_bdt,\n",
    "                            roc_auc_bag,\n",
    "                            roc_auc_gbc,\n",
    "                            roc_auc_xdt, 'N/A']}\n",
    "            #                roc_auc_stack]}\n",
    "\n",
    "model_metrics = pd.DataFrame(data=metrics_data)\n",
    "model_metrics = model_metrics.set_index('Model')\n",
    "pd.options.display.max_rows = 12\n",
    "model_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models overall had very similiar performance with no one model a clear standout from the others.  Though incomes greater than 50,000 were the target variable, it wasn't clear from the problem statement whether that was truly more important than predicting incomes under 50,000.  Overall accuracies were within a few percentage points of each other.  Precision and recall show more variation, with precision varying between 62.9% and 77.9% and recall varying between 54.7% and 63.1%.   If overall accuracy is desired, gradient boost and stacking have a slight edge over the others.  If precision is most important (that is, the smallest number of false positives compared to the true positives), stacking is best, followed closely by bagging.  If recall is desired (that is, minimize false negatives compared to the true positives) than decision tree is best, followed by gradient boosting.  Stacking and gradient boost had the best F1 scores.  Gradient boosting had the best AUC.  Per previous results, none of the cross validation results showed overfitting.\n",
    "\n",
    "On the whole, it appears that the third stack is the best model, followed by gradient boosting. It's not surprising that the gradient boost is part of the best performing (third) stack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
