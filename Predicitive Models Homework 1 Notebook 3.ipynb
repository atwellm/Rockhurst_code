{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atwell - Homework 1 Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Packages, Setup, and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection  import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score, explained_variance_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Check working directory and change if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mlatw\\\\Desktop\\\\BIA6303\\\\Assignment_1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlatw\\Desktop\\BIA6303\\Assignment_1\n"
     ]
    }
   ],
   "source": [
    "cd /Users/mlatw/Desktop/BIA6303/Assignment_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the community crime data set and displaying some basic information about it. The list of column datatypes is long, but necessary to see what obstacles we face before conducting data mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type state                      int64\n",
      "county                   float64\n",
      "community                float64\n",
      "communityname             object\n",
      "fold                       int64\n",
      "population               float64\n",
      "householdsize            float64\n",
      "racepctblack             float64\n",
      "racePctWhite             float64\n",
      "racePctAsian             float64\n",
      "racePctHisp              float64\n",
      "agePct12t21              float64\n",
      "agePct12t29              float64\n",
      "agePct16t24              float64\n",
      "agePct65up               float64\n",
      "numbUrban                float64\n",
      "pctUrban                 float64\n",
      "medIncome                float64\n",
      "pctWWage                 float64\n",
      "pctWFarmSelf             float64\n",
      "pctWInvInc               float64\n",
      "pctWSocSec               float64\n",
      "pctWPubAsst              float64\n",
      "pctWRetire               float64\n",
      "medFamInc                float64\n",
      "perCapInc                float64\n",
      "whitePerCap              float64\n",
      "blackPerCap              float64\n",
      "indianPerCap             float64\n",
      "AsianPerCap              float64\n",
      "OtherPerCap              float64\n",
      "HispPerCap               float64\n",
      "NumUnderPov              float64\n",
      "PctPopUnderPov           float64\n",
      "PctLess9thGrade          float64\n",
      "PctNotHSGrad             float64\n",
      "PctBSorMore              float64\n",
      "PctUnemployed            float64\n",
      "PctEmploy                float64\n",
      "PctEmplManu              float64\n",
      "PctEmplProfServ          float64\n",
      "PctOccupManu             float64\n",
      "PctOccupMgmtProf         float64\n",
      "MalePctDivorce           float64\n",
      "MalePctNevMarr           float64\n",
      "FemalePctDiv             float64\n",
      "TotalPctDiv              float64\n",
      "PersPerFam               float64\n",
      "PctFam2Par               float64\n",
      "PctKids2Par              float64\n",
      "PctYoungKids2Par         float64\n",
      "PctTeen2Par              float64\n",
      "PctWorkMomYoungKids      float64\n",
      "PctWorkMom               float64\n",
      "NumIlleg                 float64\n",
      "PctIlleg                 float64\n",
      "NumImmig                 float64\n",
      "PctImmigRecent           float64\n",
      "PctImmigRec5             float64\n",
      "PctImmigRec8             float64\n",
      "PctImmigRec10            float64\n",
      "PctRecentImmig           float64\n",
      "PctRecImmig5             float64\n",
      "PctRecImmig8             float64\n",
      "PctRecImmig10            float64\n",
      "PctSpeakEnglOnly         float64\n",
      "PctNotSpeakEnglWell      float64\n",
      "PctLargHouseFam          float64\n",
      "PctLargHouseOccup        float64\n",
      "PersPerOccupHous         float64\n",
      "PersPerOwnOccHous        float64\n",
      "PersPerRentOccHous       float64\n",
      "PctPersOwnOccup          float64\n",
      "PctPersDenseHous         float64\n",
      "PctHousLess3BR           float64\n",
      "MedNumBR                 float64\n",
      "HousVacant               float64\n",
      "PctHousOccup             float64\n",
      "PctHousOwnOcc            float64\n",
      "PctVacantBoarded         float64\n",
      "PctVacMore6Mos           float64\n",
      "MedYrHousBuilt           float64\n",
      "PctHousNoPhone           float64\n",
      "PctWOFullPlumb           float64\n",
      "OwnOccLowQuart           float64\n",
      "OwnOccMedVal             float64\n",
      "OwnOccHiQuart            float64\n",
      "RentLowQ                 float64\n",
      "RentMedian               float64\n",
      "RentHighQ                float64\n",
      "MedRent                  float64\n",
      "MedRentPctHousInc        float64\n",
      "MedOwnCostPctInc         float64\n",
      "MedOwnCostPctIncNoMtg    float64\n",
      "NumInShelters            float64\n",
      "NumStreet                float64\n",
      "PctForeignBorn           float64\n",
      "PctBornSameState         float64\n",
      "PctSameHouse85           float64\n",
      "PctSameCity85            float64\n",
      "PctSameState85           float64\n",
      "LemasSwornFT             float64\n",
      "LemasSwFTPerPop          float64\n",
      "LemasSwFTFieldOps        float64\n",
      "LemasSwFTFieldPerPop     float64\n",
      "LemasTotalReq            float64\n",
      "LemasTotReqPerPop        float64\n",
      "PolicReqPerOffic         float64\n",
      "PolicPerPop              float64\n",
      "RacialMatchCommPol       float64\n",
      "PctPolicWhite            float64\n",
      "PctPolicBlack            float64\n",
      "PctPolicHisp             float64\n",
      "PctPolicAsian            float64\n",
      "PctPolicMinor            float64\n",
      "OfficAssgnDrugUnits      float64\n",
      "NumKindsDrugsSeiz        float64\n",
      "PolicAveOTWorked         float64\n",
      "LandArea                 float64\n",
      "PopDens                  float64\n",
      "PctUsePubTrans           float64\n",
      "PolicCars                float64\n",
      "PolicOperBudg            float64\n",
      "LemasPctPolicOnPatr      float64\n",
      "LemasGangUnitDeploy      float64\n",
      "LemasPctOfficDrugUn      float64\n",
      "PolicBudgPerPop          float64\n",
      "ViolentCrimesPerPop      float64\n",
      "dtype: object\n",
      "Shape of Data (1993, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81440.0</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SouthPasadenacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  county  community        communityname  fold  population  \\\n",
       "0     53     NaN        NaN          Tukwilacity     1        0.00   \n",
       "1     24     NaN        NaN         Aberdeentown     1        0.00   \n",
       "2     34     5.0    81440.0  Willingborotownship     1        0.04   \n",
       "3     42    95.0     6096.0    Bethlehemtownship     1        0.01   \n",
       "4      6     NaN        NaN    SouthPasadenacity     1        0.02   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0           0.16          0.12          0.74          0.45   \n",
       "1           0.42          0.49          0.56          0.17   \n",
       "2           0.77          1.00          0.08          0.12   \n",
       "3           0.55          0.02          0.95          0.09   \n",
       "4           0.28          0.06          0.54          1.00   \n",
       "\n",
       "          ...           LandArea  PopDens  PctUsePubTrans  PolicCars  \\\n",
       "0         ...               0.02     0.12            0.45        NaN   \n",
       "1         ...               0.01     0.21            0.02        NaN   \n",
       "2         ...               0.02     0.39            0.28        NaN   \n",
       "3         ...               0.04     0.09            0.02        NaN   \n",
       "4         ...               0.01     0.58            0.10        NaN   \n",
       "\n",
       "   PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "0            NaN                  NaN                  NaN   \n",
       "1            NaN                  NaN                  NaN   \n",
       "2            NaN                  NaN                  NaN   \n",
       "3            NaN                  NaN                  NaN   \n",
       "4            NaN                  NaN                  NaN   \n",
       "\n",
       "   LemasPctOfficDrugUn  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "0                  0.0              NaN                 0.67  \n",
       "1                  0.0              NaN                 0.43  \n",
       "2                  0.0              NaN                 0.12  \n",
       "3                  0.0              NaN                 0.03  \n",
       "4                  0.0              NaN                 0.14  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 999 #added to display all rows (if needed, but output should be tweaked as required)\n",
    "url_data=\"https://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data\"\n",
    "comm_crime = pd.read_csv(url_data, na_values=\"?\") #NA values in this dataset are encoded with a ?\n",
    "comm_crime.columns = [#'crimepredict'\n",
    "'state','county','community','communityname','fold','population','householdsize','racepctblack','racePctWhite','racePctAsian','racePctHisp','agePct12t21','agePct12t29','agePct16t24','agePct65up','numbUrban','pctUrban','medIncome','pctWWage','pctWFarmSelf','pctWInvInc','pctWSocSec','pctWPubAsst','pctWRetire','medFamInc','perCapInc','whitePerCap','blackPerCap','indianPerCap','AsianPerCap','OtherPerCap','HispPerCap','NumUnderPov','PctPopUnderPov','PctLess9thGrade','PctNotHSGrad'\n",
    ",'PctBSorMore','PctUnemployed','PctEmploy','PctEmplManu','PctEmplProfServ','PctOccupManu','PctOccupMgmtProf','MalePctDivorce','MalePctNevMarr','FemalePctDiv','TotalPctDiv','PersPerFam','PctFam2Par','PctKids2Par','PctYoungKids2Par','PctTeen2Par','PctWorkMomYoungKids','PctWorkMom','NumIlleg','PctIlleg'\n",
    ",'NumImmig','PctImmigRecent','PctImmigRec5','PctImmigRec8','PctImmigRec10','PctRecentImmig','PctRecImmig5','PctRecImmig8','PctRecImmig10','PctSpeakEnglOnly'\n",
    ",'PctNotSpeakEnglWell','PctLargHouseFam','PctLargHouseOccup','PersPerOccupHous','PersPerOwnOccHous'\n",
    ",'PersPerRentOccHous','PctPersOwnOccup','PctPersDenseHous','PctHousLess3BR','MedNumBR','HousVacant','PctHousOccup','PctHousOwnOcc'\n",
    ",'PctVacantBoarded','PctVacMore6Mos','MedYrHousBuilt','PctHousNoPhone','PctWOFullPlumb','OwnOccLowQuart','OwnOccMedVal','OwnOccHiQuart','RentLowQ'\n",
    ",'RentMedian','RentHighQ','MedRent','MedRentPctHousInc','MedOwnCostPctInc','MedOwnCostPctIncNoMtg','NumInShelters','NumStreet','PctForeignBorn'\n",
    ",'PctBornSameState','PctSameHouse85','PctSameCity85','PctSameState85','LemasSwornFT','LemasSwFTPerPop','LemasSwFTFieldOps','LemasSwFTFieldPerPop'\n",
    ",'LemasTotalReq','LemasTotReqPerPop','PolicReqPerOffic','PolicPerPop','RacialMatchCommPol','PctPolicWhite','PctPolicBlack','PctPolicHisp','PctPolicAsian','PctPolicMinor','OfficAssgnDrugUnits','NumKindsDrugsSeiz','PolicAveOTWorked','LandArea','PopDens','PctUsePubTrans','PolicCars','PolicOperBudg'\n",
    ",'LemasPctPolicOnPatr','LemasGangUnitDeploy','LemasPctOfficDrugUn','PolicBudgPerPop'\n",
    ",'ViolentCrimesPerPop']\n",
    "lm_data = comm_crime #giving it a generic name so this code can be easily reused\n",
    "print(\"Data Type\", lm_data.dtypes) \n",
    "print(\"Shape of Data\", lm_data.shape) #Dimensions of dataset\n",
    "#print(\"Column Names\", lm_data.columns) keeping this code as a comment for now – we already input the column names directly in this notebook, so there’s no need to display them again.  However, it may be useful with a different dataset, so I’m retaining this code.   \n",
    "lm_data.head(5) #See top few rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TempleTerracecity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seasidecity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>80070.0</td>\n",
       "      <td>Waterburytown</td>\n",
       "      <td>10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>25</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72600.0</td>\n",
       "      <td>Walthamcity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ontariocity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  county  community      communityname  fold  population  \\\n",
       "1988     12     NaN        NaN  TempleTerracecity    10        0.01   \n",
       "1989      6     NaN        NaN        Seasidecity    10        0.05   \n",
       "1990      9     9.0    80070.0      Waterburytown    10        0.16   \n",
       "1991     25    17.0    72600.0        Walthamcity    10        0.08   \n",
       "1992      6     NaN        NaN        Ontariocity    10        0.20   \n",
       "\n",
       "      householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "1988           0.40          0.10          0.87          0.12   \n",
       "1989           0.96          0.46          0.28          0.83   \n",
       "1990           0.37          0.25          0.69          0.04   \n",
       "1991           0.51          0.06          0.87          0.22   \n",
       "1992           0.78          0.14          0.46          0.24   \n",
       "\n",
       "             ...           LandArea  PopDens  PctUsePubTrans  PolicCars  \\\n",
       "1988         ...               0.01     0.28            0.05        NaN   \n",
       "1989         ...               0.02     0.37            0.20        NaN   \n",
       "1990         ...               0.08     0.32            0.18       0.08   \n",
       "1991         ...               0.03     0.38            0.33       0.02   \n",
       "1992         ...               0.11     0.30            0.05       0.08   \n",
       "\n",
       "      PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "1988            NaN                  NaN                  NaN   \n",
       "1989            NaN                  NaN                  NaN   \n",
       "1990           0.06                 0.78                  0.0   \n",
       "1991           0.02                 0.79                  0.0   \n",
       "1992           0.04                 0.73                  0.5   \n",
       "\n",
       "      LemasPctOfficDrugUn  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "1988                 0.00              NaN                 0.09  \n",
       "1989                 0.00              NaN                 0.45  \n",
       "1990                 0.91             0.28                 0.23  \n",
       "1991                 0.22             0.18                 0.19  \n",
       "1992                 1.00             0.13                 0.48  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this initial look, all columns except ‘community name’ are numeric.  Additionally, we see that the ‘state’, ‘county’, and ‘community’ columns are numeric, even though they effectively reflect non-numeric information.  From the attribute information, ‘fold’ is “fold number for non-random 10 fold cross validation” and not part of the predictive data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exploratory Data Analysis and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll look at the data to see what changes (if any) need to be made to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's list the columns that have null values and how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_NaNs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>community</th>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherPerCap</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwornFT</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwFTPerPop</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwFTFieldOps</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasSwFTFieldPerPop</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasTotalReq</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasTotReqPerPop</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicReqPerOffic</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicPerPop</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RacialMatchCommPol</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicWhite</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicBlack</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicHisp</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicAsian</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPolicMinor</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OfficAssgnDrugUnits</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumKindsDrugsSeiz</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicCars</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Number_of_NaNs\n",
       "county                          1173\n",
       "community                       1176\n",
       "OtherPerCap                        1\n",
       "LemasSwornFT                    1675\n",
       "LemasSwFTPerPop                 1675\n",
       "LemasSwFTFieldOps               1675\n",
       "LemasSwFTFieldPerPop            1675\n",
       "LemasTotalReq                   1675\n",
       "LemasTotReqPerPop               1675\n",
       "PolicReqPerOffic                1675\n",
       "PolicPerPop                     1675\n",
       "RacialMatchCommPol              1675\n",
       "PctPolicWhite                   1675\n",
       "PctPolicBlack                   1675\n",
       "PctPolicHisp                    1675\n",
       "PctPolicAsian                   1675\n",
       "PctPolicMinor                   1675\n",
       "OfficAssgnDrugUnits             1675\n",
       "NumKindsDrugsSeiz               1675\n",
       "PolicAveOTWorked                1675\n",
       "PolicCars                       1675\n",
       "PolicOperBudg                   1675\n",
       "LemasPctPolicOnPatr             1675\n",
       "LemasGangUnitDeploy             1675\n",
       "PolicBudgPerPop                 1675"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = pd.DataFrame(lm_data.isnull().sum())\n",
    "nulls.columns = ['Number_of_NaNs']\n",
    "nulls = nulls[nulls.Number_of_NaNs !=0]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking the attribute info from the webpage where the data is stored, it appears a large number of the columns have minimums of 0 and maximums of 1.  Thus, it's useful just to list those columns don't have 0 and 1 for their minimum and maximum.  Maximum values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maximum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>community</th>\n",
       "      <td>94597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communityname</th>\n",
       "      <td>Zanesvillecity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Maximum\n",
       "state                      56\n",
       "county                    840\n",
       "community               94597\n",
       "communityname  Zanesvillecity\n",
       "fold                       10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_not1 = pd.DataFrame(lm_data.max())\n",
    "max_not1.columns = ['Maximum']\n",
    "max_not1 = max_not1[max_not1.Maximum !=1]\n",
    "max_not1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minimum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>community</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communityname</th>\n",
       "      <td>Aberdeencity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Minimum\n",
       "state                     1\n",
       "county                    1\n",
       "community                70\n",
       "communityname  Aberdeencity\n",
       "fold                      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_not0 = pd.DataFrame(lm_data.min())\n",
    "min_not0.columns = ['Minimum']\n",
    "min_not0 = min_not0[min_not0.Minimum !=0]\n",
    "min_not0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these minimums and maximums, it appears all numeric columns except state, county, community, and fold are normalized between 0 and 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1993.000000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.693929</td>\n",
       "      <td>58.826829</td>\n",
       "      <td>46188.336597</td>\n",
       "      <td>5.496237</td>\n",
       "      <td>0.057526</td>\n",
       "      <td>0.463462</td>\n",
       "      <td>0.179709</td>\n",
       "      <td>0.753643</td>\n",
       "      <td>0.153698</td>\n",
       "      <td>0.144009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065203</td>\n",
       "      <td>0.232840</td>\n",
       "      <td>0.161666</td>\n",
       "      <td>0.163428</td>\n",
       "      <td>0.076824</td>\n",
       "      <td>0.697956</td>\n",
       "      <td>0.440252</td>\n",
       "      <td>0.093939</td>\n",
       "      <td>0.195252</td>\n",
       "      <td>0.237998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.395117</td>\n",
       "      <td>126.420560</td>\n",
       "      <td>25299.726569</td>\n",
       "      <td>2.872650</td>\n",
       "      <td>0.126903</td>\n",
       "      <td>0.163731</td>\n",
       "      <td>0.253480</td>\n",
       "      <td>0.244079</td>\n",
       "      <td>0.208929</td>\n",
       "      <td>0.232549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109480</td>\n",
       "      <td>0.203142</td>\n",
       "      <td>0.229111</td>\n",
       "      <td>0.215038</td>\n",
       "      <td>0.140413</td>\n",
       "      <td>0.213981</td>\n",
       "      <td>0.406434</td>\n",
       "      <td>0.240335</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>48090.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>66660.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>94597.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             state      county     community         fold   population  \\\n",
       "count  1993.000000  820.000000    817.000000  1993.000000  1993.000000   \n",
       "mean     28.693929   58.826829  46188.336597     5.496237     0.057526   \n",
       "std      16.395117  126.420560  25299.726569     2.872650     0.126903   \n",
       "min       1.000000    1.000000     70.000000     1.000000     0.000000   \n",
       "25%      12.000000    9.000000  25065.000000     3.000000     0.010000   \n",
       "50%      34.000000   23.000000  48090.000000     5.000000     0.020000   \n",
       "75%      42.000000   59.500000  66660.000000     8.000000     0.050000   \n",
       "max      56.000000  840.000000  94597.000000    10.000000     1.000000   \n",
       "\n",
       "       householdsize  racepctblack  racePctWhite  racePctAsian  racePctHisp  \\\n",
       "count    1993.000000   1993.000000   1993.000000   1993.000000  1993.000000   \n",
       "mean        0.463462      0.179709      0.753643      0.153698     0.144009   \n",
       "std         0.163731      0.253480      0.244079      0.208929     0.232549   \n",
       "min         0.000000      0.000000      0.000000      0.000000     0.000000   \n",
       "25%         0.350000      0.020000      0.630000      0.040000     0.010000   \n",
       "50%         0.440000      0.060000      0.850000      0.070000     0.040000   \n",
       "75%         0.540000      0.230000      0.940000      0.170000     0.160000   \n",
       "max         1.000000      1.000000      1.000000      1.000000     1.000000   \n",
       "\n",
       "              ...              LandArea      PopDens  PctUsePubTrans  \\\n",
       "count         ...           1993.000000  1993.000000     1993.000000   \n",
       "mean          ...              0.065203     0.232840        0.161666   \n",
       "std           ...              0.109480     0.203142        0.229111   \n",
       "min           ...              0.000000     0.000000        0.000000   \n",
       "25%           ...              0.020000     0.100000        0.020000   \n",
       "50%           ...              0.040000     0.170000        0.070000   \n",
       "75%           ...              0.070000     0.280000        0.190000   \n",
       "max           ...              1.000000     1.000000        1.000000   \n",
       "\n",
       "        PolicCars  PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "count  318.000000     318.000000           318.000000           318.000000   \n",
       "mean     0.163428       0.076824             0.697956             0.440252   \n",
       "std      0.215038       0.140413             0.213981             0.406434   \n",
       "min      0.000000       0.000000             0.000000             0.000000   \n",
       "25%      0.040000       0.020000             0.620000             0.000000   \n",
       "50%      0.080000       0.030000             0.750000             0.500000   \n",
       "75%      0.197500       0.060000             0.840000             1.000000   \n",
       "max      1.000000       1.000000             1.000000             1.000000   \n",
       "\n",
       "       LemasPctOfficDrugUn  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "count          1993.000000       318.000000          1993.000000  \n",
       "mean              0.093939         0.195252             0.237998  \n",
       "std               0.240335         0.164948             0.233042  \n",
       "min               0.000000         0.000000             0.000000  \n",
       "25%               0.000000         0.110000             0.070000  \n",
       "50%               0.000000         0.155000             0.150000  \n",
       "75%               0.000000         0.220000             0.330000  \n",
       "max               1.000000         1.000000             1.000000  \n",
       "\n",
       "[8 rows x 127 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll drop the columns that won't be used in the analysis. A more detailed analysis could try to analyze the data by area, but only the state data is complete here; over half the rows of county and community data are blank, so I question their usefulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.00           0.16          0.12          0.74          0.45   \n",
       "1        0.00           0.42          0.49          0.56          0.17   \n",
       "2        0.04           0.77          1.00          0.08          0.12   \n",
       "3        0.01           0.55          0.02          0.95          0.09   \n",
       "4        0.02           0.28          0.06          0.54          1.00   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.07         0.26         0.59         0.35        0.27   \n",
       "1         0.04         0.39         0.47         0.28        0.32   \n",
       "2         0.10         0.51         0.50         0.34        0.21   \n",
       "3         0.05         0.38         0.38         0.23        0.36   \n",
       "4         0.25         0.31         0.48         0.27        0.37   \n",
       "\n",
       "          ...           LandArea  PopDens  PctUsePubTrans  PolicCars  \\\n",
       "0         ...               0.02     0.12            0.45        NaN   \n",
       "1         ...               0.01     0.21            0.02        NaN   \n",
       "2         ...               0.02     0.39            0.28        NaN   \n",
       "3         ...               0.04     0.09            0.02        NaN   \n",
       "4         ...               0.01     0.58            0.10        NaN   \n",
       "\n",
       "   PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "0            NaN                  NaN                  NaN   \n",
       "1            NaN                  NaN                  NaN   \n",
       "2            NaN                  NaN                  NaN   \n",
       "3            NaN                  NaN                  NaN   \n",
       "4            NaN                  NaN                  NaN   \n",
       "\n",
       "   LemasPctOfficDrugUn  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "0                  0.0              NaN                 0.67  \n",
       "1                  0.0              NaN                 0.43  \n",
       "2                  0.0              NaN                 0.12  \n",
       "3                  0.0              NaN                 0.03  \n",
       "4                  0.0              NaN                 0.14  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_data_numeric = lm_data.drop([\"state\", \"county\", \"community\", \"fold\", \"communityname\"], axis=1)\n",
    "lm_data_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on analysis above, there are 22 out of 123 numeric columns where 1,675 out of 1,993 rows are null values, and one column where one value is null. For now, I will fill those null values with with the median value.  Other possibilities to address the issue are deleting rows with nulls or deleting columns with nulls, depending on the needs of the analysis.  I decided to fill all values with medians so that all rows and columns would be considered in this round of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_data_numeric_nonull = lm_data_numeric.fillna(lm_data_numeric.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is code for a correlation matrix.  A matrix wasn't required by the problem set (so I'm leaving the code as comments) but can be useful in other applications so I'm leaving it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#correlations =lm_data_numeric_nonull.corr()\n",
    "#correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll designate the target variable and split it off from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.00           0.16          0.12          0.74          0.45   \n",
       "1        0.00           0.42          0.49          0.56          0.17   \n",
       "2        0.04           0.77          1.00          0.08          0.12   \n",
       "3        0.01           0.55          0.02          0.95          0.09   \n",
       "4        0.02           0.28          0.06          0.54          1.00   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.07         0.26         0.59         0.35        0.27   \n",
       "1         0.04         0.39         0.47         0.28        0.32   \n",
       "2         0.10         0.51         0.50         0.34        0.21   \n",
       "3         0.05         0.38         0.38         0.23        0.36   \n",
       "4         0.25         0.31         0.48         0.27        0.37   \n",
       "\n",
       "        ...         PolicAveOTWorked  LandArea  PopDens  PctUsePubTrans  \\\n",
       "0       ...                     0.26      0.02     0.12            0.45   \n",
       "1       ...                     0.26      0.01     0.21            0.02   \n",
       "2       ...                     0.26      0.02     0.39            0.28   \n",
       "3       ...                     0.26      0.04     0.09            0.02   \n",
       "4       ...                     0.26      0.01     0.58            0.10   \n",
       "\n",
       "   PolicCars  PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "0       0.08           0.03                 0.75                  0.5   \n",
       "1       0.08           0.03                 0.75                  0.5   \n",
       "2       0.08           0.03                 0.75                  0.5   \n",
       "3       0.08           0.03                 0.75                  0.5   \n",
       "4       0.08           0.03                 0.75                  0.5   \n",
       "\n",
       "   LemasPctOfficDrugUn  PolicBudgPerPop  \n",
       "0                  0.0            0.155  \n",
       "1                  0.0            0.155  \n",
       "2                  0.0            0.155  \n",
       "3                  0.0            0.155  \n",
       "4                  0.0            0.155  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name and split off from dataset\n",
    "targetName = 'ViolentCrimesPerPop'\n",
    "targetSeries = lm_data_numeric_nonull[targetName]\n",
    "#remove target from current location and insert in column 0\n",
    "del lm_data_numeric_nonull[targetName]\n",
    "#lm_data_numeric_nonull.insert(0, targetName, targetSeries)\n",
    "#reprint dataframe and see target is in position 0\n",
    "lm_data_numeric_nonull.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’re going to split the data into training and test sets, in a 75/25 ratio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(lm_data_numeric_nonull, targetSeries, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is code to look at min, max, and mean of the training and test sets.  We won't execute it here, but I'm leaving it in for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(np.max(X_train), np.min(X_train), np.mean(X_train), np.max(y_train), np.min(y_train), np.mean(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we would normalize the data before proceeding, but we've already verified that all values are between zero and one.  Thus, I'm leaving this code in but as a comment so it can be used in future projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#X_train = StandardScaler().fit_transform(X_train)\n",
    "#scalerX = StandardScaler().fit(X_train)\n",
    "#scalery = StandardScaler().fit(y_train)\n",
    "\n",
    "#X_train = scalerX.transform(X_train)\n",
    "#y_train = StandardScaler().fit_transform((y_train)\n",
    "#X_test = StandardScaler().fit_transform(X_test)\n",
    "#y_test = StandardScaler().fit_transform(y_test)\n",
    "\n",
    "#print(np.max(X_train), np.min(X_train), np.mean(X_train), np.max(y_train), np.min(y_train), np.mean(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Running linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is prepared, we can run the different linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first linear model we'll use is the Ridge Regression.  As the Ridge has a peanlty incorporated (alpha), we'll start with the default value and then use a grid search to find the optimum value.  In the case of the Ridge Regression, it uses 'L2' for its penalty (alpha), which penalizes based on the square of the weight.  It tends to result in fewer factors reduced to zero than 'L1', which uses the absolute value of the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge Model Coefficients:\n",
      "[-0.05689025  0.01982886  0.17738657 -0.02907009 -0.00728552  0.06039156\n",
      "  0.04756712 -0.18240027 -0.05822169  0.04049969 -0.0457667   0.04888704\n",
      "  0.05954256 -0.14380607  0.01622719 -0.15766169  0.0310556   0.03186793\n",
      " -0.08981279  0.02736342 -0.00842146 -0.11071426 -0.02102865 -0.02487761\n",
      "  0.0067258   0.02594549  0.02752024  0.02980123 -0.13466184 -0.07266441\n",
      "  0.06336806  0.02802515 -0.00594524  0.15017501 -0.0344746   0.02036406\n",
      "  0.02830624  0.02041756  0.18829914  0.15561227 -0.12692222 -0.01877988\n",
      "  0.05777633 -0.0432426  -0.14786919 -0.05135192  0.00935541  0.02841277\n",
      " -0.14902372 -0.10787731  0.14831198 -0.03420198  0.03740341 -0.0171951\n",
      "  0.01251498 -0.01172876 -0.05864224 -0.02587833  0.07553637  0.02281385\n",
      "  0.03412834 -0.12839741 -0.0622747  -0.04606317  0.16059874 -0.07796642\n",
      " -0.03058179 -0.12310599  0.1142622   0.07880613  0.00142095  0.07966912\n",
      " -0.05935806  0.0457428   0.05896676 -0.04158917  0.00771283  0.02401818\n",
      "  0.00728847 -0.07095502  0.03486578  0.01640035 -0.16037142 -0.00188347\n",
      "  0.01021057  0.16181844  0.06873107 -0.06098141 -0.08071722  0.10619451\n",
      "  0.11099985  0.10598203 -0.02009218 -0.00483508  0.04072464  0.00260345\n",
      "  0.00380556  0.09720921  0.00869735  0.04346068 -0.08693523  0.00308138\n",
      "  0.14800524  0.09861338 -0.08705813 -0.00157578  0.03423567  0.04537898\n",
      "  0.11494759 -0.01078704 -0.03400241 -0.0032151  -0.0073484   0.0264978\n",
      "  0.03766787 -0.05197205  0.12884901  0.03072876 -0.03895113  0.01405019\n",
      " -0.00190061 -0.11988909]\n",
      "Mean Squared Error:\n",
      "0.0162168131985\n",
      "R-Squared:\n",
      "0.693326632409\n",
      "Explained Variance Score:\n",
      "0.693326632409\n",
      "Median Absolute Error:\n",
      "0.0628709188123\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "model_rg = Ridge() #ridge with default alpha\n",
    "model_rg.fit(X_train, y_train)\n",
    "print(model_rg) #shows parameters and their default values\n",
    "expected_rg = y_train\n",
    "predicted_rg = model_rg.predict(X_train)\n",
    "print(\"Ridge Model Coefficients:\")\n",
    "print(model_rg.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_rg,predicted_rg))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_rg,predicted_rg))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_rg,predicted_rg))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_rg,predicted_rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default value of alpha = 1, the mean squared error in this case was 0.0162, the median absolute error 0.0629, and the R-squared was 0.693.  The default settings for the alpha didn't reduce any of the factors to zero, so this model has 122 variables, which strikes me as very complex.  Now let's do the grid search and see what the optimum value of alpha is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'alpha': 4}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.618339</td>\n",
       "      <td>0.710268</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.659092</td>\n",
       "      <td>0.699544</td>\n",
       "      <td>0.554854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669269</td>\n",
       "      <td>0.701245</td>\n",
       "      <td>0.585374</td>\n",
       "      <td>0.714341</td>\n",
       "      <td>0.623121</td>\n",
       "      <td>0.711661</td>\n",
       "      <td>0.058464</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.009154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087498</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.624660</td>\n",
       "      <td>0.709119</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.666363</td>\n",
       "      <td>0.698432</td>\n",
       "      <td>0.562578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673583</td>\n",
       "      <td>0.699904</td>\n",
       "      <td>0.590293</td>\n",
       "      <td>0.713490</td>\n",
       "      <td>0.630502</td>\n",
       "      <td>0.710472</td>\n",
       "      <td>0.015937</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.009176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628079</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>14</td>\n",
       "      <td>0.670788</td>\n",
       "      <td>0.697234</td>\n",
       "      <td>0.567267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675323</td>\n",
       "      <td>0.698761</td>\n",
       "      <td>0.593648</td>\n",
       "      <td>0.712434</td>\n",
       "      <td>0.633388</td>\n",
       "      <td>0.709205</td>\n",
       "      <td>0.013974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>0.009111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635553</td>\n",
       "      <td>0.702032</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.680854</td>\n",
       "      <td>0.691048</td>\n",
       "      <td>0.578250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680663</td>\n",
       "      <td>0.693402</td>\n",
       "      <td>0.600920</td>\n",
       "      <td>0.706948</td>\n",
       "      <td>0.637081</td>\n",
       "      <td>0.703361</td>\n",
       "      <td>0.038274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.008942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206251</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.637749</td>\n",
       "      <td>0.697569</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.683252</td>\n",
       "      <td>0.686348</td>\n",
       "      <td>0.581272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684050</td>\n",
       "      <td>0.688956</td>\n",
       "      <td>0.602601</td>\n",
       "      <td>0.702860</td>\n",
       "      <td>0.637569</td>\n",
       "      <td>0.699036</td>\n",
       "      <td>0.022963</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.041582</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639053</td>\n",
       "      <td>0.691644</td>\n",
       "      <td>2</td>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.684390</td>\n",
       "      <td>0.680288</td>\n",
       "      <td>0.581993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687805</td>\n",
       "      <td>0.682646</td>\n",
       "      <td>0.603405</td>\n",
       "      <td>0.697516</td>\n",
       "      <td>0.637666</td>\n",
       "      <td>0.693312</td>\n",
       "      <td>0.036444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042348</td>\n",
       "      <td>0.009071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.071874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639402</td>\n",
       "      <td>0.687542</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684732</td>\n",
       "      <td>0.676162</td>\n",
       "      <td>0.581244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689880</td>\n",
       "      <td>0.678107</td>\n",
       "      <td>0.603525</td>\n",
       "      <td>0.693828</td>\n",
       "      <td>0.637623</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.009206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.053124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639466</td>\n",
       "      <td>0.684390</td>\n",
       "      <td>4</td>\n",
       "      <td>{'alpha': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684883</td>\n",
       "      <td>0.672997</td>\n",
       "      <td>0.580255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691192</td>\n",
       "      <td>0.674574</td>\n",
       "      <td>0.603452</td>\n",
       "      <td>0.690991</td>\n",
       "      <td>0.637541</td>\n",
       "      <td>0.686229</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043706</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.639406</td>\n",
       "      <td>0.681829</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>0.670415</td>\n",
       "      <td>0.579275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692087</td>\n",
       "      <td>0.671690</td>\n",
       "      <td>0.603297</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.637432</td>\n",
       "      <td>0.683703</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>0.009466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.090623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639280</td>\n",
       "      <td>0.679670</td>\n",
       "      <td>6</td>\n",
       "      <td>{'alpha': 6}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684904</td>\n",
       "      <td>0.668227</td>\n",
       "      <td>0.578361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692728</td>\n",
       "      <td>0.669258</td>\n",
       "      <td>0.603100</td>\n",
       "      <td>0.686727</td>\n",
       "      <td>0.637301</td>\n",
       "      <td>0.681566</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044652</td>\n",
       "      <td>0.009583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.075001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639117</td>\n",
       "      <td>0.677803</td>\n",
       "      <td>7</td>\n",
       "      <td>{'alpha': 7}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684818</td>\n",
       "      <td>0.666324</td>\n",
       "      <td>0.577523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693203</td>\n",
       "      <td>0.667158</td>\n",
       "      <td>0.602881</td>\n",
       "      <td>0.685035</td>\n",
       "      <td>0.637154</td>\n",
       "      <td>0.679712</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>0.009691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.103124</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.638930</td>\n",
       "      <td>0.676158</td>\n",
       "      <td>8</td>\n",
       "      <td>{'alpha': 8}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.684682</td>\n",
       "      <td>0.664638</td>\n",
       "      <td>0.576756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693562</td>\n",
       "      <td>0.665310</td>\n",
       "      <td>0.602651</td>\n",
       "      <td>0.683541</td>\n",
       "      <td>0.636994</td>\n",
       "      <td>0.678076</td>\n",
       "      <td>0.028977</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.045322</td>\n",
       "      <td>0.009791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.090624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638728</td>\n",
       "      <td>0.674686</td>\n",
       "      <td>9</td>\n",
       "      <td>{'alpha': 9}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.684507</td>\n",
       "      <td>0.663122</td>\n",
       "      <td>0.576053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693835</td>\n",
       "      <td>0.663660</td>\n",
       "      <td>0.602414</td>\n",
       "      <td>0.682201</td>\n",
       "      <td>0.636825</td>\n",
       "      <td>0.676610</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045585</td>\n",
       "      <td>0.009883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638515</td>\n",
       "      <td>0.673353</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.684298</td>\n",
       "      <td>0.661746</td>\n",
       "      <td>0.575406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694044</td>\n",
       "      <td>0.662169</td>\n",
       "      <td>0.602176</td>\n",
       "      <td>0.680986</td>\n",
       "      <td>0.636647</td>\n",
       "      <td>0.675281</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045811</td>\n",
       "      <td>0.009968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.084375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637372</td>\n",
       "      <td>0.668072</td>\n",
       "      <td>15</td>\n",
       "      <td>{'alpha': 15}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.682915</td>\n",
       "      <td>0.656258</td>\n",
       "      <td>0.572770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694484</td>\n",
       "      <td>0.656287</td>\n",
       "      <td>0.600991</td>\n",
       "      <td>0.676153</td>\n",
       "      <td>0.635694</td>\n",
       "      <td>0.670005</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046568</td>\n",
       "      <td>0.010316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636174</td>\n",
       "      <td>0.664143</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 20}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.681216</td>\n",
       "      <td>0.652164</td>\n",
       "      <td>0.570757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694358</td>\n",
       "      <td>0.651938</td>\n",
       "      <td>0.599855</td>\n",
       "      <td>0.672535</td>\n",
       "      <td>0.634680</td>\n",
       "      <td>0.666068</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046952</td>\n",
       "      <td>0.010573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.156250         0.003125         0.618339          0.710268   \n",
       "1        0.087498         0.003125         0.624660          0.709119   \n",
       "2        0.125000         0.000000         0.628079          0.707904   \n",
       "3        0.187500         0.000000         0.635553          0.702032   \n",
       "4        0.206251         0.003125         0.637749          0.697569   \n",
       "5        0.100002         0.000000         0.639053          0.691644   \n",
       "6        0.071874         0.000000         0.639402          0.687542   \n",
       "7        0.053124         0.000000         0.639466          0.684390   \n",
       "8        0.049998         0.009375         0.639406          0.681829   \n",
       "9        0.090623         0.000000         0.639280          0.679670   \n",
       "10       0.075001         0.000000         0.639117          0.677803   \n",
       "11       0.103124         0.003124         0.638930          0.676158   \n",
       "12       0.090624         0.000000         0.638728          0.674686   \n",
       "13       0.074998         0.000000         0.638515          0.673353   \n",
       "14       0.084375         0.000000         0.637372          0.668072   \n",
       "15       0.053125         0.000000         0.636174          0.664143   \n",
       "\n",
       "   param_alpha           params  rank_test_score  split0_test_score  \\\n",
       "0         0.01  {'alpha': 0.01}               16           0.659092   \n",
       "1         0.05  {'alpha': 0.05}               15           0.666363   \n",
       "2          0.1   {'alpha': 0.1}               14           0.670788   \n",
       "3          0.5   {'alpha': 0.5}               13           0.680854   \n",
       "4            1     {'alpha': 1}               10           0.683252   \n",
       "5            2     {'alpha': 2}                6           0.684390   \n",
       "6            3     {'alpha': 3}                3           0.684732   \n",
       "7            4     {'alpha': 4}                1           0.684883   \n",
       "8            5     {'alpha': 5}                2           0.684931   \n",
       "9            6     {'alpha': 6}                4           0.684904   \n",
       "10           7     {'alpha': 7}                5           0.684818   \n",
       "11           8     {'alpha': 8}                7           0.684682   \n",
       "12           9     {'alpha': 9}                8           0.684507   \n",
       "13          10    {'alpha': 10}                9           0.684298   \n",
       "14          15    {'alpha': 15}               11           0.682915   \n",
       "15          20    {'alpha': 20}               12           0.681216   \n",
       "\n",
       "    split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0             0.699544           0.554854       ...                  0.669269   \n",
       "1             0.698432           0.562578       ...                  0.673583   \n",
       "2             0.697234           0.567267       ...                  0.675323   \n",
       "3             0.691048           0.578250       ...                  0.680663   \n",
       "4             0.686348           0.581272       ...                  0.684050   \n",
       "5             0.680288           0.581993       ...                  0.687805   \n",
       "6             0.676162           0.581244       ...                  0.689880   \n",
       "7             0.672997           0.580255       ...                  0.691192   \n",
       "8             0.670415           0.579275       ...                  0.692087   \n",
       "9             0.668227           0.578361       ...                  0.692728   \n",
       "10            0.666324           0.577523       ...                  0.693203   \n",
       "11            0.664638           0.576756       ...                  0.693562   \n",
       "12            0.663122           0.576053       ...                  0.693835   \n",
       "13            0.661746           0.575406       ...                  0.694044   \n",
       "14            0.656258           0.572770       ...                  0.694484   \n",
       "15            0.652164           0.570757       ...                  0.694358   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.701245           0.585374            0.714341   \n",
       "1             0.699904           0.590293            0.713490   \n",
       "2             0.698761           0.593648            0.712434   \n",
       "3             0.693402           0.600920            0.706948   \n",
       "4             0.688956           0.602601            0.702860   \n",
       "5             0.682646           0.603405            0.697516   \n",
       "6             0.678107           0.603525            0.693828   \n",
       "7             0.674574           0.603452            0.690991   \n",
       "8             0.671690           0.603297            0.688679   \n",
       "9             0.669258           0.603100            0.686727   \n",
       "10            0.667158           0.602881            0.685035   \n",
       "11            0.665310           0.602651            0.683541   \n",
       "12            0.663660           0.602414            0.682201   \n",
       "13            0.662169           0.602176            0.680986   \n",
       "14            0.656287           0.600991            0.676153   \n",
       "15            0.651938           0.599855            0.672535   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.623121            0.711661      0.058464        0.006249   \n",
       "1            0.630502            0.710472      0.015937        0.006251   \n",
       "2            0.633388            0.709205      0.013974        0.000000   \n",
       "3            0.637081            0.703361      0.038274        0.000000   \n",
       "4            0.637569            0.699036      0.022963        0.006250   \n",
       "5            0.637666            0.693312      0.036444        0.000000   \n",
       "6            0.637623            0.689320      0.007654        0.000000   \n",
       "7            0.637541            0.686229      0.007656        0.000000   \n",
       "8            0.637432            0.683703      0.011692        0.007655   \n",
       "9            0.637301            0.681566      0.031869        0.000000   \n",
       "10           0.637154            0.679712      0.018219        0.000000   \n",
       "11           0.636994            0.678076      0.028977        0.006249   \n",
       "12           0.636825            0.676610      0.015310        0.000000   \n",
       "13           0.636647            0.675281      0.018219        0.000000   \n",
       "14           0.635694            0.670005      0.015936        0.000000   \n",
       "15           0.634680            0.666068      0.015935        0.000000   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.043361         0.009154  \n",
       "1         0.042914         0.009176  \n",
       "2         0.042365         0.009111  \n",
       "3         0.041420         0.008942  \n",
       "4         0.041582         0.008957  \n",
       "5         0.042348         0.009071  \n",
       "6         0.043085         0.009206  \n",
       "7         0.043706         0.009340  \n",
       "8         0.044222         0.009466  \n",
       "9         0.044652         0.009583  \n",
       "10        0.045014         0.009691  \n",
       "11        0.045322         0.009791  \n",
       "12        0.045585         0.009883  \n",
       "13        0.045811         0.009968  \n",
       "14        0.046568         0.010316  \n",
       "15        0.046952         0.010573  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [.01,.05,.1,.5, 1, 2,3,4,5,6,7,8,9,10,15,20]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_rg, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search data computes alpha=4 as the best result.  Let's put that into the Ridge model and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=4, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge Model Coefficients:\n",
      "[ -2.58038849e-02   1.73957827e-02   1.52467814e-01  -5.77936567e-02\n",
      "  -1.08103032e-02   2.46478713e-02   4.71905543e-03  -8.29459282e-02\n",
      "  -3.05349647e-02   2.83395358e-02  -2.31135627e-02   4.58867617e-02\n",
      "   3.15990441e-02  -7.40994264e-02   5.81672884e-03  -1.03077639e-01\n",
      "   2.12930393e-02   3.26001524e-02  -7.37291954e-02   5.25248089e-03\n",
      "  -1.19448400e-02  -3.59773883e-02  -1.74053528e-02  -2.34060458e-02\n",
      "   8.89655504e-03   2.46861609e-02   2.33785807e-02  -4.84607878e-03\n",
      "  -8.03460134e-02  -4.10775738e-02   3.51257166e-02  -3.41729603e-03\n",
      "  -1.61930263e-02   5.94626354e-02  -2.67095942e-02   1.40832500e-02\n",
      "   1.61750144e-02   1.44337285e-03   1.13565013e-01   7.80467233e-02\n",
      "  -4.61848734e-02   1.37669205e-02   3.58270654e-02  -5.40249457e-02\n",
      "  -1.00715775e-01  -6.12182759e-02  -2.38302047e-03  -3.50393837e-04\n",
      "  -9.55703011e-02  -3.91526098e-02   1.47133424e-01  -1.02497636e-02\n",
      "   2.65709141e-02  -1.34656625e-02   5.94408762e-03  -6.68662671e-03\n",
      "  -2.34831896e-02  -8.59790027e-03   3.20979110e-02   2.64900915e-02\n",
      "   2.79655145e-02  -6.37763919e-02  -1.84176963e-02  -2.29670013e-02\n",
      "   5.52473372e-02  -3.79815030e-02  -4.77475966e-05  -4.71275498e-02\n",
      "   6.85717762e-02   5.22199163e-02  -5.51782226e-03   5.72125539e-02\n",
      "  -6.34084455e-02   1.29975057e-02   6.03807550e-02  -3.14720336e-02\n",
      "   7.05103521e-03   2.24261209e-02   1.12560525e-02  -2.56795036e-02\n",
      "   1.03797506e-02   1.09482758e-02  -9.85535596e-02   7.97872576e-03\n",
      "   3.42668247e-02   7.16830403e-02   5.71613464e-02  -3.60402826e-02\n",
      "  -7.35712776e-02   7.42984290e-02   8.79069430e-02   5.64934019e-02\n",
      "  -2.08223206e-02   4.13863103e-03   3.84982806e-02   3.74473587e-04\n",
      "  -5.49798889e-03   4.35429787e-02   8.38770410e-03   2.70618041e-02\n",
      "  -2.19438807e-02   3.40622159e-02   8.16827523e-02   4.38957255e-02\n",
      "  -6.84949318e-02  -8.44774244e-03   2.14449086e-02   1.70826604e-02\n",
      "   8.28213247e-02   4.82646740e-03  -1.08557990e-02   5.49015248e-04\n",
      "  -9.86748916e-03   1.47684302e-02   3.17096460e-02  -3.73249651e-02\n",
      "   7.51774182e-02   3.84635672e-03  -2.05011907e-02   1.60258778e-02\n",
      "   1.23493020e-02  -2.50232213e-02]\n",
      "Mean Squared Error:\n",
      "0.0168093617771\n",
      "R-Squared:\n",
      "0.682121048065\n",
      "Explained Variance Score:\n",
      "0.682121048065\n",
      "Median Absolute Error:\n",
      "0.0624783614755\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "model_rg_al = Ridge(alpha=4)\n",
    "model_rg_al.fit(X_train, y_train)\n",
    "print(model_rg_al) #shows parameters and their default values\n",
    "expected_rg = y_train\n",
    "predicted_rg = model_rg_al.predict(X_train)\n",
    "print(\"Ridge Model Coefficients:\")\n",
    "print(model_rg_al.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_rg,predicted_rg))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_rg,predicted_rg))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_rg,predicted_rg))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_rg,predicted_rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting Ridge model has a mean squared error of 0.0168, a median absolute error of 0.0625, and the R-squared was 0.682, which is slightly less accurate than the default setting of alpha=1.  Again, the alpha didn't reduce any of the factors to zero, so this model still has 122 variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LASSO Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the LASSO Regression, which like the Ridge has a penalty incorporated (alpha), so we'll start with the default value and then use a grid search to find the optimum value.  Unlike the Ridge Regression, it uses 'L1' for its penalty (alpha), which penalizes based on the absolute value of the weight, typically resulting in more factors being reduced to zero.  Thus, it can be useful to reduce a large number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "LASSO Model Coefficients:\n",
      "[ 0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0. -0. -0.  0.  0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0. -0.  0. -0. -0. -0.\n",
      "  0. -0.  0.  0.  0.  0.  0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0.  0.  0. -0.  0.\n",
      " -0. -0.  0.  0. -0.  0.  0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0.\n",
      "  0.  0. -0. -0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0. -0. -0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.]\n",
      "Mean Squared Error:\n",
      "0.0528797571365\n",
      "R-Squared:\n",
      "0.0\n",
      "Explained Variance Score:\n",
      "1.11022302463e-16\n",
      "Median Absolute Error:\n",
      "0.156211512718\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "# fit a LASSO model to the data\n",
    "from sklearn.linear_model import Lasso\n",
    "model_ls = Lasso() #LASSO with default vaues\n",
    "model_ls.fit(X_train, y_train)\n",
    "print(model_ls) #shows model parameters\n",
    "# make predictions\n",
    "expected_ls = y_train\n",
    "predicted_ls = model_ls.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"LASSO Model Coefficients:\")\n",
    "print(model_ls.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_ls,predicted_ls))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_ls,predicted_ls))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_ls,predicted_ls))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_ls,predicted_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default setting for the alpha (1) reduced all of the factors to zero!  The mean squared error in this case was 0.0528 and the R-squared was 0.0, but those don't have any effective meaning here.   Now let's do the grid search and see what the optimum value of alpha is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'alpha': 0.0001}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.012501</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.614824</td>\n",
       "      <td>0.710420</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.699724</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665006</td>\n",
       "      <td>0.701544</td>\n",
       "      <td>0.582664</td>\n",
       "      <td>0.714423</td>\n",
       "      <td>0.619101</td>\n",
       "      <td>0.711781</td>\n",
       "      <td>0.220615</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.042481</td>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.150004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623573</td>\n",
       "      <td>0.709382</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.665374</td>\n",
       "      <td>0.698592</td>\n",
       "      <td>0.559881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675518</td>\n",
       "      <td>0.699866</td>\n",
       "      <td>0.586981</td>\n",
       "      <td>0.713853</td>\n",
       "      <td>0.630135</td>\n",
       "      <td>0.710838</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>0.009336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.490623</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.640213</td>\n",
       "      <td>0.695387</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687723</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.583207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684776</td>\n",
       "      <td>0.687441</td>\n",
       "      <td>0.606870</td>\n",
       "      <td>0.699711</td>\n",
       "      <td>0.638484</td>\n",
       "      <td>0.696401</td>\n",
       "      <td>0.091962</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.041505</td>\n",
       "      <td>0.009138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636720</td>\n",
       "      <td>0.656254</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.683080</td>\n",
       "      <td>0.644921</td>\n",
       "      <td>0.571983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693835</td>\n",
       "      <td>0.643163</td>\n",
       "      <td>0.601768</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>0.632922</td>\n",
       "      <td>0.659264</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046574</td>\n",
       "      <td>0.010472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541757</td>\n",
       "      <td>0.551396</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.575081</td>\n",
       "      <td>0.540988</td>\n",
       "      <td>0.493454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590903</td>\n",
       "      <td>0.531903</td>\n",
       "      <td>0.502714</td>\n",
       "      <td>0.568371</td>\n",
       "      <td>0.546649</td>\n",
       "      <td>0.545991</td>\n",
       "      <td>0.026883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038503</td>\n",
       "      <td>0.015110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.071879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397880</td>\n",
       "      <td>0.408206</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.411280</td>\n",
       "      <td>0.389954</td>\n",
       "      <td>0.373167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419558</td>\n",
       "      <td>0.386990</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.435712</td>\n",
       "      <td>0.394974</td>\n",
       "      <td>0.394403</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016281</td>\n",
       "      <td>0.021882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.046873</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.037502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'alpha': 0.4}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038781</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.028123</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'alpha': 0.6}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0.7}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.024999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 0.9}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.037501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        1.012501         0.003124         0.614824          0.710420   \n",
       "1        1.150004         0.000000         0.623573          0.709382   \n",
       "2        0.490623         0.006250         0.640213          0.695387   \n",
       "3        0.106250         0.000000         0.636720          0.656254   \n",
       "4        0.081252         0.000000         0.541757          0.551396   \n",
       "5        0.071879         0.000000         0.397880          0.408206   \n",
       "6        0.046873         0.003126        -0.011480          0.000000   \n",
       "7        0.037500         0.000000        -0.011480          0.000000   \n",
       "8        0.031252         0.000000        -0.011480          0.000000   \n",
       "9        0.037502         0.000000        -0.011480          0.000000   \n",
       "10       0.046875         0.000000        -0.011480          0.000000   \n",
       "11       0.050001         0.003124        -0.011480          0.000000   \n",
       "12       0.028123         0.003126        -0.011480          0.000000   \n",
       "13       0.049998         0.000000        -0.011480          0.000000   \n",
       "14       0.040625         0.000000        -0.011480          0.000000   \n",
       "15       0.024999         0.000000        -0.011480          0.000000   \n",
       "16       0.037501         0.000000        -0.011480          0.000000   \n",
       "\n",
       "   param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0        1e-06   {'alpha': 1e-06}                4           0.654662   \n",
       "1        1e-05   {'alpha': 1e-05}                3           0.665374   \n",
       "2       0.0001  {'alpha': 0.0001}                1           0.687723   \n",
       "3        0.001   {'alpha': 0.001}                2           0.683080   \n",
       "4         0.01    {'alpha': 0.01}                5           0.575081   \n",
       "5         0.02    {'alpha': 0.02}                6           0.411280   \n",
       "6         0.05    {'alpha': 0.05}                7          -0.012055   \n",
       "7          0.1     {'alpha': 0.1}                7          -0.012055   \n",
       "8          0.2     {'alpha': 0.2}                7          -0.012055   \n",
       "9          0.3     {'alpha': 0.3}                7          -0.012055   \n",
       "10         0.4     {'alpha': 0.4}                7          -0.012055   \n",
       "11         0.5     {'alpha': 0.5}                7          -0.012055   \n",
       "12         0.6     {'alpha': 0.6}                7          -0.012055   \n",
       "13         0.7     {'alpha': 0.7}                7          -0.012055   \n",
       "14         0.8     {'alpha': 0.8}                7          -0.012055   \n",
       "15         0.9     {'alpha': 0.9}                7          -0.012055   \n",
       "16           1       {'alpha': 1}                7          -0.012055   \n",
       "\n",
       "    split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0             0.699724           0.552699       ...                  0.665006   \n",
       "1             0.698592           0.559881       ...                  0.675518   \n",
       "2             0.683821           0.583207       ...                  0.684776   \n",
       "3             0.644921           0.571983       ...                  0.693835   \n",
       "4             0.540988           0.493454       ...                  0.590903   \n",
       "5             0.389954           0.373167       ...                  0.419558   \n",
       "6             0.000000          -0.030598       ...                 -0.000357   \n",
       "7             0.000000          -0.030598       ...                 -0.000357   \n",
       "8             0.000000          -0.030598       ...                 -0.000357   \n",
       "9             0.000000          -0.030598       ...                 -0.000357   \n",
       "10            0.000000          -0.030598       ...                 -0.000357   \n",
       "11            0.000000          -0.030598       ...                 -0.000357   \n",
       "12            0.000000          -0.030598       ...                 -0.000357   \n",
       "13            0.000000          -0.030598       ...                 -0.000357   \n",
       "14            0.000000          -0.030598       ...                 -0.000357   \n",
       "15            0.000000          -0.030598       ...                 -0.000357   \n",
       "16            0.000000          -0.030598       ...                 -0.000357   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.701544           0.582664            0.714423   \n",
       "1             0.699866           0.586981            0.713853   \n",
       "2             0.687441           0.606870            0.699711   \n",
       "3             0.643163           0.601768            0.664714   \n",
       "4             0.531903           0.502714            0.568371   \n",
       "5             0.386990           0.390410            0.435712   \n",
       "6             0.000000          -0.005633            0.000000   \n",
       "7             0.000000          -0.005633            0.000000   \n",
       "8             0.000000          -0.005633            0.000000   \n",
       "9             0.000000          -0.005633            0.000000   \n",
       "10            0.000000          -0.005633            0.000000   \n",
       "11            0.000000          -0.005633            0.000000   \n",
       "12            0.000000          -0.005633            0.000000   \n",
       "13            0.000000          -0.005633            0.000000   \n",
       "14            0.000000          -0.005633            0.000000   \n",
       "15            0.000000          -0.005633            0.000000   \n",
       "16            0.000000          -0.005633            0.000000   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.619101            0.711781      0.220615        0.006248   \n",
       "1            0.630135            0.710838      0.037760        0.000000   \n",
       "2            0.638484            0.696401      0.091962        0.012500   \n",
       "3            0.632922            0.659264      0.015312        0.000000   \n",
       "4            0.546649            0.545991      0.026883        0.000000   \n",
       "5            0.394974            0.394403      0.028980        0.000000   \n",
       "6           -0.008746            0.000000      0.017116        0.006251   \n",
       "7           -0.008746            0.000000      0.021195        0.000000   \n",
       "8           -0.008746            0.000000      0.009881        0.000000   \n",
       "9           -0.008746            0.000000      0.021193        0.000000   \n",
       "10          -0.008746            0.000000      0.026143        0.000000   \n",
       "11          -0.008746            0.000000      0.038781        0.006247   \n",
       "12          -0.008746            0.000000      0.011694        0.006253   \n",
       "13          -0.008746            0.000000      0.015310        0.000000   \n",
       "14          -0.008746            0.000000      0.015931        0.000000   \n",
       "15          -0.008746            0.000000      0.012499        0.000000   \n",
       "16          -0.008746            0.000000      0.015936        0.000000   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.042481         0.009087  \n",
       "1         0.044476         0.009336  \n",
       "2         0.041505         0.009138  \n",
       "3         0.046574         0.010472  \n",
       "4         0.038503         0.015110  \n",
       "5         0.016281         0.021882  \n",
       "6         0.010311         0.000000  \n",
       "7         0.010311         0.000000  \n",
       "8         0.010311         0.000000  \n",
       "9         0.010311         0.000000  \n",
       "10        0.010311         0.000000  \n",
       "11        0.010311         0.000000  \n",
       "12        0.010311         0.000000  \n",
       "13        0.010311         0.000000  \n",
       "14        0.010311         0.000000  \n",
       "15        0.010311         0.000000  \n",
       "16        0.010311         0.000000  \n",
       "\n",
       "[17 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [.000001, .00001, .0001,.001,.01,.02, .05, .1, .2, .3,.4,.5,.6,.7,.8,.9,1]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_ls, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to use much lower values of alpha in this case when hunting for the optimal solution (not surprisingly, as we saw an alpha of one reducing all terms to zero).  The grid search determined that alpha=0.0001 was best.  Let's put that in the LASSO model and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "LASSO Model Coefficients:\n",
      "[-0.02141139  0.          0.19437811 -0.00251264 -0.          0.03975464\n",
      "  0.029732   -0.24149453  0.          0.         -0.          0.04549541\n",
      "  0.         -0.19320203  0.01064556 -0.14588531  0.          0.00461044\n",
      " -0.09377493  0.         -0.         -0.04255989 -0.01150573 -0.02183552\n",
      "  0.00715895  0.02277153  0.02176504 -0.         -0.13365505 -0.02033469\n",
      "  0.          0.         -0.          0.13384331 -0.01702572  0.02229886\n",
      "  0.          0.          0.19469328  0.16304113 -0.12163629 -0.          0.\n",
      " -0.         -0.186444   -0.04476262  0.          0.00694928 -0.12855144\n",
      " -0.1016484   0.16732954 -0.          0.01766404  0.          0.          0.\n",
      " -0.         -0.          0.          0.          0.         -0.11028525\n",
      " -0.06793987 -0.          0.16394893 -0.03645447 -0.         -0.0522035\n",
      "  0.1111058   0.07225682 -0.          0.05438403 -0.05958449  0.\n",
      "  0.05527996 -0.03458957  0.          0.01606185  0.00730908 -0.01504793\n",
      " -0.         -0.         -0.16146458  0.          0.          0.17399713\n",
      "  0.06383187 -0.05597608 -0.08300159  0.0697772   0.09557899  0.08967869\n",
      " -0.00829834 -0.          0.01802429 -0.         -0.          0.          0.\n",
      "  0.         -0.04883142  0.          0.13379599  0.15404811 -0.08002275\n",
      " -0.          0.0177815   0.00971742  0.10180044  0.         -0.         -0.\n",
      " -0.00078502  0.          0.02272325 -0.03877569  0.116213   -0.         -0.0157075\n",
      "  0.00980552  0.00039269 -0.04716004]\n",
      "Mean Squared Error:\n",
      "0.0164342573469\n",
      "R-Squared:\n",
      "0.689214583484\n",
      "Explained Variance Score:\n",
      "0.689214583484\n",
      "Median Absolute Error:\n",
      "0.062862187979\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression with alpha value determined by grid search\n",
    "# fit a LASSO model to the data\n",
    "from sklearn.linear_model import Lasso\n",
    "model_ls_al = Lasso(alpha=0.0001) \n",
    "model_ls_al.fit(X_train, y_train)\n",
    "print(model_ls_al) #shows model parameters\n",
    "# make predictions\n",
    "expected_ls = y_train\n",
    "predicted_ls = model_ls_al.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"LASSO Model Coefficients:\")\n",
    "print(model_ls_al.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_ls,predicted_ls))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_ls,predicted_ls))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_ls,predicted_ls))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_ls,predicted_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting LASSO model has a mean squared error of 0.0164, a median absolute error of 0.0629, and a R-squared of 0.6892, on par with the Ridge results.  Slightly less than half of the terms were penalized to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the Elasitc Net Regression, which also has a penalty incorporated (alpha), so we'll start with the default value and then use a grid search to find the optimum value.  The Elasitc Net uses a combination of L1 and L2 for its penalty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Elastic Net Model Coefficients:\n",
      "[ 0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0. -0. -0.  0.  0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0. -0.  0. -0. -0. -0.\n",
      "  0. -0.  0.  0.  0.  0.  0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0. -0.  0. -0.  0.  0. -0.  0.\n",
      " -0. -0.  0.  0. -0.  0.  0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.  0.\n",
      "  0.  0. -0. -0.  0. -0.  0.  0. -0.  0.  0.  0.  0.  0. -0. -0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.  0.]\n",
      "Mean Squared Error:\n",
      "0.0528797571365\n",
      "R-Squared:\n",
      "0.0\n",
      "Explained Variance Score:\n",
      "1.11022302463e-16\n",
      "Median Absolute Error:\n",
      "0.156211512718\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "# fit a model to the data\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model_en = ElasticNet()\n",
    "model_en.fit(X_train, y_train)\n",
    "print(model_en)\n",
    "# make predictions\n",
    "expected_en = y_train\n",
    "predicted_en = model_en.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"Elastic Net Model Coefficients:\")\n",
    "print(model_en.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_en,predicted_en))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_en,predicted_en))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_en,predicted_en))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_en,predicted_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the LASSO, the default setting for the alpha (1) reduced all of the factors to zero!  The mean squared error in this case was 0.0528 and the R-squared was 0.0, but those don't have any effective meaning here.   Now let's do the grid search and see what the optimum value of alpha is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'alpha': 0.001}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.153124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.614601</td>\n",
       "      <td>0.710425</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.654428</td>\n",
       "      <td>0.699731</td>\n",
       "      <td>0.552433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664972</td>\n",
       "      <td>0.701549</td>\n",
       "      <td>0.582454</td>\n",
       "      <td>0.714428</td>\n",
       "      <td>0.618733</td>\n",
       "      <td>0.711784</td>\n",
       "      <td>0.301589</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.531252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621469</td>\n",
       "      <td>0.709861</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.662647</td>\n",
       "      <td>0.699087</td>\n",
       "      <td>0.557980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673166</td>\n",
       "      <td>0.700653</td>\n",
       "      <td>0.586490</td>\n",
       "      <td>0.714111</td>\n",
       "      <td>0.627080</td>\n",
       "      <td>0.711289</td>\n",
       "      <td>0.044196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>0.009225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.765627</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.635886</td>\n",
       "      <td>0.701350</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.682017</td>\n",
       "      <td>0.690390</td>\n",
       "      <td>0.576770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679929</td>\n",
       "      <td>0.692916</td>\n",
       "      <td>0.601789</td>\n",
       "      <td>0.705846</td>\n",
       "      <td>0.638933</td>\n",
       "      <td>0.702139</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.041810</td>\n",
       "      <td>0.009067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.203126</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.640361</td>\n",
       "      <td>0.666325</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686815</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>0.578647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697370</td>\n",
       "      <td>0.655050</td>\n",
       "      <td>0.605187</td>\n",
       "      <td>0.674231</td>\n",
       "      <td>0.633763</td>\n",
       "      <td>0.669242</td>\n",
       "      <td>0.056768</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.045835</td>\n",
       "      <td>0.009612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118752</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.593667</td>\n",
       "      <td>0.606021</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.628332</td>\n",
       "      <td>0.593174</td>\n",
       "      <td>0.538016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652164</td>\n",
       "      <td>0.590268</td>\n",
       "      <td>0.551070</td>\n",
       "      <td>0.616191</td>\n",
       "      <td>0.598769</td>\n",
       "      <td>0.606140</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>0.013054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056251</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.526964</td>\n",
       "      <td>0.536701</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.557824</td>\n",
       "      <td>0.526477</td>\n",
       "      <td>0.483746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572517</td>\n",
       "      <td>0.518487</td>\n",
       "      <td>0.489931</td>\n",
       "      <td>0.553957</td>\n",
       "      <td>0.530816</td>\n",
       "      <td>0.530089</td>\n",
       "      <td>0.015934</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.035456</td>\n",
       "      <td>0.014795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.103127</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.264351</td>\n",
       "      <td>0.276071</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.260377</td>\n",
       "      <td>0.253652</td>\n",
       "      <td>0.256325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274877</td>\n",
       "      <td>0.255888</td>\n",
       "      <td>0.277211</td>\n",
       "      <td>0.310045</td>\n",
       "      <td>0.252923</td>\n",
       "      <td>0.254349</td>\n",
       "      <td>0.060598</td>\n",
       "      <td>0.031249</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.026296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033658</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.056253</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.018747</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.049999</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'alpha': 0.4}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.059375</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.068752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'alpha': 0.6}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.031249</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0.7}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.053124</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027242</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.037502</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 0.9}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021192</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        1.153124         0.006249         0.614601          0.710425   \n",
       "1        1.531252         0.000000         0.621469          0.709861   \n",
       "2        0.765627         0.012500         0.635886          0.701350   \n",
       "3        0.203126         0.009374         0.640361          0.666325   \n",
       "4        0.118752         0.009374         0.593667          0.606021   \n",
       "5        0.056251         0.003125         0.526964          0.536701   \n",
       "6        0.103127         0.015625         0.264351          0.276071   \n",
       "7        0.056250         0.003125        -0.011480          0.000000   \n",
       "8        0.056253         0.009374        -0.011480          0.000000   \n",
       "9        0.046874         0.000000        -0.011480          0.000000   \n",
       "10       0.049999         0.003125        -0.011480          0.000000   \n",
       "11       0.059375         0.003125        -0.011480          0.000000   \n",
       "12       0.068752         0.000000        -0.011480          0.000000   \n",
       "13       0.031249         0.003125        -0.011480          0.000000   \n",
       "14       0.053124         0.003125        -0.011480          0.000000   \n",
       "15       0.037502         0.006249        -0.011480          0.000000   \n",
       "16       0.050001         0.000000        -0.011480          0.000000   \n",
       "\n",
       "   param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0        1e-06   {'alpha': 1e-06}                4           0.654428   \n",
       "1        1e-05   {'alpha': 1e-05}                3           0.662647   \n",
       "2       0.0001  {'alpha': 0.0001}                2           0.682017   \n",
       "3        0.001   {'alpha': 0.001}                1           0.686815   \n",
       "4         0.01    {'alpha': 0.01}                5           0.628332   \n",
       "5         0.02    {'alpha': 0.02}                6           0.557824   \n",
       "6         0.05    {'alpha': 0.05}                7           0.260377   \n",
       "7          0.1     {'alpha': 0.1}                8          -0.012055   \n",
       "8          0.2     {'alpha': 0.2}                8          -0.012055   \n",
       "9          0.3     {'alpha': 0.3}                8          -0.012055   \n",
       "10         0.4     {'alpha': 0.4}                8          -0.012055   \n",
       "11         0.5     {'alpha': 0.5}                8          -0.012055   \n",
       "12         0.6     {'alpha': 0.6}                8          -0.012055   \n",
       "13         0.7     {'alpha': 0.7}                8          -0.012055   \n",
       "14         0.8     {'alpha': 0.8}                8          -0.012055   \n",
       "15         0.9     {'alpha': 0.9}                8          -0.012055   \n",
       "16           1       {'alpha': 1}                8          -0.012055   \n",
       "\n",
       "    split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0             0.699731           0.552433       ...                  0.664972   \n",
       "1             0.699087           0.557980       ...                  0.673166   \n",
       "2             0.690390           0.576770       ...                  0.679929   \n",
       "3             0.655068           0.578647       ...                  0.697370   \n",
       "4             0.593174           0.538016       ...                  0.652164   \n",
       "5             0.526477           0.483746       ...                  0.572517   \n",
       "6             0.253652           0.256325       ...                  0.274877   \n",
       "7             0.000000          -0.030598       ...                 -0.000357   \n",
       "8             0.000000          -0.030598       ...                 -0.000357   \n",
       "9             0.000000          -0.030598       ...                 -0.000357   \n",
       "10            0.000000          -0.030598       ...                 -0.000357   \n",
       "11            0.000000          -0.030598       ...                 -0.000357   \n",
       "12            0.000000          -0.030598       ...                 -0.000357   \n",
       "13            0.000000          -0.030598       ...                 -0.000357   \n",
       "14            0.000000          -0.030598       ...                 -0.000357   \n",
       "15            0.000000          -0.030598       ...                 -0.000357   \n",
       "16            0.000000          -0.030598       ...                 -0.000357   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.701549           0.582454            0.714428   \n",
       "1             0.700653           0.586490            0.714111   \n",
       "2             0.692916           0.601789            0.705846   \n",
       "3             0.655050           0.605187            0.674231   \n",
       "4             0.590268           0.551070            0.616191   \n",
       "5             0.518487           0.489931            0.553957   \n",
       "6             0.255888           0.277211            0.310045   \n",
       "7             0.000000          -0.005633            0.000000   \n",
       "8             0.000000          -0.005633            0.000000   \n",
       "9             0.000000          -0.005633            0.000000   \n",
       "10            0.000000          -0.005633            0.000000   \n",
       "11            0.000000          -0.005633            0.000000   \n",
       "12            0.000000          -0.005633            0.000000   \n",
       "13            0.000000          -0.005633            0.000000   \n",
       "14            0.000000          -0.005633            0.000000   \n",
       "15            0.000000          -0.005633            0.000000   \n",
       "16            0.000000          -0.005633            0.000000   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.618733            0.711784      0.301589        0.007653   \n",
       "1            0.627080            0.711289      0.044196        0.000000   \n",
       "2            0.638933            0.702139      0.232178        0.018222   \n",
       "3            0.633763            0.669242      0.056768        0.018748   \n",
       "4            0.598769            0.606140      0.023383        0.012499   \n",
       "5            0.530816            0.530089      0.015934        0.006250   \n",
       "6            0.252923            0.254349      0.060598        0.031249   \n",
       "7           -0.008746            0.000000      0.033658        0.006250   \n",
       "8           -0.008746            0.000000      0.037757        0.018747   \n",
       "9           -0.008746            0.000000      0.032776        0.000000   \n",
       "10          -0.008746            0.000000      0.030296        0.006251   \n",
       "11          -0.008746            0.000000      0.030300        0.006249   \n",
       "12          -0.008746            0.000000      0.037759        0.000000   \n",
       "13          -0.008746            0.000000      0.024206        0.006250   \n",
       "14          -0.008746            0.000000      0.027242        0.006249   \n",
       "15          -0.008746            0.000000      0.021192        0.007654   \n",
       "16          -0.008746            0.000000      0.028640        0.000000   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.042532         0.009087  \n",
       "1         0.043956         0.009225  \n",
       "2         0.041810         0.009067  \n",
       "3         0.045835         0.009612  \n",
       "4         0.043743         0.013054  \n",
       "5         0.035456         0.014795  \n",
       "6         0.009868         0.026296  \n",
       "7         0.010311         0.000000  \n",
       "8         0.010311         0.000000  \n",
       "9         0.010311         0.000000  \n",
       "10        0.010311         0.000000  \n",
       "11        0.010311         0.000000  \n",
       "12        0.010311         0.000000  \n",
       "13        0.010311         0.000000  \n",
       "14        0.010311         0.000000  \n",
       "15        0.010311         0.000000  \n",
       "16        0.010311         0.000000  \n",
       "\n",
       "[17 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [.000001, .00001, .0001,.001,.01,.02, .05, .1, .2, .3,.4,.5,.6,.7,.8,.9,1]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_en, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to LASSO, I had to use much lower values of alpha in this case when hunting for the optimal solution (not surprisingly, as we saw an alpha of one reducing all terms to zero).  The grid search determined that alpha=0.001 was best.  Let's put that in the Elastic Net model and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Elastic Net Model Coefficients:\n",
      "[ 0.         -0.          0.16930543 -0.02464761  0.          0.         -0.\n",
      " -0.02753984 -0.          0.          0.          0.04142679  0.\n",
      " -0.04425236 -0.         -0.05184516  0.          0.00399158 -0.01894466\n",
      " -0.          0.          0.         -0.         -0.00318068  0.\n",
      "  0.01190197  0.0004996   0.         -0.         -0.          0.         -0.\n",
      " -0.          0.         -0.         -0.         -0.         -0.\n",
      "  0.14538977  0.          0.          0.          0.         -0.\n",
      " -0.15708745 -0.03874272 -0.         -0.         -0.0716888   0.\n",
      "  0.19775075  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.          0.          0.\n",
      "  0.         -0.          0.         -0.          0.07690743  0.01014938\n",
      " -0.00479221  0.03584952 -0.0591252   0.          0.04687549 -0.          0.\n",
      "  0.          0.          0.          0.          0.         -0.          0.\n",
      "  0.01030885  0.00843867  0.03109507  0.         -0.06377949  0.03476982\n",
      "  0.07039783  0.04623778 -0.          0.          0.01039088 -0.          0.\n",
      "  0.         -0.          0.          0.          0.00651514  0.02254286\n",
      "  0.         -0.03413659 -0.          0.          0.          0.06075194\n",
      "  0.          0.          0.         -0.          0.          0.00740256\n",
      " -0.          0.03125099  0.         -0.          0.          0.02140441\n",
      "  0.        ]\n",
      "Mean Squared Error:\n",
      "0.0177858978992\n",
      "R-Squared:\n",
      "0.663653941276\n",
      "Explained Variance Score:\n",
      "0.663653941276\n",
      "Median Absolute Error:\n",
      "0.062858941736\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "# fit a model to the data\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model_en_al = ElasticNet(alpha=0.001)\n",
    "model_en_al.fit(X_train, y_train)\n",
    "print(model_en_al)\n",
    "# make predictions\n",
    "expected_en = y_train\n",
    "predicted_en = model_en_al.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"Elastic Net Model Coefficients:\")\n",
    "print(model_en_al.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_en,predicted_en))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_en,predicted_en))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_en,predicted_en))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_en,predicted_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting Elastic Net model has a mean squared error of 0.0178, a median absolute error of 0.0629, and a R-squared of 0.6636, slightly worse than the Ridge and LASSO results.  Roughly two thirds of the terms were penalized to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LARS (Least Angle Regression) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at the LARS, which conducts the regression in steps by finding the column most closely correlated with the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lars(copy_X=True, eps=2.2204460492503131e-16, fit_intercept=True,\n",
      "   fit_path=True, n_nonzero_coefs=500, normalize=True, positive=False,\n",
      "   precompute='auto', verbose=False)\n",
      "LARS intercept:\n",
      "-60365375308.6\n",
      "LARS Coefficients:\n",
      "[ -1.51547539e+10   3.99384787e+08  -1.67311467e+08  -1.60193635e+09\n",
      "  -5.65357082e+07   4.18802181e+08  -5.66050119e+08   6.01058130e+09\n",
      "  -2.94044413e+09   1.78496875e+09   1.02373212e+10  -2.68445469e+08\n",
      "   6.56624243e+09  -6.44944761e+08  -3.13894156e+08   5.00881909e+08\n",
      "   7.60009012e+08  -1.00114441e+09  -1.40889266e+09  -3.92735020e+09\n",
      "  -1.28361052e+08  -3.42721197e+09  -1.37220316e+08   8.45317669e+07\n",
      "  -1.24176636e+07   2.19354643e+08   2.44080425e+08   1.31773268e+10\n",
      "   1.54430923e+09   7.18437934e+08  -1.18718395e+09   1.41875756e+09\n",
      "   1.15101585e+08  -2.39918787e+08  -3.00509641e+08  -3.82746040e+08\n",
      "  -2.36403050e+08   1.18209484e+08   1.70957864e+10  -1.23677803e+09\n",
      "   2.17755723e+10  -3.53178493e+10  -7.35986773e+09   2.95252974e+09\n",
      "  -3.50678626e+09  -7.70712392e+08  -2.52689978e+07  -6.87831308e+08\n",
      "   6.86889095e+08  -9.89871685e+09  -8.00265231e+08  -1.10616751e+09\n",
      "  -2.94771255e+08   1.30164113e+09  -1.88551988e+09   8.12592490e+08\n",
      "   3.28070029e+09  -8.12978920e+09   1.18683847e+10  -9.97920869e+09\n",
      "   3.32892944e+09   1.57523631e+09   1.19928173e+10  -1.37428537e+10\n",
      "   1.33219578e+10  -7.09432874e+09   4.09917413e+09   2.81849209e+10\n",
      "   5.73150731e+08   7.59489475e+08   4.26876610e+08  -1.12670601e+09\n",
      "  -2.62099265e+08  -2.95987270e+10  -1.21975679e+09   1.74860200e+08\n",
      "  -3.29164797e+08  -9.59327560e+08  -1.23274443e+08  -9.67110372e+09\n",
      "   2.54731484e+09   5.12661604e+09  -4.12297118e+08   2.93434688e+09\n",
      "   3.47755145e+09  -5.45219789e+09  -2.04953659e+08   4.51431023e+07\n",
      "  -2.95666989e+08  -5.85190631e+08  -1.25373977e+08   4.16311152e+09\n",
      "   1.10167850e+09   2.41915333e+09  -6.31155297e+08  -1.26012464e+08\n",
      "   4.65041150e+10  -7.05478990e+12   5.54849031e+10   4.23578575e+10\n",
      "   4.56499679e+09  -1.09628133e+10   3.56375120e+09   7.02252462e+12\n",
      "  -1.10844622e+09  -5.15751413e+08   9.70730801e+08  -4.47355568e+09\n",
      "   1.05332116e+09  -2.42009968e+09  -2.28204282e+09  -3.73372871e+09\n",
      "   2.37136501e+09   1.31704256e+09  -6.22380204e+08   1.79331402e+08\n",
      "   4.48699265e+08   8.59983434e+09   2.42840160e+09   8.50083240e+08\n",
      "  -4.86205629e+08  -6.76510656e+08]\n",
      "Mean Squared Error:\n",
      "2.82174358183e+18\n",
      "R-Squared:\n",
      "-5.33615079687e+19\n",
      "Explained Variance Score:\n",
      "-5.33615079687e+19\n",
      "Median Absolute Error:\n",
      "421507801.33\n"
     ]
    }
   ],
   "source": [
    "#LARS Regression Model- Least Angle Regression model\n",
    "from sklearn import linear_model\n",
    "model_LAR = linear_model.Lars() #default numer of n_nonzero_coefs\n",
    "model_LAR.fit(X_train, y_train)\n",
    "print(model_LAR)\n",
    "# make predictions\n",
    "expected_LAR = y_train\n",
    "predicted_LAR = model_LAR.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "#mse_LAR = np.mean((predicted_LAR-expected_LAR)**2)\n",
    "print(\"LARS intercept:\")\n",
    "print(model_LAR.intercept_)\n",
    "print(\"LARS Coefficients:\")\n",
    "print(model_LAR.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_LAR,predicted_LAR))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_LAR,predicted_LAR))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_LAR,predicted_LAR))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_LAR,predicted_LAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error numbers are so large here that the model is effectively meaningless.  The default number of remaining values (the paremeter is called \"n nonzero coefficients\") is 500 in the LARS, so let's use a grid serach to find the optimal number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'n_nonzero_coefs': 8}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_nonzero_coefs</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042458</td>\n",
       "      <td>0.055538</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_nonzero_coefs': 1}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>0.024545</td>\n",
       "      <td>0.080367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049767</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.082319</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.104304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031545</td>\n",
       "      <td>0.040061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368916</td>\n",
       "      <td>0.380232</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_nonzero_coefs': 2}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.358786</td>\n",
       "      <td>0.332586</td>\n",
       "      <td>0.337893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406283</td>\n",
       "      <td>0.375584</td>\n",
       "      <td>0.377163</td>\n",
       "      <td>0.429798</td>\n",
       "      <td>0.364442</td>\n",
       "      <td>0.364954</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022587</td>\n",
       "      <td>0.032577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.533453</td>\n",
       "      <td>0.542660</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_nonzero_coefs': 3}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.573866</td>\n",
       "      <td>0.533793</td>\n",
       "      <td>0.475356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586209</td>\n",
       "      <td>0.527898</td>\n",
       "      <td>0.490002</td>\n",
       "      <td>0.559551</td>\n",
       "      <td>0.541862</td>\n",
       "      <td>0.538807</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.044174</td>\n",
       "      <td>0.011907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.554618</td>\n",
       "      <td>0.565299</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_nonzero_coefs': 4}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.599488</td>\n",
       "      <td>0.556718</td>\n",
       "      <td>0.501851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594764</td>\n",
       "      <td>0.534627</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.589709</td>\n",
       "      <td>0.558446</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039319</td>\n",
       "      <td>0.021381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569939</td>\n",
       "      <td>0.582132</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_nonzero_coefs': 5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.611154</td>\n",
       "      <td>0.567458</td>\n",
       "      <td>0.518108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602318</td>\n",
       "      <td>0.540895</td>\n",
       "      <td>0.527668</td>\n",
       "      <td>0.599112</td>\n",
       "      <td>0.590516</td>\n",
       "      <td>0.592859</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039109</td>\n",
       "      <td>0.024958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.118749</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.580946</td>\n",
       "      <td>0.592724</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_nonzero_coefs': 6}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.611595</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>0.523949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642604</td>\n",
       "      <td>0.575053</td>\n",
       "      <td>0.528968</td>\n",
       "      <td>0.600662</td>\n",
       "      <td>0.597671</td>\n",
       "      <td>0.602314</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.046856</td>\n",
       "      <td>0.018499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.125001</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_nonzero_coefs': 7}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.633290</td>\n",
       "      <td>0.587056</td>\n",
       "      <td>0.524005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642725</td>\n",
       "      <td>0.575247</td>\n",
       "      <td>0.543221</td>\n",
       "      <td>0.616081</td>\n",
       "      <td>0.600725</td>\n",
       "      <td>0.606860</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.047566</td>\n",
       "      <td>0.016739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.591949</td>\n",
       "      <td>0.603523</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_nonzero_coefs': 8}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633866</td>\n",
       "      <td>0.587424</td>\n",
       "      <td>0.532016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642784</td>\n",
       "      <td>0.575360</td>\n",
       "      <td>0.548378</td>\n",
       "      <td>0.616762</td>\n",
       "      <td>0.602735</td>\n",
       "      <td>0.610002</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.044619</td>\n",
       "      <td>0.019350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.575592</td>\n",
       "      <td>0.587252</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_nonzero_coefs': 9}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.634124</td>\n",
       "      <td>0.587610</td>\n",
       "      <td>0.533272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555453</td>\n",
       "      <td>0.489245</td>\n",
       "      <td>0.550369</td>\n",
       "      <td>0.616802</td>\n",
       "      <td>0.604842</td>\n",
       "      <td>0.613122</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.037726</td>\n",
       "      <td>0.050855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.121877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557389</td>\n",
       "      <td>0.547823</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_nonzero_coefs': 10}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.631648</td>\n",
       "      <td>0.511786</td>\n",
       "      <td>0.536363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448616</td>\n",
       "      <td>0.364801</td>\n",
       "      <td>0.563104</td>\n",
       "      <td>0.612888</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.616844</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063758</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.146873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229753</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_nonzero_coefs': 20}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.338547</td>\n",
       "      <td>-0.173268</td>\n",
       "      <td>0.567553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.886793</td>\n",
       "      <td>-1.314493</td>\n",
       "      <td>0.504623</td>\n",
       "      <td>0.490124</td>\n",
       "      <td>0.626160</td>\n",
       "      <td>0.649983</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566720</td>\n",
       "      <td>0.754216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.165627</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.444349</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_nonzero_coefs': 30}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028456</td>\n",
       "      <td>-0.845828</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.224394</td>\n",
       "      <td>-3.032642</td>\n",
       "      <td>0.334440</td>\n",
       "      <td>0.316693</td>\n",
       "      <td>0.632767</td>\n",
       "      <td>0.663954</td>\n",
       "      <td>0.015934</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>1.068852</td>\n",
       "      <td>1.408781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.165623</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>-1.369488</td>\n",
       "      <td>-2.253636</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_nonzero_coefs': 40}</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.692439</td>\n",
       "      <td>-4.371189</td>\n",
       "      <td>0.581763</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.205241</td>\n",
       "      <td>-8.150955</td>\n",
       "      <td>-0.158490</td>\n",
       "      <td>-0.096689</td>\n",
       "      <td>0.633667</td>\n",
       "      <td>0.670611</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>2.560619</td>\n",
       "      <td>3.494925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19.284316</td>\n",
       "      <td>-24.974841</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_nonzero_coefs': 50}</td>\n",
       "      <td>14</td>\n",
       "      <td>-3.858653</td>\n",
       "      <td>-8.550854</td>\n",
       "      <td>0.582516</td>\n",
       "      <td>...</td>\n",
       "      <td>-93.039746</td>\n",
       "      <td>-116.935831</td>\n",
       "      <td>-0.659807</td>\n",
       "      <td>-0.743289</td>\n",
       "      <td>0.620681</td>\n",
       "      <td>0.673612</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.929183</td>\n",
       "      <td>46.108272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.225001</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-31.571999</td>\n",
       "      <td>-40.230665</td>\n",
       "      <td>60</td>\n",
       "      <td>{'n_nonzero_coefs': 60}</td>\n",
       "      <td>15</td>\n",
       "      <td>-7.499211</td>\n",
       "      <td>-14.763486</td>\n",
       "      <td>0.581502</td>\n",
       "      <td>...</td>\n",
       "      <td>-149.667672</td>\n",
       "      <td>-185.818124</td>\n",
       "      <td>-1.784521</td>\n",
       "      <td>-1.930899</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.674285</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>59.146651</td>\n",
       "      <td>73.018430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.190624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.836959</td>\n",
       "      <td>-88.003883</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_nonzero_coefs': 70}</td>\n",
       "      <td>16</td>\n",
       "      <td>-10.268400</td>\n",
       "      <td>-19.208359</td>\n",
       "      <td>0.580818</td>\n",
       "      <td>...</td>\n",
       "      <td>-356.605770</td>\n",
       "      <td>-418.898832</td>\n",
       "      <td>-3.259403</td>\n",
       "      <td>-3.278058</td>\n",
       "      <td>0.616972</td>\n",
       "      <td>0.678259</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.499237</td>\n",
       "      <td>165.610056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.193749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-145.024743</td>\n",
       "      <td>-163.954110</td>\n",
       "      <td>80</td>\n",
       "      <td>{'n_nonzero_coefs': 80}</td>\n",
       "      <td>17</td>\n",
       "      <td>-16.678442</td>\n",
       "      <td>-28.903219</td>\n",
       "      <td>0.578680</td>\n",
       "      <td>...</td>\n",
       "      <td>-704.278404</td>\n",
       "      <td>-787.568184</td>\n",
       "      <td>-4.874785</td>\n",
       "      <td>-4.669865</td>\n",
       "      <td>0.616331</td>\n",
       "      <td>0.679807</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>279.814953</td>\n",
       "      <td>311.999050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.193748</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>-230.293171</td>\n",
       "      <td>-250.394387</td>\n",
       "      <td>90</td>\n",
       "      <td>{'n_nonzero_coefs': 90}</td>\n",
       "      <td>18</td>\n",
       "      <td>-22.255088</td>\n",
       "      <td>-37.060177</td>\n",
       "      <td>0.569941</td>\n",
       "      <td>...</td>\n",
       "      <td>-1120.062559</td>\n",
       "      <td>-1207.762173</td>\n",
       "      <td>-9.562278</td>\n",
       "      <td>-8.523601</td>\n",
       "      <td>0.616401</td>\n",
       "      <td>0.679910</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>445.150077</td>\n",
       "      <td>478.884073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.334375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-302.039280</td>\n",
       "      <td>-320.288884</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_nonzero_coefs': 100}</td>\n",
       "      <td>19</td>\n",
       "      <td>-30.921457</td>\n",
       "      <td>-48.642877</td>\n",
       "      <td>0.561523</td>\n",
       "      <td>...</td>\n",
       "      <td>-1459.240909</td>\n",
       "      <td>-1537.252667</td>\n",
       "      <td>-20.197287</td>\n",
       "      <td>-16.921768</td>\n",
       "      <td>0.613949</td>\n",
       "      <td>0.678483</td>\n",
       "      <td>0.083035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>578.970873</td>\n",
       "      <td>608.748607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.493751</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>-477.007306</td>\n",
       "      <td>-474.877894</td>\n",
       "      <td>110</td>\n",
       "      <td>{'n_nonzero_coefs': 110}</td>\n",
       "      <td>20</td>\n",
       "      <td>-43.320231</td>\n",
       "      <td>-62.144783</td>\n",
       "      <td>0.543661</td>\n",
       "      <td>...</td>\n",
       "      <td>-2313.378888</td>\n",
       "      <td>-2290.858800</td>\n",
       "      <td>-27.880612</td>\n",
       "      <td>-22.752427</td>\n",
       "      <td>0.596879</td>\n",
       "      <td>0.673104</td>\n",
       "      <td>0.039031</td>\n",
       "      <td>0.022963</td>\n",
       "      <td>918.725266</td>\n",
       "      <td>908.280744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.381250</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>-595.509479</td>\n",
       "      <td>-576.033618</td>\n",
       "      <td>120</td>\n",
       "      <td>{'n_nonzero_coefs': 120}</td>\n",
       "      <td>21</td>\n",
       "      <td>-52.850124</td>\n",
       "      <td>-71.592764</td>\n",
       "      <td>0.524346</td>\n",
       "      <td>...</td>\n",
       "      <td>-2886.200569</td>\n",
       "      <td>-2779.924816</td>\n",
       "      <td>-37.584187</td>\n",
       "      <td>-29.980715</td>\n",
       "      <td>0.556670</td>\n",
       "      <td>0.652129</td>\n",
       "      <td>0.032174</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>1146.017528</td>\n",
       "      <td>1102.264359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.159376         0.000000         0.042458          0.055538   \n",
       "1        0.087499         0.000000         0.368916          0.380232   \n",
       "2        0.100002         0.003125         0.533453          0.542660   \n",
       "3        0.121875         0.000000         0.554618          0.565299   \n",
       "4        0.137501         0.000000         0.569939          0.582132   \n",
       "5        0.118749         0.006250         0.580946          0.592724   \n",
       "6        0.125001         0.003124         0.588785          0.600610   \n",
       "7        0.125000         0.003126         0.591949          0.603523   \n",
       "8        0.118750         0.003125         0.575592          0.587252   \n",
       "9        0.121877         0.000000         0.557389          0.547823   \n",
       "10       0.146873         0.000000         0.229753          0.063721   \n",
       "11       0.165627         0.003125        -0.130660         -0.444349   \n",
       "12       0.165623         0.006251        -1.369488         -2.253636   \n",
       "13       0.206250         0.000000       -19.284316        -24.974841   \n",
       "14       0.225001         0.003125       -31.571999        -40.230665   \n",
       "15       0.190624         0.000000       -73.836959        -88.003883   \n",
       "16       0.193749         0.000000      -145.024743       -163.954110   \n",
       "17       0.193748         0.006250      -230.293171       -250.394387   \n",
       "18       0.334375         0.000000      -302.039280       -320.288884   \n",
       "19       0.493751         0.018750      -477.007306       -474.877894   \n",
       "20       0.381250         0.003126      -595.509479       -576.033618   \n",
       "\n",
       "   param_n_nonzero_coefs                    params  rank_test_score  \\\n",
       "0                      1    {'n_nonzero_coefs': 1}               11   \n",
       "1                      2    {'n_nonzero_coefs': 2}                9   \n",
       "2                      3    {'n_nonzero_coefs': 3}                8   \n",
       "3                      4    {'n_nonzero_coefs': 4}                7   \n",
       "4                      5    {'n_nonzero_coefs': 5}                5   \n",
       "5                      6    {'n_nonzero_coefs': 6}                3   \n",
       "6                      7    {'n_nonzero_coefs': 7}                2   \n",
       "7                      8    {'n_nonzero_coefs': 8}                1   \n",
       "8                      9    {'n_nonzero_coefs': 9}                4   \n",
       "9                     10   {'n_nonzero_coefs': 10}                6   \n",
       "10                    20   {'n_nonzero_coefs': 20}               10   \n",
       "11                    30   {'n_nonzero_coefs': 30}               12   \n",
       "12                    40   {'n_nonzero_coefs': 40}               13   \n",
       "13                    50   {'n_nonzero_coefs': 50}               14   \n",
       "14                    60   {'n_nonzero_coefs': 60}               15   \n",
       "15                    70   {'n_nonzero_coefs': 70}               16   \n",
       "16                    80   {'n_nonzero_coefs': 80}               17   \n",
       "17                    90   {'n_nonzero_coefs': 90}               18   \n",
       "18                   100  {'n_nonzero_coefs': 100}               19   \n",
       "19                   110  {'n_nonzero_coefs': 110}               20   \n",
       "20                   120  {'n_nonzero_coefs': 120}               21   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0            0.015237            0.024545           0.080367       ...          \n",
       "1            0.358786            0.332586           0.337893       ...          \n",
       "2            0.573866            0.533793           0.475356       ...          \n",
       "3            0.599488            0.556718           0.501851       ...          \n",
       "4            0.611154            0.567458           0.518108       ...          \n",
       "5            0.611595            0.567857           0.523949       ...          \n",
       "6            0.633290            0.587056           0.524005       ...          \n",
       "7            0.633866            0.587424           0.532016       ...          \n",
       "8            0.634124            0.587610           0.533272       ...          \n",
       "9            0.631648            0.511786           0.536363       ...          \n",
       "10           0.338547           -0.173268           0.567553       ...          \n",
       "11           0.028456           -0.845828           0.577982       ...          \n",
       "12          -1.692439           -4.371189           0.581763       ...          \n",
       "13          -3.858653           -8.550854           0.582516       ...          \n",
       "14          -7.499211          -14.763486           0.581502       ...          \n",
       "15         -10.268400          -19.208359           0.580818       ...          \n",
       "16         -16.678442          -28.903219           0.578680       ...          \n",
       "17         -22.255088          -37.060177           0.569941       ...          \n",
       "18         -30.921457          -48.642877           0.561523       ...          \n",
       "19         -43.320231          -62.144783           0.543661       ...          \n",
       "20         -52.850124          -71.592764           0.524346       ...          \n",
       "\n",
       "    split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0            0.049767            0.047200           0.069320   \n",
       "1            0.406283            0.375584           0.377163   \n",
       "2            0.586209            0.527898           0.490002   \n",
       "3            0.594764            0.534627           0.518552   \n",
       "4            0.602318            0.540895           0.527668   \n",
       "5            0.642604            0.575053           0.528968   \n",
       "6            0.642725            0.575247           0.543221   \n",
       "7            0.642784            0.575360           0.548378   \n",
       "8            0.555453            0.489245           0.550369   \n",
       "9            0.448616            0.364801           0.563104   \n",
       "10          -0.886793           -1.314493           0.504623   \n",
       "11          -2.224394           -3.032642           0.334440   \n",
       "12          -6.205241           -8.150955          -0.158490   \n",
       "13         -93.039746         -116.935831          -0.659807   \n",
       "14        -149.667672         -185.818124          -1.784521   \n",
       "15        -356.605770         -418.898832          -3.259403   \n",
       "16        -704.278404         -787.568184          -4.874785   \n",
       "17       -1120.062559        -1207.762173          -9.562278   \n",
       "18       -1459.240909        -1537.252667         -20.197287   \n",
       "19       -2313.378888        -2290.858800         -27.880612   \n",
       "20       -2886.200569        -2779.924816         -37.584187   \n",
       "\n",
       "    split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0             0.082319          -0.002552            0.006142      0.104304   \n",
       "1             0.429798           0.364442            0.364954      0.007654   \n",
       "2             0.559551           0.541862            0.538807      0.018750   \n",
       "3             0.589709           0.558446            0.555907      0.011694   \n",
       "4             0.599112           0.590516            0.592859      0.006252   \n",
       "5             0.600662           0.597671            0.602314      0.012501   \n",
       "6             0.616081           0.600725            0.606860      0.009882   \n",
       "7             0.616762           0.602735            0.610002      0.017116   \n",
       "8             0.616802           0.604842            0.613122      0.007654   \n",
       "9             0.612888           0.607383            0.616844      0.011694   \n",
       "10            0.490124           0.626160            0.649983      0.021195   \n",
       "11            0.316693           0.632767            0.663954      0.015934   \n",
       "12           -0.096689           0.633667            0.670611      0.021195   \n",
       "13           -0.743289           0.620681            0.673612      0.011693   \n",
       "14           -1.930899           0.617566            0.674285      0.015932   \n",
       "15           -3.278058           0.616972            0.678259      0.018220   \n",
       "16           -4.669865           0.616331            0.679807      0.015936   \n",
       "17           -8.523601           0.616401            0.679910      0.012499   \n",
       "18          -16.921768           0.613949            0.678483      0.083035   \n",
       "19          -22.752427           0.596879            0.673104      0.039031   \n",
       "20          -29.980715           0.556670            0.652129      0.032174   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.000000        0.031545         0.040061  \n",
       "1         0.000000        0.022587         0.032577  \n",
       "2         0.006250        0.044174         0.011907  \n",
       "3         0.000000        0.039319         0.021381  \n",
       "4         0.000000        0.039109         0.024958  \n",
       "5         0.007655        0.046856         0.018499  \n",
       "6         0.006248        0.047566         0.016739  \n",
       "7         0.006252        0.044619         0.019350  \n",
       "8         0.006251        0.037726         0.050855  \n",
       "9         0.000000        0.063758         0.101008  \n",
       "10        0.000000        0.566720         0.754216  \n",
       "11        0.006251        1.068852         1.408781  \n",
       "12        0.007655        2.560619         3.494925  \n",
       "13        0.000000       36.929183        46.108272  \n",
       "14        0.006250       59.146651        73.018430  \n",
       "15        0.000000      141.499237       165.610056  \n",
       "16        0.000000      279.814953       311.999050  \n",
       "17        0.007655      445.150077       478.884073  \n",
       "18        0.000000      578.970873       608.748607  \n",
       "19        0.022963      918.725266       908.280744  \n",
       "20        0.006251     1146.017528      1102.264359  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"n_nonzero_coefs\": [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,110,120]}\n",
    "#param_grid={\"alpha\": [0,10,1]} #this does a range 1 through 10 changes by a factor of 1. \n",
    "#param_grid={\"alpha\": [.01,1,.05]} #this does a range 1 through 1 changes by a factor of .05\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_LAR, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The grid serach determined that 8 nonzero coefficients is the best answer.  Let's put that number into the LARS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lars(copy_X=True, eps=2.2204460492503131e-16, fit_intercept=True,\n",
      "   fit_path=True, n_nonzero_coefs=8, normalize=True, positive=False,\n",
      "   precompute='auto', verbose=False)\n",
      "LARS intercept:\n",
      "0.498311886923\n",
      "LARS Coefficients:\n",
      "[  0.00000000e+00   0.00000000e+00   0.00000000e+00  -1.58651432e-01\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   7.64547341e-02   0.00000000e+00\n",
      "   0.00000000e+00  -4.29670793e-02   0.00000000e+00   0.00000000e+00\n",
      "  -3.32715597e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.74648912e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   7.92804640e-02\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   8.58360982e-05   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "Mean Squared Error:\n",
      "0.0216156237166\n",
      "R-Squared:\n",
      "0.591230654468\n",
      "Explained Variance Score:\n",
      "0.591230654468\n",
      "Median Absolute Error:\n",
      "0.0719546775645\n"
     ]
    }
   ],
   "source": [
    "#LARS Regression Model- Least Angle Regression model\n",
    "from sklearn import linear_model\n",
    "model_LAR_cf = linear_model.Lars(n_nonzero_coefs=8)\n",
    "model_LAR_cf.fit(X_train, y_train)\n",
    "print(model_LAR_cf)\n",
    "# make predictions\n",
    "expected_LAR = y_train\n",
    "predicted_LAR = model_LAR_cf.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"LARS intercept:\")\n",
    "print(model_LAR_cf.intercept_)\n",
    "print(\"LARS Coefficients:\")\n",
    "print(model_LAR_cf.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_LAR,predicted_LAR))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_LAR,predicted_LAR))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_LAR,predicted_LAR))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_LAR,predicted_LAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LARS has a mean squared error of 0.0216, a median absolute error of 0.0720, and an R-squared of 0.591, slightly worse than the other results seen so far.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to conduct a cross validation on the Ridge model with the alpha=4 as found during the grid search.    Cross validation is a process where we take a subset of the data (in this case, 10% of it) and a this data is compared to a model generated by the remaining data (in this case, 90% of it).  This process is repeated for a total of 10 times (in our example), with each run using a different 10% of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.71818732  0.64075015  0.63274775  0.49837093  0.72692664  0.64143831\n",
      "  0.62025856  0.60044992  0.63444518  0.63891038]\n",
      "Mean Cross Validation Score 0.635248514688\n"
     ]
    }
   ],
   "source": [
    "#verify Ridge with Cross Validation\n",
    "scores = cross_val_score(model_rg_al, X_train, y_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print(\"Mean Cross Validation Score\", scores.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation revealed a wide range of scores from 0.498 to 0.727.  This suggests the model is overfit, which not entirely surprising given that it contains 122 variables.  Since the LASSO results were similar, we'll run a Cross Validation on the LASSO as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.7193922   0.64335571  0.63249457  0.50557729  0.71939543  0.63940197\n",
      "  0.63024936  0.60924868  0.63448746  0.63162436]\n",
      "Mean Cross Validation Score 0.636522702073\n"
     ]
    }
   ],
   "source": [
    "#verify LASSO with Cross Validation\n",
    "scores = cross_val_score(model_ls_al, X_train, y_train, cv=10)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print(\"Mean Cross Validation Score\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LASSO cross validation results also show a significant spread, from 0.506 to 0.719, but not quite as large as the Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Mean Squared Error, Median Absolute Error, and R Squared scores, I judge the Ridge  and LASSO models to be nearly tied in performance.  That said, I would choose the LASSO as the cross validation results for the Ridge were worse, thus the Ridge model is likely more overfit than the LASSO.  Follow-on analysis should look at which variables should be eliminated from the model to achieve less variance, and other methods to achieve more consistant results.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
