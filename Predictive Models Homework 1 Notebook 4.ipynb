{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atwell - Homework 1 Notebook 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Packages, Setup, and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection  import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score, explained_variance_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Check working directory and change if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mlatw\\\\Desktop\\\\BIA6303\\\\Assignment_1'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlatw\\Desktop\\BIA6303\\Assignment_1\n"
     ]
    }
   ],
   "source": [
    "cd /Users/mlatw/Desktop/BIA6303/Assignment_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the prostate data set and displaying some basic information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type Obs          int64\n",
      "lcavol     float64\n",
      "lweight    float64\n",
      "age          int64\n",
      "lbph       float64\n",
      "svi          int64\n",
      "lcp        float64\n",
      "gleason      int64\n",
      "pgg45        int64\n",
      "lpsa       float64\n",
      "dtype: object\n",
      "Shape of Data (97, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Obs</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Obs    lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45  \\\n",
       "0    1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0   \n",
       "1    2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0   \n",
       "2    3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20   \n",
       "3    4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0   \n",
       "4    5  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0   \n",
       "\n",
       "       lpsa  \n",
       "0 -0.430783  \n",
       "1 -0.162519  \n",
       "2 -0.162519  \n",
       "3 -0.162519  \n",
       "4  0.371564  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 999 #added to display all rows (if needed, but output should be tweaked as required)\n",
    "prostate = pd.read_csv(\"prostate.csv\") #NA values in this dataset are encoded with a ?\n",
    "lm_data = prostate #giving it a generic name so this code can be easily reused\n",
    "print(\"Data Type\", lm_data.dtypes) \n",
    "print(\"Shape of Data\", lm_data.shape) #Dimensions of dataset\n",
    "lm_data.head(5) #See top few rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Obs</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>2.830268</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>4.385147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>3.821004</td>\n",
       "      <td>3.896909</td>\n",
       "      <td>44</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>4.684443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>2.907447</td>\n",
       "      <td>3.396185</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1</td>\n",
       "      <td>2.463853</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5.143124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2.882564</td>\n",
       "      <td>3.773910</td>\n",
       "      <td>68</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>5.477509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>3.471966</td>\n",
       "      <td>3.974998</td>\n",
       "      <td>68</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>1</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Obs    lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45  \\\n",
       "92   93  2.830268  3.876396   68 -1.386294    1  1.321756        7     60   \n",
       "93   94  3.821004  3.896909   44 -1.386294    1  2.169054        7     40   \n",
       "94   95  2.907447  3.396185   52 -1.386294    1  2.463853        7     10   \n",
       "95   96  2.882564  3.773910   68  1.558145    1  1.558145        7     80   \n",
       "96   97  3.471966  3.974998   68  0.438255    1  2.904165        7     20   \n",
       "\n",
       "        lpsa  \n",
       "92  4.385147  \n",
       "93  4.684443  \n",
       "94  5.143124  \n",
       "95  5.477509  \n",
       "96  5.582932  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this initial look, all columns are numeric.  Additionally, we see that the 'obs' is a line numer and shouldn't figure in any numerical analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exploratory Data Analysis and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll look at the data to see what changes (if any) need to be made to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's list the columns that have null values and how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_NaNs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Number_of_NaNs]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = pd.DataFrame(lm_data.isnull().sum())\n",
    "nulls.columns = ['Number_of_NaNs']\n",
    "nulls = nulls[nulls.Number_of_NaNs !=0]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls in the dataset.  Now let's see a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Obs</th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.145456</td>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Obs     lcavol    lweight        age       lbph        svi  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean   49.000000   1.350010   3.628943  63.865979   0.100356   0.216495   \n",
       "std    28.145456   1.178625   0.428411   7.445117   1.450807   0.413995   \n",
       "min     1.000000  -1.347074   2.374906  41.000000  -1.386294   0.000000   \n",
       "25%    25.000000   0.512824   3.375880  60.000000  -1.386294   0.000000   \n",
       "50%    49.000000   1.446919   3.623007  65.000000   0.300105   0.000000   \n",
       "75%    73.000000   2.127041   3.876396  68.000000   1.558145   0.000000   \n",
       "max    97.000000   3.821004   4.780383  79.000000   2.326302   1.000000   \n",
       "\n",
       "             lcp    gleason       pgg45       lpsa  \n",
       "count  97.000000  97.000000   97.000000  97.000000  \n",
       "mean   -0.179366   6.752577   24.381443   2.478387  \n",
       "std     1.398250   0.722134   28.204035   1.154329  \n",
       "min    -1.386294   6.000000    0.000000  -0.430783  \n",
       "25%    -1.386294   6.000000    0.000000   1.731656  \n",
       "50%    -0.798508   7.000000   15.000000   2.591516  \n",
       "75%     1.178655   7.000000   40.000000   3.056357  \n",
       "max     2.904165   9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll drop the column that won't be used in the analysis, in this case 'Obs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783\n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519\n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519\n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519\n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_data_numeric = lm_data.drop([\"Obs\"], axis=1)\n",
    "lm_data_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls need to be filled, so this code isn't necessary, but executing to maintain consistency with the rest of the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_data_numeric_nonull = lm_data_numeric.fillna(lm_data_numeric.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is code for a correlation matrix, which shows the degree that variables chanhge with each other (1 = perfect positive correlation, 0 = no corrleation, an -1 = perfect negative correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280521</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.734460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.280521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.433319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.169593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.179809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.566218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.548813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>0.368987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.433319</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.179809</td>\n",
       "      <td>0.566218</td>\n",
       "      <td>0.548813</td>\n",
       "      <td>0.368987</td>\n",
       "      <td>0.422316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.280521  0.225000  0.027350  0.538845  0.675310  0.432417   \n",
       "lweight  0.280521  1.000000  0.347969  0.442264  0.155385  0.164537  0.056882   \n",
       "age      0.225000  0.347969  1.000000  0.350186  0.117658  0.127668  0.268892   \n",
       "lbph     0.027350  0.442264  0.350186  1.000000 -0.085843 -0.006999  0.077820   \n",
       "svi      0.538845  0.155385  0.117658 -0.085843  1.000000  0.673111  0.320412   \n",
       "lcp      0.675310  0.164537  0.127668 -0.006999  0.673111  1.000000  0.514830   \n",
       "gleason  0.432417  0.056882  0.268892  0.077820  0.320412  0.514830  1.000000   \n",
       "pgg45    0.433652  0.107354  0.276112  0.078460  0.457648  0.631528  0.751905   \n",
       "lpsa     0.734460  0.433319  0.169593  0.179809  0.566218  0.548813  0.368987   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.433652  0.734460  \n",
       "lweight  0.107354  0.433319  \n",
       "age      0.276112  0.169593  \n",
       "lbph     0.078460  0.179809  \n",
       "svi      0.457648  0.566218  \n",
       "lcp      0.631528  0.548813  \n",
       "gleason  0.751905  0.368987  \n",
       "pgg45    1.000000  0.422316  \n",
       "lpsa     0.422316  1.000000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations =lm_data_numeric_nonull.corr()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strongest correlations with the target variable (lpsa) is lcavol, svi, and lcp. Age and lbph appear to have the weakest correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll normalize the data.  All data should be between 0 and 1 after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.521874</td>\n",
       "      <td>0.521326</td>\n",
       "      <td>0.601736</td>\n",
       "      <td>0.400434</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>0.281305</td>\n",
       "      <td>0.250859</td>\n",
       "      <td>0.243814</td>\n",
       "      <td>0.483756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.228059</td>\n",
       "      <td>0.178098</td>\n",
       "      <td>0.195924</td>\n",
       "      <td>0.390780</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>0.325897</td>\n",
       "      <td>0.240711</td>\n",
       "      <td>0.282040</td>\n",
       "      <td>0.191949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.359882</td>\n",
       "      <td>0.416123</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540625</td>\n",
       "      <td>0.518858</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.454237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136999</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.502568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.672226</td>\n",
       "      <td>0.624196</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.793094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.579864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    0.521874   0.521326   0.601736   0.400434   0.216495   0.281305   \n",
       "std     0.228059   0.178098   0.195924   0.390780   0.413995   0.325897   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.359882   0.416123   0.500000   0.000000   0.000000   0.000000   \n",
       "50%     0.540625   0.518858   0.631579   0.454237   0.000000   0.136999   \n",
       "75%     0.672226   0.624196   0.710526   0.793094   0.000000   0.597826   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "         gleason      pgg45       lpsa  \n",
       "count  97.000000  97.000000  97.000000  \n",
       "mean    0.250859   0.243814   0.483756  \n",
       "std     0.240711   0.282040   0.191949  \n",
       "min     0.000000   0.000000   0.000000  \n",
       "25%     0.000000   0.000000   0.359584  \n",
       "50%     0.333333   0.150000   0.502568  \n",
       "75%     0.333333   0.400000   0.579864  \n",
       "max     1.000000   1.000000   1.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_data_numeric_nonull_nm = lm_data_numeric_nonull\n",
    "lm_data_numeric_nonull_nm = (lm_data_numeric_nonull_nm - lm_data_numeric_nonull_nm.min())/(lm_data_numeric_nonull_nm.max() - lm_data_numeric_nonull_nm.min()) #calculates normalized 0 to 1 value\n",
    "lm_data_numeric_nonull_nm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've verified the data is normalized.  Now we’ll designate the target variable and split it off from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.148460</td>\n",
       "      <td>0.164023</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068269</td>\n",
       "      <td>0.392737</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161810</td>\n",
       "      <td>0.131507</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027689</td>\n",
       "      <td>0.377423</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406048</td>\n",
       "      <td>0.439608</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight       age  lbph  svi  lcp   gleason  pgg45\n",
       "0  0.148460  0.164023  0.236842   0.0  0.0  0.0  0.000000    0.0\n",
       "1  0.068269  0.392737  0.447368   0.0  0.0  0.0  0.000000    0.0\n",
       "2  0.161810  0.131507  0.868421   0.0  0.0  0.0  0.333333    0.2\n",
       "3  0.027689  0.377423  0.447368   0.0  0.0  0.0  0.000000    0.0\n",
       "4  0.406048  0.439608  0.552632   0.0  0.0  0.0  0.000000    0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name and split off from dataset\n",
    "targetName = 'lpsa'\n",
    "targetSeries = lm_data_numeric_nonull_nm[targetName]\n",
    "#remove target from current location and insert in column 0\n",
    "del lm_data_numeric_nonull_nm[targetName]\n",
    "#lm_data_numeric_nonull.insert(0, targetName, targetSeries)\n",
    "#reprint dataframe and see target is in position 0\n",
    "lm_data_numeric_nonull_nm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’re going to split the data into training and test sets, in a 75/25 ratio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(lm_data_numeric_nonull_nm, targetSeries, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is code to look at min, max, and mean of the training and test sets.  We won't execute it here, but I'm leaving it in for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(np.max(X_train), np.min(X_train), np.mean(X_train), np.max(y_train), np.min(y_train), np.mean(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Running linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is prepared, we can run the different linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first linear model we'll use is the Ridge Regression.  As the Ridge has a peanlty incorporated (alpha), we'll start with the default value and then use a grid search to find the optimum value.  In the case of the Ridge Regression, it uses 'L2' for its penalty (alpha), which penalizes based on the square of the weight.  It tends to result in fewer factors reduced to zero than 'L1', which uses the absolute value of the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge Model Coefficients:\n",
      "[ 0.32731261  0.15531845 -0.05028167  0.10058787  0.17424164  0.01772567\n",
      "  0.03317449  0.06574799]\n",
      "Mean Squared Error:\n",
      "0.00859069788912\n",
      "R-Squared:\n",
      "0.753592211425\n",
      "Explained Variance Score:\n",
      "0.753592211425\n",
      "Median Absolute Error:\n",
      "0.0527039053157\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "model_rg = Ridge() #ridge with default alpha\n",
    "model_rg.fit(X_train, y_train)\n",
    "print(model_rg) #shows parameters and their default values\n",
    "expected_rg = y_train\n",
    "predicted_rg = model_rg.predict(X_train)\n",
    "print(\"Ridge Model Coefficients:\")\n",
    "print(model_rg.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_rg,predicted_rg))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_rg,predicted_rg))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_rg,predicted_rg))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_rg,predicted_rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default value of alpha = 1, the mean squared error in this case was 0.00859, the median absolute error 0.0527, and the R-squared was 0.754.  None of the parameters was reduced to zero.  Now let's do the grid search and see what the optimum value of alpha is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'alpha': 0.5}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043746</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.639881</td>\n",
       "      <td>0.787519</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.743137</td>\n",
       "      <td>0.781925</td>\n",
       "      <td>0.603231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853175</td>\n",
       "      <td>0.755693</td>\n",
       "      <td>0.750763</td>\n",
       "      <td>0.775470</td>\n",
       "      <td>0.244342</td>\n",
       "      <td>0.826911</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.210140</td>\n",
       "      <td>0.023844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.643034</td>\n",
       "      <td>0.787232</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743019</td>\n",
       "      <td>0.781584</td>\n",
       "      <td>0.615152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844560</td>\n",
       "      <td>0.755470</td>\n",
       "      <td>0.756771</td>\n",
       "      <td>0.775156</td>\n",
       "      <td>0.250518</td>\n",
       "      <td>0.826706</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.206433</td>\n",
       "      <td>0.023854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645995</td>\n",
       "      <td>0.786438</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.742351</td>\n",
       "      <td>0.780642</td>\n",
       "      <td>0.627211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833950</td>\n",
       "      <td>0.754862</td>\n",
       "      <td>0.763169</td>\n",
       "      <td>0.774275</td>\n",
       "      <td>0.257754</td>\n",
       "      <td>0.826128</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202127</td>\n",
       "      <td>0.023878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.650720</td>\n",
       "      <td>0.772327</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727337</td>\n",
       "      <td>0.763925</td>\n",
       "      <td>0.665886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761842</td>\n",
       "      <td>0.744650</td>\n",
       "      <td>0.787627</td>\n",
       "      <td>0.758034</td>\n",
       "      <td>0.304351</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.175055</td>\n",
       "      <td>0.024125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642642</td>\n",
       "      <td>0.751078</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.703032</td>\n",
       "      <td>0.738967</td>\n",
       "      <td>0.665105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699622</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>0.789490</td>\n",
       "      <td>0.733141</td>\n",
       "      <td>0.350044</td>\n",
       "      <td>0.796046</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149453</td>\n",
       "      <td>0.024441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622714</td>\n",
       "      <td>0.713961</td>\n",
       "      <td>2</td>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.658374</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.636198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622411</td>\n",
       "      <td>0.703175</td>\n",
       "      <td>0.769750</td>\n",
       "      <td>0.690333</td>\n",
       "      <td>0.423329</td>\n",
       "      <td>0.759952</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.025073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604523</td>\n",
       "      <td>0.683410</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.620485</td>\n",
       "      <td>0.661984</td>\n",
       "      <td>0.604914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573365</td>\n",
       "      <td>0.680118</td>\n",
       "      <td>0.743766</td>\n",
       "      <td>0.656240</td>\n",
       "      <td>0.478914</td>\n",
       "      <td>0.727885</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084141</td>\n",
       "      <td>0.025460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587722</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>4</td>\n",
       "      <td>{'alpha': 4}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.587584</td>\n",
       "      <td>0.633102</td>\n",
       "      <td>0.576828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537249</td>\n",
       "      <td>0.659142</td>\n",
       "      <td>0.717579</td>\n",
       "      <td>0.627533</td>\n",
       "      <td>0.520160</td>\n",
       "      <td>0.698866</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068458</td>\n",
       "      <td>0.025610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571748</td>\n",
       "      <td>0.633203</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.558398</td>\n",
       "      <td>0.607742</td>\n",
       "      <td>0.552002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508304</td>\n",
       "      <td>0.639571</td>\n",
       "      <td>0.692384</td>\n",
       "      <td>0.602335</td>\n",
       "      <td>0.550016</td>\n",
       "      <td>0.672167</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061827</td>\n",
       "      <td>0.025616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.556346</td>\n",
       "      <td>0.611456</td>\n",
       "      <td>6</td>\n",
       "      <td>{'alpha': 6}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.532132</td>\n",
       "      <td>0.584920</td>\n",
       "      <td>0.529890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483879</td>\n",
       "      <td>0.621091</td>\n",
       "      <td>0.668455</td>\n",
       "      <td>0.579647</td>\n",
       "      <td>0.570991</td>\n",
       "      <td>0.647374</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.061438</td>\n",
       "      <td>0.025544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.541424</td>\n",
       "      <td>0.591299</td>\n",
       "      <td>7</td>\n",
       "      <td>{'alpha': 7}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.508257</td>\n",
       "      <td>0.564064</td>\n",
       "      <td>0.509980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462574</td>\n",
       "      <td>0.603540</td>\n",
       "      <td>0.645830</td>\n",
       "      <td>0.558900</td>\n",
       "      <td>0.585097</td>\n",
       "      <td>0.624232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.025436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526962</td>\n",
       "      <td>0.572476</td>\n",
       "      <td>8</td>\n",
       "      <td>{'alpha': 8}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.486396</td>\n",
       "      <td>0.544813</td>\n",
       "      <td>0.491869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443576</td>\n",
       "      <td>0.586826</td>\n",
       "      <td>0.624470</td>\n",
       "      <td>0.539738</td>\n",
       "      <td>0.593901</td>\n",
       "      <td>0.602565</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068348</td>\n",
       "      <td>0.025310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.512959</td>\n",
       "      <td>0.554816</td>\n",
       "      <td>9</td>\n",
       "      <td>{'alpha': 9}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.466268</td>\n",
       "      <td>0.526923</td>\n",
       "      <td>0.475255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426375</td>\n",
       "      <td>0.570887</td>\n",
       "      <td>0.604312</td>\n",
       "      <td>0.521921</td>\n",
       "      <td>0.598613</td>\n",
       "      <td>0.582234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.025177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499423</td>\n",
       "      <td>0.538191</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>14</td>\n",
       "      <td>0.447652</td>\n",
       "      <td>0.510215</td>\n",
       "      <td>0.459908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410629</td>\n",
       "      <td>0.555675</td>\n",
       "      <td>0.585282</td>\n",
       "      <td>0.505276</td>\n",
       "      <td>0.600166</td>\n",
       "      <td>0.563127</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076313</td>\n",
       "      <td>0.025039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.438769</td>\n",
       "      <td>0.467636</td>\n",
       "      <td>15</td>\n",
       "      <td>{'alpha': 15}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.371941</td>\n",
       "      <td>0.440460</td>\n",
       "      <td>0.397086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347118</td>\n",
       "      <td>0.489212</td>\n",
       "      <td>0.504589</td>\n",
       "      <td>0.435755</td>\n",
       "      <td>0.580860</td>\n",
       "      <td>0.482816</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>0.087715</td>\n",
       "      <td>0.024283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388919</td>\n",
       "      <td>0.412897</td>\n",
       "      <td>20</td>\n",
       "      <td>{'alpha': 20}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.316392</td>\n",
       "      <td>0.387308</td>\n",
       "      <td>0.349909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300119</td>\n",
       "      <td>0.435877</td>\n",
       "      <td>0.442540</td>\n",
       "      <td>0.382805</td>\n",
       "      <td>0.543602</td>\n",
       "      <td>0.421732</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090320</td>\n",
       "      <td>0.023392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.043746         0.003126         0.639881          0.787519   \n",
       "1        0.006250         0.003125         0.643034          0.787232   \n",
       "2        0.015624         0.000000         0.645995          0.786438   \n",
       "3        0.006250         0.003125         0.650720          0.772327   \n",
       "4        0.009377         0.000000         0.642642          0.751078   \n",
       "5        0.003124         0.000000         0.622714          0.713961   \n",
       "6        0.006250         0.000000         0.604523          0.683410   \n",
       "7        0.012500         0.000000         0.587722          0.656947   \n",
       "8        0.003124         0.000000         0.571748          0.633203   \n",
       "9        0.006251         0.003126         0.556346          0.611456   \n",
       "10       0.000000         0.009375         0.541424          0.591299   \n",
       "11       0.003124         0.000000         0.526962          0.572476   \n",
       "12       0.000000         0.003129         0.512959          0.554816   \n",
       "13       0.006250         0.000000         0.499423          0.538191   \n",
       "14       0.003125         0.003122         0.438769          0.467636   \n",
       "15       0.003125         0.000000         0.388919          0.412897   \n",
       "\n",
       "   param_alpha           params  rank_test_score  split0_test_score  \\\n",
       "0         0.01  {'alpha': 0.01}                5           0.743137   \n",
       "1         0.05  {'alpha': 0.05}                3           0.743019   \n",
       "2          0.1   {'alpha': 0.1}                2           0.742351   \n",
       "3          0.5   {'alpha': 0.5}                1           0.727337   \n",
       "4            1     {'alpha': 1}                4           0.703032   \n",
       "5            2     {'alpha': 2}                6           0.658374   \n",
       "6            3     {'alpha': 3}                7           0.620485   \n",
       "7            4     {'alpha': 4}                8           0.587584   \n",
       "8            5     {'alpha': 5}                9           0.558398   \n",
       "9            6     {'alpha': 6}               10           0.532132   \n",
       "10           7     {'alpha': 7}               11           0.508257   \n",
       "11           8     {'alpha': 8}               12           0.486396   \n",
       "12           9     {'alpha': 9}               13           0.466268   \n",
       "13          10    {'alpha': 10}               14           0.447652   \n",
       "14          15    {'alpha': 15}               15           0.371941   \n",
       "15          20    {'alpha': 20}               16           0.316392   \n",
       "\n",
       "    split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0             0.781925           0.603231       ...                  0.853175   \n",
       "1             0.781584           0.615152       ...                  0.844560   \n",
       "2             0.780642           0.627211       ...                  0.833950   \n",
       "3             0.763925           0.665886       ...                  0.761842   \n",
       "4             0.738967           0.665105       ...                  0.699622   \n",
       "5             0.696203           0.636198       ...                  0.622411   \n",
       "6             0.661984           0.604914       ...                  0.573365   \n",
       "7             0.633102           0.576828       ...                  0.537249   \n",
       "8             0.607742           0.552002       ...                  0.508304   \n",
       "9             0.584920           0.529890       ...                  0.483879   \n",
       "10            0.564064           0.509980       ...                  0.462574   \n",
       "11            0.544813           0.491869       ...                  0.443576   \n",
       "12            0.526923           0.475255       ...                  0.426375   \n",
       "13            0.510215           0.459908       ...                  0.410629   \n",
       "14            0.440460           0.397086       ...                  0.347118   \n",
       "15            0.387308           0.349909       ...                  0.300119   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.755693           0.750763            0.775470   \n",
       "1             0.755470           0.756771            0.775156   \n",
       "2             0.754862           0.763169            0.774275   \n",
       "3             0.744650           0.787627            0.758034   \n",
       "4             0.729743           0.789490            0.733141   \n",
       "5             0.703175           0.769750            0.690333   \n",
       "6             0.680118           0.743766            0.656240   \n",
       "7             0.659142           0.717579            0.627533   \n",
       "8             0.639571           0.692384            0.602335   \n",
       "9             0.621091           0.668455            0.579647   \n",
       "10            0.603540           0.645830            0.558900   \n",
       "11            0.586826           0.624470            0.539738   \n",
       "12            0.570887           0.604312            0.521921   \n",
       "13            0.555675           0.585282            0.505276   \n",
       "14            0.489212           0.504589            0.435755   \n",
       "15            0.435877           0.442540            0.382805   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.244342            0.826911      0.025003        0.006252   \n",
       "1            0.250518            0.826706      0.007655        0.006250   \n",
       "2            0.257754            0.826128      0.024206        0.000000   \n",
       "3            0.304351            0.814839      0.007654        0.006250   \n",
       "4            0.350044            0.796046      0.007656        0.000000   \n",
       "5            0.423329            0.759952      0.006249        0.000000   \n",
       "6            0.478914            0.727885      0.007655        0.000000   \n",
       "7            0.520160            0.698866      0.018221        0.000000   \n",
       "8            0.550016            0.672167      0.006248        0.000000   \n",
       "9            0.570991            0.647374      0.007656        0.006252   \n",
       "10           0.585097            0.624232      0.000000        0.007654   \n",
       "11           0.593901            0.602565      0.006249        0.000000   \n",
       "12           0.598613            0.582234      0.000000        0.006258   \n",
       "13           0.600166            0.563127      0.007654        0.000000   \n",
       "14           0.580860            0.482816      0.006250        0.006244   \n",
       "15           0.543602            0.421732      0.006250        0.000000   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.210140         0.023844  \n",
       "1         0.206433         0.023854  \n",
       "2         0.202127         0.023878  \n",
       "3         0.175055         0.024125  \n",
       "4         0.149453         0.024441  \n",
       "5         0.110619         0.025073  \n",
       "6         0.084141         0.025460  \n",
       "7         0.068458         0.025610  \n",
       "8         0.061827         0.025616  \n",
       "9         0.061438         0.025544  \n",
       "10        0.064300         0.025436  \n",
       "11        0.068348         0.025310  \n",
       "12        0.072507         0.025177  \n",
       "13        0.076313         0.025039  \n",
       "14        0.087715         0.024283  \n",
       "15        0.090320         0.023392  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [.01,.05,.1,.5, 1, 2,3,4,5,6,7,8,9,10,15,20]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_rg, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search data computes alpha=0.5 as the best result.  Let's put that into the Ridge model and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge Model Coefficients:\n",
      "[ 0.38386064  0.18404992 -0.07692148  0.10423687  0.1784481  -0.01365929\n",
      "  0.02661234  0.07787221]\n",
      "Mean Squared Error:\n",
      "0.00801957992442\n",
      "R-Squared:\n",
      "0.769973641259\n",
      "Explained Variance Score:\n",
      "0.769973641259\n",
      "Median Absolute Error:\n",
      "0.0536551782714\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "model_rg_al = Ridge(alpha=0.5)\n",
    "model_rg_al.fit(X_train, y_train)\n",
    "print(model_rg_al) #shows parameters and their default values\n",
    "expected_rg = y_train\n",
    "predicted_rg = model_rg_al.predict(X_train)\n",
    "print(\"Ridge Model Coefficients:\")\n",
    "print(model_rg_al.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_rg,predicted_rg))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_rg,predicted_rg))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_rg,predicted_rg))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_rg,predicted_rg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting Ridge model has a mean squared error of 0.00802, a median absolute error of 0.0536, and the R-squared was 0.770, which is slightly more accurate than the default setting of alpha=1.  Again, the alpha didn't reduce any of the factors to zero, so this model still has 8 variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LASSO Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the LASSO Regression, which like the Ridge has a penalty incorporated (alpha), so we'll start with the default value and then use a grid search to find the optimum value.  Unlike the Ridge Regression, it uses 'L1' for its penalty (alpha), which penalizes based on the absolute value of the weight, typically resulting in more factors being reduced to zero.  Thus, it can be useful to reduce a large number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "LASSO Model Coefficients:\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Mean Squared Error:\n",
      "0.0348637433045\n",
      "R-Squared:\n",
      "0.0\n",
      "Explained Variance Score:\n",
      "2.22044604925e-16\n",
      "Median Absolute Error:\n",
      "0.113175264987\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "# fit a LASSO model to the data\n",
    "from sklearn.linear_model import Lasso\n",
    "model_ls = Lasso() #LASSO with default vaues\n",
    "model_ls.fit(X_train, y_train)\n",
    "print(model_ls) #shows model parameters\n",
    "# make predictions\n",
    "expected_ls = y_train\n",
    "predicted_ls = model_ls.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"LASSO Model Coefficients:\")\n",
    "print(model_ls.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_ls,predicted_ls))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_ls,predicted_ls))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_ls,predicted_ls))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_ls,predicted_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default setting for the alpha (1) reduced all of the factors to zero!  The mean squared error in this case was 0.0348 and the R-squared was 0.0, but those don't have any effective meaning here.   Now let's do the grid search and see what the optimum value of alpha is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'alpha': 0.001}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638987</td>\n",
       "      <td>0.787532</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743111</td>\n",
       "      <td>0.781940</td>\n",
       "      <td>0.599974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855276</td>\n",
       "      <td>0.755704</td>\n",
       "      <td>0.749139</td>\n",
       "      <td>0.775484</td>\n",
       "      <td>0.242785</td>\n",
       "      <td>0.826920</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.023843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639296</td>\n",
       "      <td>0.787531</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743213</td>\n",
       "      <td>0.781939</td>\n",
       "      <td>0.600938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854734</td>\n",
       "      <td>0.755703</td>\n",
       "      <td>0.749291</td>\n",
       "      <td>0.775483</td>\n",
       "      <td>0.243622</td>\n",
       "      <td>0.826919</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210655</td>\n",
       "      <td>0.023843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642287</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.744130</td>\n",
       "      <td>0.781804</td>\n",
       "      <td>0.610674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849054</td>\n",
       "      <td>0.755594</td>\n",
       "      <td>0.750742</td>\n",
       "      <td>0.775397</td>\n",
       "      <td>0.251820</td>\n",
       "      <td>0.826837</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206434</td>\n",
       "      <td>0.023850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.657714</td>\n",
       "      <td>0.778411</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740214</td>\n",
       "      <td>0.769695</td>\n",
       "      <td>0.660693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802968</td>\n",
       "      <td>0.749679</td>\n",
       "      <td>0.761192</td>\n",
       "      <td>0.766751</td>\n",
       "      <td>0.317395</td>\n",
       "      <td>0.818622</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.173564</td>\n",
       "      <td>0.023382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578790</td>\n",
       "      <td>0.660786</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.591794</td>\n",
       "      <td>0.629251</td>\n",
       "      <td>0.518201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580317</td>\n",
       "      <td>0.652739</td>\n",
       "      <td>0.686740</td>\n",
       "      <td>0.634863</td>\n",
       "      <td>0.520297</td>\n",
       "      <td>0.709655</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061087</td>\n",
       "      <td>0.029652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352107</td>\n",
       "      <td>0.428180</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.307680</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.276227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273500</td>\n",
       "      <td>0.419538</td>\n",
       "      <td>0.448575</td>\n",
       "      <td>0.396148</td>\n",
       "      <td>0.463149</td>\n",
       "      <td>0.495804</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083781</td>\n",
       "      <td>0.058931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'alpha': 0.4}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'alpha': 0.6}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0.7}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 0.9}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.012500         0.000000         0.638987          0.787532   \n",
       "1        0.009376         0.000000         0.639296          0.787531   \n",
       "2        0.003125         0.000000         0.642287          0.787424   \n",
       "3        0.003125         0.003124         0.657714          0.778411   \n",
       "4        0.003125         0.000000         0.578790          0.660786   \n",
       "5        0.006250         0.000000         0.352107          0.428180   \n",
       "6        0.006250         0.000000        -0.021704          0.000000   \n",
       "7        0.003125         0.003126        -0.021704          0.000000   \n",
       "8        0.006252         0.000000        -0.021704          0.000000   \n",
       "9        0.009375         0.000000        -0.021704          0.000000   \n",
       "10       0.003125         0.000000        -0.021704          0.000000   \n",
       "11       0.006251         0.000000        -0.021704          0.000000   \n",
       "12       0.009375         0.003125        -0.021704          0.000000   \n",
       "13       0.003125         0.003125        -0.021704          0.000000   \n",
       "14       0.000000         0.003124        -0.021704          0.000000   \n",
       "15       0.003125         0.000000        -0.021704          0.000000   \n",
       "16       0.009376         0.000000        -0.021704          0.000000   \n",
       "\n",
       "   param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0        1e-06   {'alpha': 1e-06}                4           0.743111   \n",
       "1        1e-05   {'alpha': 1e-05}                3           0.743213   \n",
       "2       0.0001  {'alpha': 0.0001}                2           0.744130   \n",
       "3        0.001   {'alpha': 0.001}                1           0.740214   \n",
       "4         0.01    {'alpha': 0.01}                5           0.591794   \n",
       "5         0.02    {'alpha': 0.02}                6           0.307680   \n",
       "6         0.05    {'alpha': 0.05}                7          -0.047905   \n",
       "7          0.1     {'alpha': 0.1}                7          -0.047905   \n",
       "8          0.2     {'alpha': 0.2}                7          -0.047905   \n",
       "9          0.3     {'alpha': 0.3}                7          -0.047905   \n",
       "10         0.4     {'alpha': 0.4}                7          -0.047905   \n",
       "11         0.5     {'alpha': 0.5}                7          -0.047905   \n",
       "12         0.6     {'alpha': 0.6}                7          -0.047905   \n",
       "13         0.7     {'alpha': 0.7}                7          -0.047905   \n",
       "14         0.8     {'alpha': 0.8}                7          -0.047905   \n",
       "15         0.9     {'alpha': 0.9}                7          -0.047905   \n",
       "16           1       {'alpha': 1}                7          -0.047905   \n",
       "\n",
       "    split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0             0.781940           0.599974       ...                  0.855276   \n",
       "1             0.781939           0.600938       ...                  0.854734   \n",
       "2             0.781804           0.610674       ...                  0.849054   \n",
       "3             0.769695           0.660693       ...                  0.802968   \n",
       "4             0.629251           0.518201       ...                  0.580317   \n",
       "5             0.339448           0.276227       ...                  0.273500   \n",
       "6             0.000000          -0.005272       ...                 -0.039230   \n",
       "7             0.000000          -0.005272       ...                 -0.039230   \n",
       "8             0.000000          -0.005272       ...                 -0.039230   \n",
       "9             0.000000          -0.005272       ...                 -0.039230   \n",
       "10            0.000000          -0.005272       ...                 -0.039230   \n",
       "11            0.000000          -0.005272       ...                 -0.039230   \n",
       "12            0.000000          -0.005272       ...                 -0.039230   \n",
       "13            0.000000          -0.005272       ...                 -0.039230   \n",
       "14            0.000000          -0.005272       ...                 -0.039230   \n",
       "15            0.000000          -0.005272       ...                 -0.039230   \n",
       "16            0.000000          -0.005272       ...                 -0.039230   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.755704           0.749139            0.775484   \n",
       "1             0.755703           0.749291            0.775483   \n",
       "2             0.755594           0.750742            0.775397   \n",
       "3             0.749679           0.761192            0.766751   \n",
       "4             0.652739           0.686740            0.634863   \n",
       "5             0.419538           0.448575            0.396148   \n",
       "6             0.000000          -0.002761            0.000000   \n",
       "7             0.000000          -0.002761            0.000000   \n",
       "8             0.000000          -0.002761            0.000000   \n",
       "9             0.000000          -0.002761            0.000000   \n",
       "10            0.000000          -0.002761            0.000000   \n",
       "11            0.000000          -0.002761            0.000000   \n",
       "12            0.000000          -0.002761            0.000000   \n",
       "13            0.000000          -0.002761            0.000000   \n",
       "14            0.000000          -0.002761            0.000000   \n",
       "15            0.000000          -0.002761            0.000000   \n",
       "16            0.000000          -0.002761            0.000000   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.242785            0.826920      0.006250        0.000000   \n",
       "1            0.243622            0.826919      0.007655        0.000000   \n",
       "2            0.251820            0.826837      0.006251        0.000000   \n",
       "3            0.317395            0.818622      0.006249        0.006248   \n",
       "4            0.520297            0.709655      0.006251        0.000000   \n",
       "5            0.463149            0.495804      0.007655        0.000000   \n",
       "6           -0.012653            0.000000      0.007655        0.000000   \n",
       "7           -0.012653            0.000000      0.006250        0.006252   \n",
       "8           -0.012653            0.000000      0.007657        0.000000   \n",
       "9           -0.012653            0.000000      0.007655        0.000000   \n",
       "10          -0.012653            0.000000      0.006249        0.000000   \n",
       "11          -0.012653            0.000000      0.007655        0.000000   \n",
       "12          -0.012653            0.000000      0.012499        0.006250   \n",
       "13          -0.012653            0.000000      0.006250        0.006251   \n",
       "14          -0.012653            0.000000      0.000000        0.006248   \n",
       "15          -0.012653            0.000000      0.006250        0.000000   \n",
       "16          -0.012653            0.000000      0.007655        0.000000   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.211079         0.023843  \n",
       "1         0.210655         0.023843  \n",
       "2         0.206434         0.023850  \n",
       "3         0.173564         0.023382  \n",
       "4         0.061087         0.029652  \n",
       "5         0.083781         0.058931  \n",
       "6         0.018566         0.000000  \n",
       "7         0.018566         0.000000  \n",
       "8         0.018566         0.000000  \n",
       "9         0.018566         0.000000  \n",
       "10        0.018566         0.000000  \n",
       "11        0.018566         0.000000  \n",
       "12        0.018566         0.000000  \n",
       "13        0.018566         0.000000  \n",
       "14        0.018566         0.000000  \n",
       "15        0.018566         0.000000  \n",
       "16        0.018566         0.000000  \n",
       "\n",
       "[17 rows x 21 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [.000001, .00001, .0001,.001,.01,.02, .05, .1, .2, .3,.4,.5,.6,.7,.8,.9,1]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_ls, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to use much lower values of alpha in this case when hunting for the optimal solution (not surprisingly, as we saw an alpha of one reducing all terms to zero).  The grid search determined that alpha=0.001 was best.  Let's put that in the LASSO model and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "LASSO Model Coefficients:\n",
      "[ 0.43167195  0.17574678 -0.05943902  0.09817497  0.17002846 -0.00093135\n",
      "  0.          0.06759174]\n",
      "Mean Squared Error:\n",
      "0.00797137786088\n",
      "R-Squared:\n",
      "0.771356225542\n",
      "Explained Variance Score:\n",
      "0.771356225542\n",
      "Median Absolute Error:\n",
      "0.0558427969484\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression with alpha value determined by grid search\n",
    "# fit a LASSO model to the data\n",
    "from sklearn.linear_model import Lasso\n",
    "model_ls_al = Lasso(alpha=0.001) \n",
    "model_ls_al.fit(X_train, y_train)\n",
    "print(model_ls_al) #shows model parameters\n",
    "# make predictions\n",
    "expected_ls = y_train\n",
    "predicted_ls = model_ls_al.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"LASSO Model Coefficients:\")\n",
    "print(model_ls_al.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_ls,predicted_ls))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_ls,predicted_ls))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_ls,predicted_ls))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_ls,predicted_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting LASSO model has a mean squared error of 0.00797, a median absolute error of 0.0558, and a R-squared of 0.771, on par with the Ridge results.  Only one term were penalized to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the Elasitc Net Regression, which also has a penalty incorporated (alpha), so we'll start with the default value and then use a grid search to find the optimum value.  The Elasitc Net uses a combination of L1 and L2 for its penalty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Elastic Net Model Coefficients:\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Mean Squared Error:\n",
      "0.0348637433045\n",
      "R-Squared:\n",
      "0.0\n",
      "Explained Variance Score:\n",
      "2.22044604925e-16\n",
      "Median Absolute Error:\n",
      "0.113175264987\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "# fit a model to the data\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model_en = ElasticNet()\n",
    "model_en.fit(X_train, y_train)\n",
    "print(model_en)\n",
    "# make predictions\n",
    "expected_en = y_train\n",
    "predicted_en = model_en.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"Elastic Net Model Coefficients:\")\n",
    "print(model_en.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_en,predicted_en))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_en,predicted_en))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_en,predicted_en))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_en,predicted_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the LASSO, the default setting for the alpha (1) reduced all of the factors to zero!  The mean squared error in this case was 0.0349 and the R-squared was 0.0, but those don't have any effective meaning here.   Now let's do the grid search and see what the optimum value of alpha is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'alpha': 0.001}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021874</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.638983</td>\n",
       "      <td>0.787532</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743104</td>\n",
       "      <td>0.781940</td>\n",
       "      <td>0.599941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855300</td>\n",
       "      <td>0.755704</td>\n",
       "      <td>0.749135</td>\n",
       "      <td>0.775484</td>\n",
       "      <td>0.242788</td>\n",
       "      <td>0.826920</td>\n",
       "      <td>0.021196</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.211083</td>\n",
       "      <td>0.023843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.787531</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743158</td>\n",
       "      <td>0.781940</td>\n",
       "      <td>0.600473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854973</td>\n",
       "      <td>0.755703</td>\n",
       "      <td>0.749255</td>\n",
       "      <td>0.775484</td>\n",
       "      <td>0.243204</td>\n",
       "      <td>0.826919</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.210863</td>\n",
       "      <td>0.023843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.640912</td>\n",
       "      <td>0.787495</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.743645</td>\n",
       "      <td>0.781894</td>\n",
       "      <td>0.606258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851624</td>\n",
       "      <td>0.755667</td>\n",
       "      <td>0.750418</td>\n",
       "      <td>0.775453</td>\n",
       "      <td>0.247753</td>\n",
       "      <td>0.826892</td>\n",
       "      <td>0.024204</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.208494</td>\n",
       "      <td>0.023845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.653632</td>\n",
       "      <td>0.784178</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745221</td>\n",
       "      <td>0.777494</td>\n",
       "      <td>0.649743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.753104</td>\n",
       "      <td>0.759931</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.287646</td>\n",
       "      <td>0.824220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.187971</td>\n",
       "      <td>0.023825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630272</td>\n",
       "      <td>0.721911</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.668623</td>\n",
       "      <td>0.704952</td>\n",
       "      <td>0.603267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643597</td>\n",
       "      <td>0.701876</td>\n",
       "      <td>0.762569</td>\n",
       "      <td>0.703579</td>\n",
       "      <td>0.472494</td>\n",
       "      <td>0.765310</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093470</td>\n",
       "      <td>0.024701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546246</td>\n",
       "      <td>0.627126</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.547339</td>\n",
       "      <td>0.589715</td>\n",
       "      <td>0.480623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519323</td>\n",
       "      <td>0.624531</td>\n",
       "      <td>0.665045</td>\n",
       "      <td>0.595329</td>\n",
       "      <td>0.523507</td>\n",
       "      <td>0.678280</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062315</td>\n",
       "      <td>0.033047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180779</td>\n",
       "      <td>0.249695</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.107558</td>\n",
       "      <td>0.137188</td>\n",
       "      <td>0.136015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091459</td>\n",
       "      <td>0.260938</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.200980</td>\n",
       "      <td>0.323053</td>\n",
       "      <td>0.316187</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089838</td>\n",
       "      <td>0.072868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'alpha': 0.4}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'alpha': 0.6}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0.7}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 0.9}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.047905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.021874         0.006249         0.638983          0.787532   \n",
       "1        0.003126         0.003126         0.639146          0.787531   \n",
       "2        0.015623         0.003125         0.640912          0.787495   \n",
       "3        0.000000         0.006249         0.653632          0.784178   \n",
       "4        0.009374         0.000000         0.630272          0.721911   \n",
       "5        0.009376         0.000000         0.546246          0.627126   \n",
       "6        0.006251         0.000000         0.180779          0.249695   \n",
       "7        0.006250         0.000000        -0.021704          0.000000   \n",
       "8        0.000000         0.006249        -0.021704          0.000000   \n",
       "9        0.009376         0.000000        -0.021704          0.000000   \n",
       "10       0.003124         0.003125        -0.021704          0.000000   \n",
       "11       0.006250         0.000000        -0.021704          0.000000   \n",
       "12       0.003125         0.000000        -0.021704          0.000000   \n",
       "13       0.003125         0.000000        -0.021704          0.000000   \n",
       "14       0.006249         0.000000        -0.021704          0.000000   \n",
       "15       0.003125         0.006251        -0.021704          0.000000   \n",
       "16       0.003125         0.003124        -0.021704          0.000000   \n",
       "\n",
       "   param_alpha             params  rank_test_score  split0_test_score  \\\n",
       "0        1e-06   {'alpha': 1e-06}                4           0.743104   \n",
       "1        1e-05   {'alpha': 1e-05}                3           0.743158   \n",
       "2       0.0001  {'alpha': 0.0001}                2           0.743645   \n",
       "3        0.001   {'alpha': 0.001}                1           0.745221   \n",
       "4         0.01    {'alpha': 0.01}                5           0.668623   \n",
       "5         0.02    {'alpha': 0.02}                6           0.547339   \n",
       "6         0.05    {'alpha': 0.05}                7           0.107558   \n",
       "7          0.1     {'alpha': 0.1}                8          -0.047905   \n",
       "8          0.2     {'alpha': 0.2}                8          -0.047905   \n",
       "9          0.3     {'alpha': 0.3}                8          -0.047905   \n",
       "10         0.4     {'alpha': 0.4}                8          -0.047905   \n",
       "11         0.5     {'alpha': 0.5}                8          -0.047905   \n",
       "12         0.6     {'alpha': 0.6}                8          -0.047905   \n",
       "13         0.7     {'alpha': 0.7}                8          -0.047905   \n",
       "14         0.8     {'alpha': 0.8}                8          -0.047905   \n",
       "15         0.9     {'alpha': 0.9}                8          -0.047905   \n",
       "16           1       {'alpha': 1}                8          -0.047905   \n",
       "\n",
       "    split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0             0.781940           0.599941       ...                  0.855300   \n",
       "1             0.781940           0.600473       ...                  0.854973   \n",
       "2             0.781894           0.606258       ...                  0.851624   \n",
       "3             0.777494           0.649743       ...                  0.819355   \n",
       "4             0.704952           0.603267       ...                  0.643597   \n",
       "5             0.589715           0.480623       ...                  0.519323   \n",
       "6             0.137188           0.136015       ...                  0.091459   \n",
       "7             0.000000          -0.005272       ...                 -0.039230   \n",
       "8             0.000000          -0.005272       ...                 -0.039230   \n",
       "9             0.000000          -0.005272       ...                 -0.039230   \n",
       "10            0.000000          -0.005272       ...                 -0.039230   \n",
       "11            0.000000          -0.005272       ...                 -0.039230   \n",
       "12            0.000000          -0.005272       ...                 -0.039230   \n",
       "13            0.000000          -0.005272       ...                 -0.039230   \n",
       "14            0.000000          -0.005272       ...                 -0.039230   \n",
       "15            0.000000          -0.005272       ...                 -0.039230   \n",
       "16            0.000000          -0.005272       ...                 -0.039230   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.755704           0.749135            0.775484   \n",
       "1             0.755703           0.749255            0.775484   \n",
       "2             0.755667           0.750418            0.775453   \n",
       "3             0.753104           0.759931            0.772500   \n",
       "4             0.701876           0.762569            0.703579   \n",
       "5             0.624531           0.665045            0.595329   \n",
       "6             0.260938           0.254237            0.200980   \n",
       "7             0.000000          -0.002761            0.000000   \n",
       "8             0.000000          -0.002761            0.000000   \n",
       "9             0.000000          -0.002761            0.000000   \n",
       "10            0.000000          -0.002761            0.000000   \n",
       "11            0.000000          -0.002761            0.000000   \n",
       "12            0.000000          -0.002761            0.000000   \n",
       "13            0.000000          -0.002761            0.000000   \n",
       "14            0.000000          -0.002761            0.000000   \n",
       "15            0.000000          -0.002761            0.000000   \n",
       "16            0.000000          -0.002761            0.000000   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.242788            0.826920      0.021196        0.007654   \n",
       "1            0.243204            0.826919      0.006251        0.006251   \n",
       "2            0.247753            0.826892      0.024204        0.006250   \n",
       "3            0.287646            0.824220      0.000000        0.007654   \n",
       "4            0.472494            0.765310      0.007654        0.000000   \n",
       "5            0.523507            0.678280      0.007655        0.000000   \n",
       "6            0.323053            0.316187      0.007655        0.000000   \n",
       "7           -0.012653            0.000000      0.007655        0.000000   \n",
       "8           -0.012653            0.000000      0.000000        0.007654   \n",
       "9           -0.012653            0.000000      0.007656        0.000000   \n",
       "10          -0.012653            0.000000      0.006249        0.006249   \n",
       "11          -0.012653            0.000000      0.007655        0.000000   \n",
       "12          -0.012653            0.000000      0.006251        0.000000   \n",
       "13          -0.012653            0.000000      0.006249        0.000000   \n",
       "14          -0.012653            0.000000      0.007654        0.000000   \n",
       "15          -0.012653            0.000000      0.006250        0.007655   \n",
       "16          -0.012653            0.000000      0.006251        0.006248   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.211083         0.023843  \n",
       "1         0.210863         0.023843  \n",
       "2         0.208494         0.023845  \n",
       "3         0.187971         0.023825  \n",
       "4         0.093470         0.024701  \n",
       "5         0.062315         0.033047  \n",
       "6         0.089838         0.072868  \n",
       "7         0.018566         0.000000  \n",
       "8         0.018566         0.000000  \n",
       "9         0.018566         0.000000  \n",
       "10        0.018566         0.000000  \n",
       "11        0.018566         0.000000  \n",
       "12        0.018566         0.000000  \n",
       "13        0.018566         0.000000  \n",
       "14        0.018566         0.000000  \n",
       "15        0.018566         0.000000  \n",
       "16        0.018566         0.000000  \n",
       "\n",
       "[17 rows x 21 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [.000001, .00001, .0001,.001,.01,.02, .05, .1, .2, .3,.4,.5,.6,.7,.8,.9,1]}\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_en, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to LASSO, I had to use much lower values of alpha in this case when hunting for the optimal solution (not surprisingly, as we saw an alpha of one reducing all terms to zero).  The grid search determined that alpha=0.001 was best.  Let's put that in the Elastic Net model and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Elastic Net Model Coefficients:\n",
      "[  4.47467325e-01   1.99466961e-01  -8.85351556e-02   1.02795939e-01\n",
      "   1.75494079e-01  -3.23424897e-02   1.61504668e-04   8.94991416e-02]\n",
      "Mean Squared Error:\n",
      "0.0077638444699\n",
      "R-Squared:\n",
      "0.777308925146\n",
      "Explained Variance Score:\n",
      "0.777308925146\n",
      "Median Absolute Error:\n",
      "0.0514926334665\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression\n",
    "# fit a model to the data\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model_en_al = ElasticNet(alpha=0.001)\n",
    "model_en_al.fit(X_train, y_train)\n",
    "print(model_en_al)\n",
    "# make predictions\n",
    "expected_en = y_train\n",
    "predicted_en = model_en_al.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"Elastic Net Model Coefficients:\")\n",
    "print(model_en_al.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_en,predicted_en))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_en,predicted_en))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_en,predicted_en))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_en,predicted_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting Elastic Net model has a mean squared error of 0.00776, a median absolute error of 0.0515, and a R-squared of 0.777, slightly better than the Ridge and LASSO results.  No terms were penalized to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LARS (Least Angle Regression) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at the LARS, which conducts the regression in steps by finding the column most closely correlated with the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lars(copy_X=True, eps=2.2204460492503131e-16, fit_intercept=True,\n",
      "   fit_path=True, n_nonzero_coefs=500, normalize=True, positive=False,\n",
      "   precompute='auto', verbose=False)\n",
      "LARS intercept:\n",
      "0.0981914852983\n",
      "LARS Coefficients:\n",
      "[ 0.47606464  0.23312088 -0.12713002  0.10808687  0.18188083 -0.07502736\n",
      "  0.0105249   0.10966399]\n",
      "Mean Squared Error:\n",
      "0.00765717158932\n",
      "R-Squared:\n",
      "0.780368633327\n",
      "Explained Variance Score:\n",
      "0.780368633327\n",
      "Median Absolute Error:\n",
      "0.0621096254695\n"
     ]
    }
   ],
   "source": [
    "#LARS Regression Model- Least Angle Regression model\n",
    "from sklearn import linear_model\n",
    "model_LAR = linear_model.Lars() #default numer of n_nonzero_coefs\n",
    "model_LAR.fit(X_train, y_train)\n",
    "print(model_LAR)\n",
    "# make predictions\n",
    "expected_LAR = y_train\n",
    "predicted_LAR = model_LAR.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "#mse_LAR = np.mean((predicted_LAR-expected_LAR)**2)\n",
    "print(\"LARS intercept:\")\n",
    "print(model_LAR.intercept_)\n",
    "print(\"LARS Coefficients:\")\n",
    "print(model_LAR.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_LAR,predicted_LAR))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_LAR,predicted_LAR))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_LAR,predicted_LAR))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_LAR,predicted_LAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LARS produce a mean squared error of 0.00766, a median absolute error of 0.0621, and a R squared of 0.78.  The default number of remaining values (the paremeter is called \"n nonzero coefficients\") is 500 in the LARS, so the model used all 8 parameters.  Let's use a grid serach to find the optimal number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best {'n_nonzero_coefs': 6}\n",
      "Grid Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_nonzero_coefs</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.084377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318160</td>\n",
       "      <td>0.343187</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_nonzero_coefs': 1}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.338821</td>\n",
       "      <td>0.426984</td>\n",
       "      <td>0.291814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243542</td>\n",
       "      <td>0.202645</td>\n",
       "      <td>0.409598</td>\n",
       "      <td>0.483104</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.305332</td>\n",
       "      <td>0.071673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054445</td>\n",
       "      <td>0.099837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468678</td>\n",
       "      <td>0.516809</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_nonzero_coefs': 2}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.396901</td>\n",
       "      <td>0.475411</td>\n",
       "      <td>0.443795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535367</td>\n",
       "      <td>0.507454</td>\n",
       "      <td>0.451454</td>\n",
       "      <td>0.516573</td>\n",
       "      <td>0.522779</td>\n",
       "      <td>0.528935</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051903</td>\n",
       "      <td>0.026301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.594725</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_nonzero_coefs': 3}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.552042</td>\n",
       "      <td>0.611894</td>\n",
       "      <td>0.550099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646112</td>\n",
       "      <td>0.598344</td>\n",
       "      <td>0.624683</td>\n",
       "      <td>0.659918</td>\n",
       "      <td>0.606928</td>\n",
       "      <td>0.657574</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.038876</td>\n",
       "      <td>0.042020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615940</td>\n",
       "      <td>0.684403</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_nonzero_coefs': 4}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.577946</td>\n",
       "      <td>0.636387</td>\n",
       "      <td>0.555011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.641128</td>\n",
       "      <td>0.671313</td>\n",
       "      <td>0.597628</td>\n",
       "      <td>0.720835</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056328</td>\n",
       "      <td>0.032658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.666325</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_nonzero_coefs': 5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.714050</td>\n",
       "      <td>0.751312</td>\n",
       "      <td>0.633416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788818</td>\n",
       "      <td>0.734298</td>\n",
       "      <td>0.745440</td>\n",
       "      <td>0.738677</td>\n",
       "      <td>0.448841</td>\n",
       "      <td>0.799491</td>\n",
       "      <td>0.022966</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.118456</td>\n",
       "      <td>0.023658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.768025</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_nonzero_coefs': 6}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738737</td>\n",
       "      <td>0.769889</td>\n",
       "      <td>0.657851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797412</td>\n",
       "      <td>0.743556</td>\n",
       "      <td>0.749136</td>\n",
       "      <td>0.747032</td>\n",
       "      <td>0.443967</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.123530</td>\n",
       "      <td>0.021011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660952</td>\n",
       "      <td>0.782385</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_nonzero_coefs': 7}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745935</td>\n",
       "      <td>0.777044</td>\n",
       "      <td>0.644222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832077</td>\n",
       "      <td>0.754187</td>\n",
       "      <td>0.750283</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.327371</td>\n",
       "      <td>0.819284</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.022658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638962</td>\n",
       "      <td>0.787532</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_nonzero_coefs': 8}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743097</td>\n",
       "      <td>0.781940</td>\n",
       "      <td>0.599874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855335</td>\n",
       "      <td>0.755704</td>\n",
       "      <td>0.749122</td>\n",
       "      <td>0.775484</td>\n",
       "      <td>0.242736</td>\n",
       "      <td>0.826920</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211110</td>\n",
       "      <td>0.023843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.084377         0.000000         0.318160          0.343187   \n",
       "1       0.006251         0.000000         0.468678          0.516809   \n",
       "2       0.009375         0.006250         0.594725          0.649047   \n",
       "3       0.006251         0.000000         0.615940          0.684403   \n",
       "4       0.018752         0.003125         0.666325          0.758333   \n",
       "5       0.003125         0.006251         0.678000          0.768025   \n",
       "6       0.015625         0.000000         0.660952          0.782385   \n",
       "7       0.012500         0.000000         0.638962          0.787532   \n",
       "\n",
       "  param_n_nonzero_coefs                  params  rank_test_score  \\\n",
       "0                     1  {'n_nonzero_coefs': 1}                8   \n",
       "1                     2  {'n_nonzero_coefs': 2}                7   \n",
       "2                     3  {'n_nonzero_coefs': 3}                6   \n",
       "3                     4  {'n_nonzero_coefs': 4}                5   \n",
       "4                     5  {'n_nonzero_coefs': 5}                2   \n",
       "5                     6  {'n_nonzero_coefs': 6}                1   \n",
       "6                     7  {'n_nonzero_coefs': 7}                3   \n",
       "7                     8  {'n_nonzero_coefs': 8}                4   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.338821            0.426984           0.291814       ...          \n",
       "1           0.396901            0.475411           0.443795       ...          \n",
       "2           0.552042            0.611894           0.550099       ...          \n",
       "3           0.577946            0.636387           0.555011       ...          \n",
       "4           0.714050            0.751312           0.633416       ...          \n",
       "5           0.738737            0.769889           0.657851       ...          \n",
       "6           0.745935            0.777044           0.644222       ...          \n",
       "7           0.743097            0.781940           0.599874       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.243542            0.202645           0.409598   \n",
       "1           0.535367            0.507454           0.451454   \n",
       "2           0.646112            0.598344           0.624683   \n",
       "3           0.715054            0.672000           0.641128   \n",
       "4           0.788818            0.734298           0.745440   \n",
       "5           0.797412            0.743556           0.749136   \n",
       "6           0.832077            0.754187           0.750283   \n",
       "7           0.855335            0.755704           0.749122   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.483104           0.307431            0.305332      0.071673   \n",
       "1            0.516573           0.522779            0.528935      0.007656   \n",
       "2            0.659918           0.606928            0.657574      0.007655   \n",
       "3            0.671313           0.597628            0.720835      0.007655   \n",
       "4            0.738677           0.448841            0.799491      0.022966   \n",
       "5            0.747032           0.443967            0.800169      0.006250   \n",
       "6            0.766990           0.327371            0.819284      0.017117   \n",
       "7            0.775484           0.242736            0.826920      0.011692   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000000        0.054445         0.099837  \n",
       "1        0.000000        0.051903         0.026301  \n",
       "2        0.012500        0.038876         0.042020  \n",
       "3        0.000000        0.056328         0.032658  \n",
       "4        0.006250        0.118456         0.023658  \n",
       "5        0.012501        0.123530         0.021011  \n",
       "6        0.000000        0.174487         0.022658  \n",
       "7        0.000000        0.211110         0.023843  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a full grid over several parameters and cross validate 5 times\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"n_nonzero_coefs\": [1,2,3,4,5,6,7,8,]}\n",
    "#param_grid={\"alpha\": [0,10,1]} #this does a range 1 through 10 changes by a factor of 1. \n",
    "#param_grid={\"alpha\": [.01,1,.05]} #this does a range 1 through 1 changes by a factor of .05\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model_LAR, param_grid=param_grid,n_jobs=-1,cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best\", grid_search.best_params_) \n",
    "print(\"Grid Scores:\")\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The grid serach determined that 6 nonzero coefficients is the best answer.  Let's put that number into the LARS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lars(copy_X=True, eps=2.2204460492503131e-16, fit_intercept=True,\n",
      "   fit_path=True, n_nonzero_coefs=6, normalize=True, positive=False,\n",
      "   precompute='auto', verbose=False)\n",
      "LARS intercept:\n",
      "0.104007351457\n",
      "LARS Coefficients:\n",
      "[ 0.43500287  0.2037187  -0.06765826  0.09094705  0.1632417   0.          0.\n",
      "  0.06788898]\n",
      "Mean Squared Error:\n",
      "0.00794167265944\n",
      "R-Squared:\n",
      "0.772208262605\n",
      "Explained Variance Score:\n",
      "0.772208262605\n",
      "Median Absolute Error:\n",
      "0.0523219153454\n"
     ]
    }
   ],
   "source": [
    "#LARS Regression Model- Least Angle Regression model\n",
    "from sklearn import linear_model\n",
    "model_LAR_cf = linear_model.Lars(n_nonzero_coefs=6)\n",
    "model_LAR_cf.fit(X_train, y_train)\n",
    "print(model_LAR_cf)\n",
    "# make predictions\n",
    "expected_LAR = y_train\n",
    "predicted_LAR = model_LAR_cf.predict(X_train)\n",
    "# summarize the fit of the model\n",
    "print(\"LARS intercept:\")\n",
    "print(model_LAR_cf.intercept_)\n",
    "print(\"LARS Coefficients:\")\n",
    "print(model_LAR_cf.coef_)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(mean_squared_error(expected_LAR,predicted_LAR))\n",
    "print(\"R-Squared:\")\n",
    "print(r2_score(expected_LAR,predicted_LAR))\n",
    "print(\"Explained Variance Score:\")\n",
    "print(explained_variance_score(expected_LAR,predicted_LAR))\n",
    "print(\"Median Absolute Error:\") \n",
    "print(median_absolute_error(expected_LAR,predicted_LAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LARS has a mean squared error of 0.0079, a median absolute error of 0.0523, and an R-squared of 0.772.  R Squared and MSE were slightly worse with the new number of coefficients, median absolute error slighly better.  Overall, these results are on par with the other results seen so far.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to conduct a cross validation on the Elastic net model with the alpha=0.001 as found during the grid search.    Cross validation is a process where we take a subset of the data (in this case, 33% of it) and a this data is compared to a model generated by the remaining data (in this case, 67% of it).  This process is repeated for a total of 3 times (in our example), with each run using a different 33% of the data.  I used three fold cross validation as this is a very small dataset and larger numbers would produce wide variation in results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.69964072  0.75578668  0.28330527]\n",
      "Mean Cross Validation Score 0.579577558105\n"
     ]
    }
   ],
   "source": [
    "#verify Ridge with Cross Validation\n",
    "scores = cross_val_score(model_en_al, X_train, y_train, cv=3)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print(\"Mean Cross Validation Score\", scores.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation revealed a wide range of scores from 0.284 to 0.756.  This suggests the model is overfit, but the small size of the dataset may also be playing a role.  Since the LASSO results were similar, we'll run a Cross Validation on the LASSO as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.70223651  0.76106091  0.29958882]\n",
      "Mean Cross Validation Score 0.587628748631\n"
     ]
    }
   ],
   "source": [
    "#verify LASSO with Cross Validation\n",
    "scores = cross_val_score(model_ls_al, X_train, y_train, cv=3)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "print(\"Mean Cross Validation Score\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LASSO cross validation results also show a significant spread, from 0.3 to 0.761, about the same as the Elastic Net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Mean Squared Error, Median Absolute Error, and R Squared scores, the four models, when using the alpha or coefficient number as determined by their grid searches, performed very similarly. The Elastic Net model had was slightly better than the rest in that it had the lowest median absolute error, the highest R-squared, and the lowest MSE; but, the differences were slight.  I would use the Elastic Net due to these factors but the small size of the dataset prevents making an authoritative statement.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
